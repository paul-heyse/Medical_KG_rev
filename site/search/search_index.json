{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Medical KG Knowledge Platform","text":"<p>Welcome to the Medical Knowledge Graph platform documentation. This site aggregates specifications, runbooks, and operational guides that complement the OpenSpec change proposals.</p>"},{"location":"#key-sections","title":"Key Sections","text":"<ul> <li>Architecture \u2013 High-level system design and rationale.</li> <li>DevOps &amp; Observability \u2013 CI/CD pipelines, infrastructure-as-code, and monitoring patterns.</li> <li>API References \u2013 REST, GraphQL, gRPC, and AsyncAPI contracts generated from the gateway.</li> <li>Guides \u2013 Hands-on tutorials and workflows for operating and extending the platform.</li> </ul> <p>Use the navigation sidebar to explore the content. All documentation is generated with MkDocs Material and published automatically via GitHub Actions.</p>"},{"location":"api-portal/","title":"Medical KG API Portal","text":"<p>This lightweight developer portal provides quick access to the REST, GraphQL, gRPC, SOAP, and AsyncAPI documentation for the multi-protocol gateway.</p>"},{"location":"api-portal/#rest-openapi","title":"REST (OpenAPI)","text":"<ul> <li>Interactive Swagger UI: <code>/docs/openapi</code></li> <li>Specification file: <code>docs/openapi.yaml</code></li> <li>Contract testing recommendation: <code>pytest tests/contract/test_rest_contract.py</code></li> </ul>"},{"location":"api-portal/#graphql","title":"GraphQL","text":"<ul> <li>Playground: <code>/docs/graphql</code></li> <li>Endpoint: <code>/graphql</code></li> <li>Schema SDL: <code>docs/schema.graphql</code></li> <li>Contract testing recommendation: <code>pytest tests/contract/test_graphql_contract.py</code></li> </ul>"},{"location":"api-portal/#grpc","title":"gRPC","text":"<ul> <li>Proto definitions under <code>src/Medical_KG_rev/proto</code></li> <li>Buf configuration: <code>buf.yaml</code></li> <li>Code generation: <code>buf generate</code></li> <li><code>EmbeddingService.Embed</code> requires <code>inputs</code>, <code>namespace</code>, and the authenticated   <code>tenant_id</code>.</li> <li>Use <code>EmbeddingService.ListNamespaces</code> and   <code>EmbeddingService.ValidateTexts</code> to mirror the REST namespace APIs.</li> <li>Health check service exposed via <code>grpc.health.v1</code></li> </ul>"},{"location":"api-portal/#asyncapi-sse","title":"AsyncAPI (SSE)","text":"<ul> <li>AsyncAPI UI: <code>/docs/asyncapi</code></li> <li>Specification: <code>docs/asyncapi.yaml</code></li> <li>Authentication: provide <code>X-API-Key</code> header when connecting to <code>/v1/jobs/{job_id}/events</code></li> </ul>"},{"location":"api-portal/#soap","title":"SOAP","text":"<ul> <li>SOAP endpoint: <code>/soap</code></li> <li>WSDL document: <code>/soap/wsdl</code></li> </ul>"},{"location":"api-portal/#authentication-guide","title":"Authentication Guide","text":"<p>All protocols expect a tenant-aware request. REST, gRPC, and SOAP payloads must include the <code>tenant_id</code> field. GraphQL derives the tenant from authentication context when omitted. For SSE streaming, add the <code>X-API-Key</code> header with <code>public-demo-key</code>.</p>"},{"location":"api-portal/#example-workflow","title":"Example Workflow","text":"<ol> <li>Ingest: Submit documents via REST <code>/v1/ingest/clinicaltrials</code></li> <li>Chunk: Call GraphQL <code>chunk</code> mutation to segment documents</li> <li>Embed: Generate embeddings via gRPC <code>EmbeddingService</code> or GraphQL    <code>embed</code> mutation (namespaces are derived from the authenticated tenant).</li> <li>Extract: Use REST <code>/v1/extract/pico</code> to obtain structured claims</li> <li>Write: Persist relationships via GraphQL <code>write_kg</code> mutation</li> <li>Stream: Monitor job status with SSE <code>/v1/jobs/{job_id}/events</code></li> </ol> <p>Refer to the <code>tests/contract</code> folder for executable examples.</p>"},{"location":"api-portal/#deployment","title":"Deployment","text":"<p>Serve the API portal and generated specifications locally with:</p> <pre><code>python -m http.server --directory docs 9000\n</code></pre> <p>For GitHub Pages, configure the repository to publish the <code>docs/</code> directory as a static site.</p>"},{"location":"gpu-microservices/","title":"MinerU Vision-Language Deployment","text":"<p>This document describes how the MinerU PDF parsing service integrates with the dedicated vLLM vision-language model when operating in split-container mode.</p>"},{"location":"gpu-microservices/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             MinerU Workers               \u2502\n\u2502  \u2022 8 CPU containers (2 vCPU / 4GiB)      \u2502\n\u2502  \u2022 mineru CLI in HTTP client mode        \u2502\n\u2502  \u2022 Connect to vLLM via Service DNS       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u2502  HTTP (OpenAI-compatible)\n                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                vLLM Server               \u2502\n\u2502  \u2022 Model: Qwen/Qwen2.5-VL-7B-Instruct    \u2502\n\u2502  \u2022 GPU memory utilisation target: 92 %   \u2502\n\u2502  \u2022 Exposes /v1/chat/completions + /health\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"gpu-microservices/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Split responsibility \u2013 MinerU workers no longer load GPU models. They stream requests to the   vLLM OpenAI-compatible API and focus exclusively on PDF orchestration.</li> <li>Hot model sharing \u2013 A single vLLM instance batches requests from all workers, dramatically   improving GPU utilisation and throughput.</li> <li>Resilience \u2013 The worker HTTP client provides connection pooling, retries, and circuit-breaker   protection. Metrics are exported for end-to-end visibility.</li> </ul>"},{"location":"gpu-microservices/#local-development","title":"Local Development","text":""},{"location":"gpu-microservices/#start-the-vllm-server","title":"Start the vLLM Server","text":"<pre><code>docker compose -f docker-compose.vllm.yml up -d vllm-server\ncurl http://localhost:8000/health\n</code></pre>"},{"location":"gpu-microservices/#start-mineru-workers","title":"Start MinerU Workers","text":"<pre><code>docker compose up -d mineru-worker\n</code></pre> <p>Workers require the following environment variables:</p> <ul> <li><code>VLLM_SERVER_URL</code> \u2013 defaults to <code>http://vllm-server:8000</code></li> <li><code>MINERU_BACKEND</code> \u2013 must be <code>vlm-http-client</code></li> </ul>"},{"location":"gpu-microservices/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p>The base manifests under <code>ops/k8s/base/</code> deploy the vLLM server and the CPU-only MinerU worker pool. Apply them via Kustomize or plain <code>kubectl</code>:</p> <pre><code>kubectl apply -k ops/k8s/base\n</code></pre> <p>Resources:</p> <ul> <li><code>deployment-vllm-server.yaml</code> \u2013 GPU-backed vLLM instance (RTX 5090)</li> <li><code>deployment-mineru-workers.yaml</code> \u2013 8 replicas, no GPU requests</li> <li><code>networkpolicy-vllm-server.yaml</code> \u2013 restricts access to MinerU workers only</li> <li><code>servicemonitor-vllm-server.yaml</code> \u2013 scrapes Prometheus metrics from the vLLM pod</li> </ul>"},{"location":"gpu-microservices/#health-monitoring","title":"Health Monitoring","text":"<ul> <li>vLLM \u2013 <code>GET /health</code> returns HTTP 200 when the model is ready.</li> <li>Prometheus \u2013 scrape <code>/metrics</code> from both vLLM and worker pods for   <code>mineru_vllm_*</code> and <code>vllm_*</code> series.</li> <li>Alerts \u2013 <code>ops/monitoring/alerts-vllm.yml</code> defines high latency and circuit breaker alerts.</li> </ul>"},{"location":"gpu-microservices/#graceful-shutdown","title":"Graceful Shutdown","text":"<p>Scale the worker deployment to zero before restarting the vLLM server to avoid open requests:</p> <pre><code>kubectl scale deployment/mineru-workers --replicas=0 -n medical-kg\nkubectl rollout restart deployment/vllm-server -n medical-kg\nkubectl scale deployment/mineru-workers --replicas=8 -n medical-kg\n</code></pre> <p>Monitor pod status and Prometheus metrics throughout the restart to confirm healthy recovery.</p>"},{"location":"operational-runbook/","title":"Medical_KG_rev Operational Runbook","text":""},{"location":"operational-runbook/#overview","title":"Overview","text":"<p>This runbook provides operational procedures for the Medical_KG_rev platform, focusing on storage, monitoring, and troubleshooting procedures.</p>"},{"location":"operational-runbook/#table-of-contents","title":"Table of Contents","text":"<ol> <li>System Overview</li> <li>Monitoring and Alerting</li> <li>Storage Operations</li> <li>Pipeline Operations</li> <li>Troubleshooting</li> <li>Emergency Procedures</li> <li>Maintenance Procedures</li> </ol>"},{"location":"operational-runbook/#system-overview","title":"System Overview","text":""},{"location":"operational-runbook/#architecture-components","title":"Architecture Components","text":"<ul> <li>API Gateway: Multi-protocol API (REST, GraphQL, gRPC, SOAP, AsyncAPI)</li> <li>Orchestration: Dagster-based pipeline orchestration</li> <li>Storage: S3-compatible object storage + Redis caching</li> <li>AI Services: MinerU (PDF processing), vLLM (embeddings)</li> <li>Knowledge Graph: Neo4j graph database</li> <li>Monitoring: Prometheus + Grafana + Jaeger</li> </ul>"},{"location":"operational-runbook/#key-services","title":"Key Services","text":"Service Port Purpose Health Check API Gateway 8000 Main API endpoint <code>/health</code> Dagster UI 3000 Pipeline management <code>/health</code> MinIO 9000 Object storage <code>/minio/health/live</code> Redis 6379 Caching <code>PING</code> Neo4j 7474 Graph database <code>/health</code> Prometheus 9090 Metrics collection <code>/health</code> Grafana 3001 Dashboards <code>/health</code> Jaeger 16686 Distributed tracing <code>/health</code>"},{"location":"operational-runbook/#monitoring-and-alerting","title":"Monitoring and Alerting","text":""},{"location":"operational-runbook/#key-metrics","title":"Key Metrics","text":""},{"location":"operational-runbook/#storage-metrics","title":"Storage Metrics","text":"<ul> <li><code>storage_pdf_upload_total</code>: Total PDF uploads</li> <li><code>storage_pdf_upload_duration_seconds</code>: Upload duration</li> <li><code>storage_pdf_upload_size_bytes</code>: Upload size distribution</li> <li><code>storage_cache_hit_total</code>: Cache hit rate</li> <li><code>storage_cache_miss_total</code>: Cache miss rate</li> </ul>"},{"location":"operational-runbook/#pipeline-metrics","title":"Pipeline Metrics","text":"<ul> <li><code>pipeline_pdf_download_total</code>: PDF download attempts</li> <li><code>pipeline_pdf_download_success_total</code>: Successful downloads</li> <li><code>pipeline_pdf_download_failure_total</code>: Failed downloads</li> <li><code>pipeline_pdf_gate_open_total</code>: Gate open events</li> <li><code>pipeline_pdf_gate_closed_total</code>: Gate closed events</li> </ul>"},{"location":"operational-runbook/#system-metrics","title":"System Metrics","text":"<ul> <li><code>http_requests_total</code>: API request count</li> <li><code>http_request_duration_seconds</code>: API response time</li> <li><code>dagster_job_runs_total</code>: Pipeline job runs</li> <li><code>dagster_job_failures_total</code>: Pipeline failures</li> </ul>"},{"location":"operational-runbook/#alerting-rules","title":"Alerting Rules","text":""},{"location":"operational-runbook/#critical-alerts","title":"Critical Alerts","text":"<pre><code># High error rate\n- alert: HighErrorRate\n  expr: rate(http_requests_total{status=~\"5..\"}[5m]) &gt; 0.1\n  for: 2m\n  labels:\n    severity: critical\n  annotations:\n    summary: \"High error rate detected\"\n\n# Storage failures\n- alert: StorageFailures\n  expr: rate(storage_pdf_upload_failure_total[5m]) &gt; 0.05\n  for: 1m\n  labels:\n    severity: critical\n  annotations:\n    summary: \"Storage upload failures detected\"\n\n# Pipeline failures\n- alert: PipelineFailures\n  expr: rate(dagster_job_failures_total[10m]) &gt; 0.1\n  for: 5m\n  labels:\n    severity: critical\n  annotations:\n    summary: \"Pipeline failures detected\"\n</code></pre>"},{"location":"operational-runbook/#warning-alerts","title":"Warning Alerts","text":"<pre><code># High latency\n- alert: HighLatency\n  expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) &gt; 2\n  for: 5m\n  labels:\n    severity: warning\n  annotations:\n    summary: \"High API latency detected\"\n\n# Low cache hit rate\n- alert: LowCacheHitRate\n  expr: rate(storage_cache_hit_total[5m]) / (rate(storage_cache_hit_total[5m]) + rate(storage_cache_miss_total[5m])) &lt; 0.8\n  for: 10m\n  labels:\n    severity: warning\n  annotations:\n    summary: \"Low cache hit rate detected\"\n</code></pre>"},{"location":"operational-runbook/#dashboard-urls","title":"Dashboard URLs","text":"<ul> <li>Main Dashboard: http://grafana:3001/d/main</li> <li>Storage Dashboard: http://grafana:3001/d/storage</li> <li>Pipeline Dashboard: http://grafana:3001/d/pipeline</li> <li>API Dashboard: http://grafana:3001/d/api</li> </ul>"},{"location":"operational-runbook/#storage-operations","title":"Storage Operations","text":""},{"location":"operational-runbook/#health-checks","title":"Health Checks","text":""},{"location":"operational-runbook/#s3minio-health-check","title":"S3/MinIO Health Check","text":"<pre><code>#!/bin/bash\n# Check MinIO health\ncurl -f http://minio:9000/minio/health/live || exit 1\n\n# Check bucket accessibility\naws s3 ls s3://medical-kg-pdf --endpoint-url http://minio:9000 || exit 1\n\n# Test upload/download\necho \"test\" | aws s3 cp - s3://medical-kg-pdf/health-check --endpoint-url http://minio:9000\naws s3 cp s3://medical-kg-pdf/health-check - --endpoint-url http://minio:9000\naws s3 rm s3://medical-kg-pdf/health-check --endpoint-url http://minio:9000\n</code></pre>"},{"location":"operational-runbook/#redis-health-check","title":"Redis Health Check","text":"<pre><code>#!/bin/bash\n# Check Redis connectivity\nredis-cli -u \"$REDIS_URL\" ping || exit 1\n\n# Check memory usage\nredis-cli -u \"$REDIS_URL\" info memory | grep used_memory_human\n\n# Check key count\nredis-cli -u \"$REDIS_URL\" dbsize\n</code></pre>"},{"location":"operational-runbook/#storage-maintenance","title":"Storage Maintenance","text":""},{"location":"operational-runbook/#cleanup-old-files","title":"Cleanup Old Files","text":"<pre><code>#!/bin/bash\n# Clean up files older than 30 days\naws s3 ls s3://medical-kg-pdf --recursive --endpoint-url http://minio:9000 | \\\nawk '$1 &lt; \"'$(date -d '30 days ago' --iso-8601)'\" {print $4}' | \\\nxargs -I {} aws s3 rm s3://medical-kg-pdf/{} --endpoint-url http://minio:9000\n</code></pre>"},{"location":"operational-runbook/#redis-memory-cleanup","title":"Redis Memory Cleanup","text":"<pre><code>#!/bin/bash\n# Clear expired keys\nredis-cli -u \"$REDIS_URL\" --scan --pattern \"medical-kg:*\" | \\\nxargs -I {} redis-cli -u \"$REDIS_URL\" expire {} 0\n\n# Check memory usage after cleanup\nredis-cli -u \"$REDIS_URL\" info memory | grep used_memory_human\n</code></pre>"},{"location":"operational-runbook/#backup-procedures","title":"Backup Procedures","text":""},{"location":"operational-runbook/#s3-backup","title":"S3 Backup","text":"<pre><code>#!/bin/bash\n# Create S3 backup\nBACKUP_DATE=$(date +%Y%m%d_%H%M%S)\nBACKUP_BUCKET=\"medical-kg-pdf-backup\"\n\n# Sync current bucket to backup bucket\naws s3 sync s3://medical-kg-pdf s3://$BACKUP_BUCKET/$BACKUP_DATE \\\n  --endpoint-url http://minio:9000\n\n# Verify backup\naws s3 ls s3://$BACKUP_BUCKET/$BACKUP_DATE --endpoint-url http://minio:9000\n</code></pre>"},{"location":"operational-runbook/#redis-backup","title":"Redis Backup","text":"<pre><code>#!/bin/bash\n# Create Redis backup\nBACKUP_DATE=$(date +%Y%m%d_%H%M%S)\nBACKUP_FILE=\"/backups/redis_$BACKUP_DATE.rdb\"\n\n# Trigger Redis save\nredis-cli -u \"$REDIS_URL\" BGSAVE\n\n# Wait for save to complete\nwhile [ \"$(redis-cli -u \"$REDIS_URL\" LASTSAVE)\" = \"$(redis-cli -u \"$REDIS_URL\" LASTSAVE)\" ]; do\n  sleep 1\ndone\n\n# Copy backup file\ncp /var/lib/redis/dump.rdb \"$BACKUP_FILE\"\n</code></pre>"},{"location":"operational-runbook/#pipeline-operations","title":"Pipeline Operations","text":""},{"location":"operational-runbook/#pipeline-management","title":"Pipeline Management","text":""},{"location":"operational-runbook/#start-pipeline","title":"Start Pipeline","text":"<pre><code>#!/bin/bash\n# Start PDF processing pipeline\ndagster job execute --job pdf-two-phase --config config/orchestration/pipelines/pdf-two-phase.yaml\n</code></pre>"},{"location":"operational-runbook/#monitor-pipeline","title":"Monitor Pipeline","text":"<pre><code>#!/bin/bash\n# Check pipeline status\ndagster job status --job pdf-two-phase\n\n# View pipeline logs\ndagster job logs --job pdf-two-phase --tail\n</code></pre>"},{"location":"operational-runbook/#stop-pipeline","title":"Stop Pipeline","text":"<pre><code>#!/bin/bash\n# Stop running pipeline\ndagster job cancel --job pdf-two-phase\n</code></pre>"},{"location":"operational-runbook/#pipeline-troubleshooting","title":"Pipeline Troubleshooting","text":""},{"location":"operational-runbook/#check-pipeline-state","title":"Check Pipeline State","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"Check pipeline state and diagnose issues.\"\"\"\n\nimport asyncio\nfrom Medical_KG_rev.orchestration.ledger import JobLedger\nfrom Medical_KG_rev.storage.clients import create_storage_clients\nfrom Medical_KG_rev.config.settings import ObjectStorageSettings, RedisCacheSettings\n\nasync def check_pipeline_state(job_id: str):\n    # Check ledger state\n    ledger = JobLedger()\n    state = await ledger.get_job_state(job_id)\n    print(f\"Job {job_id} state: {state}\")\n\n    # Check storage\n    object_settings = ObjectStorageSettings()\n    redis_settings = RedisCacheSettings()\n    clients = create_storage_clients(object_settings, redis_settings)\n\n    # Check if PDF assets exist\n    if \"pdf_assets\" in state.metadata:\n        for asset in state.metadata[\"pdf_assets\"]:\n            if \"storage_uri\" in asset:\n                print(f\"PDF asset: {asset['storage_uri']}\")\n\n                # Check if file exists in storage\n                try:\n                    # Extract checksum from URI\n                    checksum = asset[\"storage_uri\"].split(\"/\")[-1].replace(\".pdf\", \"\")\n                    data = await clients.pdf_storage_client.get_pdf_data(\n                        state.tenant_id, state.document_id, checksum\n                    )\n                    print(f\"PDF exists in storage: {len(data)} bytes\")\n                except Exception as e:\n                    print(f\"PDF not found in storage: {e}\")\n\nif __name__ == \"__main__\":\n    import sys\n    job_id = sys.argv[1] if len(sys.argv) &gt; 1 else \"test-job\"\n    asyncio.run(check_pipeline_state(job_id))\n</code></pre>"},{"location":"operational-runbook/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operational-runbook/#common-issues","title":"Common Issues","text":""},{"location":"operational-runbook/#1-pdf-upload-failures","title":"1. PDF Upload Failures","text":"<p>Symptoms:</p> <ul> <li><code>storage_pdf_upload_failure_total</code> metric increasing</li> <li>Error logs showing \"Storage error\" or \"S3 error\"</li> </ul> <p>Diagnosis:</p> <pre><code># Check S3 connectivity\naws s3 ls s3://medical-kg-pdf --endpoint-url http://minio:9000\n\n# Check bucket permissions\naws s3api get-bucket-acl --bucket medical-kg-pdf --endpoint-url http://minio:9000\n\n# Check disk space on MinIO\ndf -h /var/lib/minio\n</code></pre> <p>Resolution:</p> <ol> <li>Check MinIO service status: <code>docker-compose ps minio</code></li> <li>Restart MinIO if needed: <code>docker-compose restart minio</code></li> <li>Check bucket permissions and policies</li> <li>Verify network connectivity between services</li> </ol>"},{"location":"operational-runbook/#2-redis-connection-issues","title":"2. Redis Connection Issues","text":"<p>Symptoms:</p> <ul> <li><code>storage_cache_miss_total</code> metric increasing</li> <li>Error logs showing \"Redis connection failed\"</li> </ul> <p>Diagnosis:</p> <pre><code># Check Redis connectivity\nredis-cli -u \"$REDIS_URL\" ping\n\n# Check Redis memory usage\nredis-cli -u \"$REDIS_URL\" info memory\n\n# Check Redis logs\ndocker-compose logs redis\n</code></pre> <p>Resolution:</p> <ol> <li>Check Redis service status: <code>docker-compose ps redis</code></li> <li>Restart Redis if needed: <code>docker-compose restart redis</code></li> <li>Check memory usage and clear expired keys</li> <li>Verify Redis configuration</li> </ol>"},{"location":"operational-runbook/#3-pipeline-stuck-at-pdf-gate","title":"3. Pipeline Stuck at PDF Gate","text":"<p>Symptoms:</p> <ul> <li>Pipeline jobs stuck in \"running\" state</li> <li><code>pipeline_pdf_gate_closed_total</code> metric increasing</li> <li>No progress on PDF processing</li> </ul> <p>Diagnosis:</p> <pre><code># Check PDF gate status\nfrom Medical_KG_rev.orchestration.ledger import JobLedger\n\nledger = JobLedger()\nstate = await ledger.get_job_state(\"stuck-job-id\")\nprint(f\"PDF gate status: {state.pdf_gate}\")\n</code></pre> <p>Resolution:</p> <ol> <li>Check if PDF download completed successfully</li> <li>Verify PDF exists in storage</li> <li>Check MinerU service health</li> <li>Manually trigger PDF gate if needed</li> </ol>"},{"location":"operational-runbook/#4-high-memory-usage","title":"4. High Memory Usage","text":"<p>Symptoms:</p> <ul> <li>System memory usage &gt; 80%</li> <li>Redis memory usage high</li> <li>Slow response times</li> </ul> <p>Diagnosis:</p> <pre><code># Check system memory\nfree -h\n\n# Check Redis memory\nredis-cli -u \"$REDIS_URL\" info memory\n\n# Check Docker container memory\ndocker stats\n</code></pre> <p>Resolution:</p> <ol> <li>Clear Redis cache: <code>redis-cli -u \"$REDIS_URL\" FLUSHDB</code></li> <li>Restart high-memory services</li> <li>Check for memory leaks in application code</li> <li>Scale up resources if needed</li> </ol>"},{"location":"operational-runbook/#debug-commands","title":"Debug Commands","text":""},{"location":"operational-runbook/#storage-debug","title":"Storage Debug","text":"<pre><code>#!/bin/bash\n# Debug storage connectivity\necho \"Testing S3 connectivity...\"\naws s3 ls s3://medical-kg-pdf --endpoint-url http://minio:9000\n\necho \"Testing Redis connectivity...\"\nredis-cli -u \"$REDIS_URL\" ping\n\necho \"Testing PDF upload...\"\necho \"test\" | aws s3 cp - s3://medical-kg-pdf/debug-test --endpoint-url http://minio:9000\naws s3 rm s3://medical-kg-pdf/debug-test --endpoint-url http://minio:9000\n</code></pre>"},{"location":"operational-runbook/#pipeline-debug","title":"Pipeline Debug","text":"<pre><code>#!/bin/bash\n# Debug pipeline state\ndagster job status --job pdf-two-phase\n\n# Check pipeline logs\ndagster job logs --job pdf-two-phase --tail 100\n\n# Check specific job\ndagster job status --job pdf-two-phase --run-id &lt;run-id&gt;\n</code></pre>"},{"location":"operational-runbook/#emergency-procedures","title":"Emergency Procedures","text":""},{"location":"operational-runbook/#service-outage-response","title":"Service Outage Response","text":""},{"location":"operational-runbook/#1-api-gateway-down","title":"1. API Gateway Down","text":"<ol> <li>Check service status: <code>docker-compose ps gateway</code></li> <li>Check logs: <code>docker-compose logs gateway</code></li> <li>Restart service: <code>docker-compose restart gateway</code></li> <li>Check dependencies (Redis, Neo4j, etc.)</li> <li>Notify team if issue persists</li> </ol>"},{"location":"operational-runbook/#2-storage-service-down","title":"2. Storage Service Down","text":"<ol> <li>Check MinIO status: <code>docker-compose ps minio</code></li> <li>Check disk space: <code>df -h</code></li> <li>Restart MinIO: <code>docker-compose restart minio</code></li> <li>Check Redis status: <code>docker-compose ps redis</code></li> <li>Restart Redis if needed: <code>docker-compose restart redis</code></li> <li>Verify data integrity after restart</li> </ol>"},{"location":"operational-runbook/#3-pipeline-service-down","title":"3. Pipeline Service Down","text":"<ol> <li>Check Dagster status: <code>docker-compose ps dagster</code></li> <li>Check logs: <code>docker-compose logs dagster</code></li> <li>Restart Dagster: <code>docker-compose restart dagster</code></li> <li>Check running jobs: <code>dagster job status</code></li> <li>Cancel stuck jobs if needed</li> </ol>"},{"location":"operational-runbook/#data-recovery","title":"Data Recovery","text":""},{"location":"operational-runbook/#1-s3-data-recovery","title":"1. S3 Data Recovery","text":"<pre><code>#!/bin/bash\n# Restore from backup\nBACKUP_DATE=\"20240101_120000\"  # Replace with actual backup date\nBACKUP_BUCKET=\"medical-kg-pdf-backup\"\n\n# Restore from backup\naws s3 sync s3://$BACKUP_BUCKET/$BACKUP_DATE s3://medical-kg-pdf \\\n  --endpoint-url http://minio:9000\n\n# Verify restoration\naws s3 ls s3://medical-kg-pdf --endpoint-url http://minio:9000\n</code></pre>"},{"location":"operational-runbook/#2-redis-data-recovery","title":"2. Redis Data Recovery","text":"<pre><code>#!/bin/bash\n# Restore Redis from backup\nBACKUP_FILE=\"/backups/redis_20240101_120000.rdb\"\n\n# Stop Redis\ndocker-compose stop redis\n\n# Copy backup file\ncp \"$BACKUP_FILE\" /var/lib/redis/dump.rdb\n\n# Start Redis\ndocker-compose start redis\n\n# Verify restoration\nredis-cli -u \"$REDIS_URL\" dbsize\n</code></pre>"},{"location":"operational-runbook/#rollback-procedures","title":"Rollback Procedures","text":""},{"location":"operational-runbook/#1-application-rollback","title":"1. Application Rollback","text":"<pre><code>#!/bin/bash\n# Rollback to previous version\ngit checkout previous-version-tag\ndocker-compose build\ndocker-compose up -d\n\n# Verify rollback\ncurl -f http://localhost:8000/health\n</code></pre>"},{"location":"operational-runbook/#2-configuration-rollback","title":"2. Configuration Rollback","text":"<pre><code>#!/bin/bash\n# Rollback configuration changes\ngit checkout HEAD~1 -- config/\ndocker-compose restart\n\n# Verify configuration\ndocker-compose config\n</code></pre>"},{"location":"operational-runbook/#maintenance-procedures","title":"Maintenance Procedures","text":""},{"location":"operational-runbook/#regular-maintenance","title":"Regular Maintenance","text":""},{"location":"operational-runbook/#daily-tasks","title":"Daily Tasks","text":"<ul> <li>[ ] Check system health dashboards</li> <li>[ ] Review error logs</li> <li>[ ] Monitor storage usage</li> <li>[ ] Check pipeline job status</li> </ul>"},{"location":"operational-runbook/#weekly-tasks","title":"Weekly Tasks","text":"<ul> <li>[ ] Review performance metrics</li> <li>[ ] Clean up old log files</li> <li>[ ] Check backup status</li> <li>[ ] Review security logs</li> </ul>"},{"location":"operational-runbook/#monthly-tasks","title":"Monthly Tasks","text":"<ul> <li>[ ] Update system dependencies</li> <li>[ ] Review and update documentation</li> <li>[ ] Performance optimization review</li> <li>[ ] Security audit</li> </ul>"},{"location":"operational-runbook/#scheduled-maintenance","title":"Scheduled Maintenance","text":""},{"location":"operational-runbook/#backup-schedule","title":"Backup Schedule","text":"<ul> <li>S3 Backups: Daily at 2 AM UTC</li> <li>Redis Backups: Daily at 3 AM UTC</li> <li>Configuration Backups: Weekly on Sundays</li> </ul>"},{"location":"operational-runbook/#cleanup-schedule","title":"Cleanup Schedule","text":"<ul> <li>Old Files: Daily cleanup of files older than 30 days</li> <li>Expired Cache: Daily cleanup of expired Redis keys</li> <li>Log Files: Weekly cleanup of old log files</li> </ul>"},{"location":"operational-runbook/#performance-tuning","title":"Performance Tuning","text":""},{"location":"operational-runbook/#s3-optimization","title":"S3 Optimization","text":"<pre><code>#!/bin/bash\n# Optimize S3 performance\naws configure set default.s3.max_concurrent_requests 20\naws configure set default.s3.max_bandwidth 100MB/s\naws configure set default.s3.multipart_threshold 64MB\naws configure set default.s3.multipart_chunksize 16MB\n</code></pre>"},{"location":"operational-runbook/#redis-optimization","title":"Redis Optimization","text":"<pre><code>#!/bin/bash\n# Optimize Redis performance\nredis-cli -u \"$REDIS_URL\" CONFIG SET maxmemory-policy allkeys-lru\nredis-cli -u \"$REDIS_URL\" CONFIG SET tcp-keepalive 60\nredis-cli -u \"$REDIS_URL\" CONFIG SET timeout 300\n</code></pre>"},{"location":"operational-runbook/#contact-information","title":"Contact Information","text":""},{"location":"operational-runbook/#team-contacts","title":"Team Contacts","text":"<ul> <li>Platform Team: platform@company.com</li> <li>On-Call Engineer: +1-555-0123</li> <li>Emergency Contact: +1-555-9999</li> </ul>"},{"location":"operational-runbook/#escalation-procedures","title":"Escalation Procedures","text":"<ol> <li>Level 1: Platform Team (0-15 minutes)</li> <li>Level 2: Senior Engineer (15-30 minutes)</li> <li>Level 3: Engineering Manager (30-60 minutes)</li> <li>Level 4: CTO (60+ minutes)</li> </ol>"},{"location":"operational-runbook/#external-dependencies","title":"External Dependencies","text":"<ul> <li>AWS Support: Enterprise Support Plan</li> <li>MinIO Support: Community Support</li> <li>Redis Support: Enterprise Support Plan</li> <li>Neo4j Support: Enterprise Support Plan</li> </ul>"},{"location":"operational-runbook/#appendix","title":"Appendix","text":""},{"location":"operational-runbook/#useful-commands","title":"Useful Commands","text":""},{"location":"operational-runbook/#docker-commands","title":"Docker Commands","text":"<pre><code># View all containers\ndocker-compose ps\n\n# View logs\ndocker-compose logs -f service-name\n\n# Restart service\ndocker-compose restart service-name\n\n# Scale service\ndocker-compose up -d --scale service-name=3\n\n# Execute command in container\ndocker-compose exec service-name command\n</code></pre>"},{"location":"operational-runbook/#monitoring-commands","title":"Monitoring Commands","text":"<pre><code># Check system resources\nhtop\ndf -h\nfree -h\n\n# Check network connectivity\nnetstat -tulpn\nss -tulpn\n\n# Check process status\nps aux | grep service-name\n</code></pre>"},{"location":"operational-runbook/#storage-commands","title":"Storage Commands","text":"<pre><code># S3 operations\naws s3 ls s3://bucket-name --endpoint-url http://minio:9000\naws s3 cp local-file s3://bucket-name/remote-file --endpoint-url http://minio:9000\naws s3 rm s3://bucket-name/file --endpoint-url http://minio:9000\n\n# Redis operations\nredis-cli -u \"$REDIS_URL\" keys \"pattern*\"\nredis-cli -u \"$REDIS_URL\" get \"key\"\nredis-cli -u \"$REDIS_URL\" set \"key\" \"value\"\nredis-cli -u \"$REDIS_URL\" del \"key\"\n</code></pre>"},{"location":"operational-runbook/#configuration-files","title":"Configuration Files","text":""},{"location":"operational-runbook/#environment-variables","title":"Environment Variables","text":"<pre><code># S3/MinIO\nexport AWS_ACCESS_KEY_ID=minioadmin\nexport AWS_SECRET_ACCESS_KEY=minioadmin\nexport S3_ENDPOINT_URL=http://minio:9000\nexport S3_BUCKET=medical-kg-pdf\n\n# Redis\nexport REDIS_URL=redis://redis:6379/0\nexport REDIS_PASSWORD=redis-password\n\n# Application\nexport ENVIRONMENT=dev\nexport LOG_LEVEL=INFO\nexport CORRELATION_ID_HEADER=X-Correlation-ID\n</code></pre>"},{"location":"operational-runbook/#docker-compose-overrides","title":"Docker Compose Overrides","text":"<pre><code># docker-compose.override.yml\nversion: '3.8'\nservices:\n  minio:\n    environment:\n      MINIO_ROOT_USER: minioadmin\n      MINIO_ROOT_PASSWORD: minioadmin\n    volumes:\n      - minio-data:/data\n    ports:\n      - \"9000:9000\"\n      - \"9001:9001\"\n\n  redis:\n    environment:\n      REDIS_PASSWORD: redis-password\n    volumes:\n      - redis-data:/data\n    ports:\n      - \"6379:6379\"\n\nvolumes:\n  minio-data:\n  redis-data:\n</code></pre> <p>This runbook should be reviewed and updated regularly to reflect changes in the system architecture and operational procedures.</p>"},{"location":"storage-architecture/","title":"Storage Architecture Documentation","text":""},{"location":"storage-architecture/#overview","title":"Overview","text":"<p>The Medical_KG_rev platform integrates S3-compatible object storage and Redis caching to provide durable, scalable storage for pipeline artifacts and metadata. This document describes the architecture, components, and operational procedures.</p>"},{"location":"storage-architecture/#architecture-components","title":"Architecture Components","text":""},{"location":"storage-architecture/#1-object-storage-s3minio","title":"1. Object Storage (S3/MinIO)","text":"<p>Purpose: Durable storage for PDFs, MinerU artifacts, and other pipeline outputs.</p> <p>Key Features:</p> <ul> <li>S3-compatible API support (AWS S3, MinIO, etc.)</li> <li>Configurable endpoints and credentials</li> <li>Automatic checksum generation and validation</li> <li>Presigned URL generation for secure access</li> <li>Metadata storage for provenance tracking</li> </ul> <p>Configuration:</p> <pre><code>ObjectStorageSettings(\n    bucket=\"medical-kg-pdf\",\n    region=\"us-east-1\",\n    endpoint_url=\"http://minio:9000\",  # Optional for MinIO\n    access_key_id=\"minioadmin\",\n    secret_access_key=\"minioadmin\",\n    use_tls=False,  # For development\n    max_file_size=100 * 1024 * 1024,  # 100MB\n    key_prefix=\"pdf\"\n)\n</code></pre> <p>Storage Layout:</p> <pre><code>bucket/\n\u251c\u2500\u2500 pdf/\n\u2502   \u2514\u2500\u2500 {tenant_id}/\n\u2502       \u2514\u2500\u2500 {document_id}/\n\u2502           \u2514\u2500\u2500 {checksum}.pdf\n\u2514\u2500\u2500 documents/\n    \u2514\u2500\u2500 {tenant_id}/\n        \u2514\u2500\u2500 {document_id}/\n            \u2514\u2500\u2500 {artifact_type}/\n                \u2514\u2500\u2500 {checksum}.{extension}\n</code></pre>"},{"location":"storage-architecture/#2-redis-cache","title":"2. Redis Cache","text":"<p>Purpose: High-performance caching for metadata, checksums, and temporary data.</p> <p>Key Features:</p> <ul> <li>In-memory data store with configurable TTL</li> <li>Connection pooling and failover support</li> <li>Key prefixing for multi-tenancy</li> <li>Automatic expiration handling</li> </ul> <p>Configuration:</p> <pre><code>RedisCacheSettings(\n    url=\"redis://redis:6379/0\",\n    password=\"redis-password\",  # Optional\n    use_tls=False,  # For development\n    db_index=0,\n    key_prefix=\"medical-kg\",\n    default_ttl=3600,  # 1 hour\n    max_connections=10\n)\n</code></pre> <p>Cache Layout:</p> <pre><code>{key_prefix}:pdf:{tenant_id}:{document_id}:{checksum} -&gt; PdfAsset\n{key_prefix}:metadata:{tenant_id}:{document_id} -&gt; dict\n{key_prefix}:checksum:{hash} -&gt; str\n</code></pre>"},{"location":"storage-architecture/#client-architecture","title":"Client Architecture","text":""},{"location":"storage-architecture/#1-pdfstorageclient","title":"1. PdfStorageClient","text":"<p>Purpose: Typed client for PDF-specific storage operations.</p> <p>Key Methods:</p> <ul> <li><code>store_pdf()</code>: Upload PDF with metadata caching</li> <li><code>get_pdf_asset()</code>: Retrieve PDF metadata from cache</li> <li><code>get_pdf_data()</code>: Download PDF data from storage</li> <li><code>get_presigned_url()</code>: Generate secure access URLs</li> <li><code>delete_pdf()</code>: Remove PDF and associated metadata</li> </ul> <p>Usage Example:</p> <pre><code>from Medical_KG_rev.storage.clients import create_storage_clients\n\n# Create clients\nclients = create_storage_clients(object_settings, redis_settings)\n\n# Store PDF\nasset = await clients.pdf_storage_client.store_pdf(\n    tenant_id=\"tenant-123\",\n    document_id=\"doc-456\",\n    pdf_data=pdf_bytes,\n    content_type=\"application/pdf\"\n)\n\n# Retrieve PDF\npdf_data = await clients.pdf_storage_client.get_pdf_data(\n    tenant_id=\"tenant-123\",\n    document_id=\"doc-456\",\n    checksum=asset.checksum\n)\n</code></pre>"},{"location":"storage-architecture/#2-documentstorageclient","title":"2. DocumentStorageClient","text":"<p>Purpose: General-purpose storage for document artifacts.</p> <p>Key Methods:</p> <ul> <li><code>upload_document_artifact()</code>: Store artifacts (MinerU output, etc.)</li> <li><code>get_document_artifact()</code>: Retrieve stored artifacts</li> </ul> <p>Usage Example:</p> <pre><code># Store MinerU output\nuri = await clients.document_storage_client.upload_document_artifact(\n    tenant_id=\"tenant-123\",\n    document_id=\"doc-456\",\n    artifact_type=\"mineru_output\",\n    data=json_bytes,\n    file_extension=\"json\"\n)\n\n# Retrieve artifact\ndata = await clients.document_storage_client.get_document_artifact(\n    tenant_id=\"tenant-123\",\n    document_id=\"doc-456\",\n    artifact_type=\"mineru_output\",\n    checksum=\"abc123\",\n    file_extension=\"json\"\n)\n</code></pre>"},{"location":"storage-architecture/#pipeline-integration","title":"Pipeline Integration","text":""},{"location":"storage-architecture/#1-pdf-download-stage","title":"1. PDF Download Stage","text":"<p>Purpose: Download PDFs from external sources and store them persistently.</p> <p>Key Features:</p> <ul> <li>HTTP retry logic with exponential backoff</li> <li>Automatic content type detection</li> <li>Error handling and logging</li> <li>Storage URI generation</li> </ul> <p>Configuration:</p> <pre><code># config/orchestration/pipelines/pdf-two-phase.yaml\nstages:\n  - name: pdf-download\n    type: pdf-download\n    config:\n      retry_attempts: 3\n      timeout: 30\n      max_file_size: 100MB\n</code></pre> <p>Input State:</p> <pre><code>PipelineState(\n    metadata={\n        \"pdf_urls\": [\n            \"https://example.com/paper1.pdf\",\n            \"https://example.com/paper2.pdf\"\n        ]\n    }\n)\n</code></pre> <p>Output State:</p> <pre><code>PipelineState(\n    metadata={\n        \"pdf_assets\": [\n            {\n                \"url\": \"https://example.com/paper1.pdf\",\n                \"storage_uri\": \"s3://bucket/pdf/tenant/doc/abc123.pdf\",\n                \"checksum\": \"abc123\",\n                \"size\": 1024,\n                \"content_type\": \"application/pdf\",\n                \"error\": None\n            }\n        ]\n    }\n)\n</code></pre>"},{"location":"storage-architecture/#2-pdf-gate-stage","title":"2. PDF Gate Stage","text":"<p>Purpose: Conditional pipeline progression based on PDF readiness.</p> <p>Key Features:</p> <ul> <li>Checks <code>pdf_gate.ir_ready</code> status</li> <li>Blocks pipeline until PDF is processed</li> <li>Supports both sync and async execution</li> </ul> <p>Configuration:</p> <pre><code>stages:\n  - name: pdf-gate\n    type: pdf-gate\n    config:\n      gate_name: \"pdf-ir-gate\"\n</code></pre>"},{"location":"storage-architecture/#3-mineru-integration","title":"3. MinerU Integration","text":"<p>Purpose: Process PDFs stored in object storage.</p> <p>Key Features:</p> <ul> <li>Fetches PDFs from S3 using cached metadata</li> <li>Supports both content and storage URI inputs</li> <li>Automatic checksum extraction from URIs</li> </ul> <p>Usage Example:</p> <pre><code># MinerU service with storage support\nprocessor = MineruProcessor(\n    pdf_storage=clients.pdf_storage_client\n)\n\n# Process PDF from storage\nrequest = MineruRequest(\n    storage_uri=\"s3://bucket/pdf/tenant/doc/abc123.pdf\",\n    content=None  # Will be fetched from storage\n)\n\nresult = await processor.process_async(request)\n</code></pre>"},{"location":"storage-architecture/#adapter-integration","title":"Adapter Integration","text":""},{"location":"storage-architecture/#1-storagehelpermixin","title":"1. StorageHelperMixin","text":"<p>Purpose: Provide storage capabilities to adapters.</p> <p>Key Features:</p> <ul> <li>Optional PDF upload functionality</li> <li>Error handling and logging</li> <li>Protocol compliance checking</li> </ul> <p>Usage Example:</p> <pre><code>from Medical_KG_rev.adapters.mixins.storage_helpers import StorageHelperMixin\n\nclass MyAdapter(BaseAdapter, StorageHelperMixin):\n    async def fetch_and_upload_pdf(self, context, pdf_url, document_id):\n        # Fetch PDF data\n        pdf_data = await self._fetch_pdf_data(pdf_url)\n\n        # Upload to storage if available\n        storage_uri = await self.upload_pdf_if_available(\n            tenant_id=context.tenant_id,\n            document_id=document_id,\n            pdf_data=pdf_data\n        )\n\n        return storage_uri\n</code></pre>"},{"location":"storage-architecture/#configuration-management","title":"Configuration Management","text":""},{"location":"storage-architecture/#1-environment-specific-settings","title":"1. Environment-Specific Settings","text":"<p>Development:</p> <pre><code>ENVIRONMENT_DEFAULTS[Environment.DEV] = {\n    \"object_storage\": {\n        \"endpoint_url\": \"http://minio:9000\",\n        \"bucket\": \"medical-kg-pdf\",\n        \"use_tls\": False,\n    },\n    \"redis_cache\": {\n        \"url\": \"redis://redis:6379/0\",\n        \"use_tls\": False,\n    }\n}\n</code></pre> <p>Production:</p> <pre><code>ENVIRONMENT_DEFAULTS[Environment.PROD] = {\n    \"object_storage\": {\n        \"use_tls\": True,\n    },\n    \"redis_cache\": {\n        \"use_tls\": True,\n    }\n}\n</code></pre>"},{"location":"storage-architecture/#2-secrets-management","title":"2. Secrets Management","text":"<p>Environment Variables:</p> <pre><code># S3/MinIO\nAWS_ACCESS_KEY_ID=minioadmin\nAWS_SECRET_ACCESS_KEY=minioadmin\nS3_ENDPOINT_URL=http://minio:9000\nS3_BUCKET=medical-kg-pdf\n\n# Redis\nREDIS_URL=redis://redis:6379/0\nREDIS_PASSWORD=redis-password\n</code></pre> <p>Vault Integration (Production):</p> <pre><code># Load secrets from Vault\nvault_client = hvac.Client(url=\"https://vault.example.com\")\nsecrets = vault_client.secrets.kv.v2.read_secret_version(path=\"medical-kg/storage\")\n\nobject_storage = ObjectStorageSettings(\n    access_key_id=secrets[\"data\"][\"data\"][\"s3_access_key\"],\n    secret_access_key=secrets[\"data\"][\"data\"][\"s3_secret_key\"],\n    # ...\n)\n</code></pre>"},{"location":"storage-architecture/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"storage-architecture/#1-metrics","title":"1. Metrics","text":"<p>Storage Metrics:</p> <ul> <li><code>storage_pdf_upload_total</code>: Total PDF uploads</li> <li><code>storage_pdf_upload_duration_seconds</code>: Upload duration</li> <li><code>storage_pdf_upload_size_bytes</code>: Upload size distribution</li> <li><code>storage_cache_hit_total</code>: Cache hit rate</li> <li><code>storage_cache_miss_total</code>: Cache miss rate</li> </ul> <p>Pipeline Metrics:</p> <ul> <li><code>pipeline_pdf_download_total</code>: PDF download attempts</li> <li><code>pipeline_pdf_download_success_total</code>: Successful downloads</li> <li><code>pipeline_pdf_download_failure_total</code>: Failed downloads</li> <li><code>pipeline_pdf_gate_open_total</code>: Gate open events</li> <li><code>pipeline_pdf_gate_closed_total</code>: Gate closed events</li> </ul>"},{"location":"storage-architecture/#2-logging","title":"2. Logging","text":"<p>Structured Logging:</p> <pre><code>logger.info(\n    \"storage.pdf_uploaded\",\n    tenant_id=tenant_id,\n    document_id=document_id,\n    s3_key=asset.s3_key,\n    size=len(pdf_data),\n    checksum=asset.checksum,\n    duration=upload_time\n)\n</code></pre> <p>Error Logging:</p> <pre><code>logger.warning(\n    \"storage.pdf_upload_failed\",\n    tenant_id=tenant_id,\n    document_id=document_id,\n    error=str(e),\n    retry_count=retry_count\n)\n</code></pre>"},{"location":"storage-architecture/#3-tracing","title":"3. Tracing","text":"<p>OpenTelemetry Spans:</p> <pre><code>from opentelemetry import trace\n\ntracer = trace.get_tracer(__name__)\n\nwith tracer.start_as_current_span(\"storage.upload_pdf\") as span:\n    span.set_attribute(\"tenant_id\", tenant_id)\n    span.set_attribute(\"document_id\", document_id)\n    span.set_attribute(\"file_size\", len(pdf_data))\n\n    # Upload PDF\n    asset = await client.store_pdf(...)\n\n    span.set_attribute(\"s3_key\", asset.s3_key)\n    span.set_attribute(\"checksum\", asset.checksum)\n</code></pre>"},{"location":"storage-architecture/#operational-procedures","title":"Operational Procedures","text":""},{"location":"storage-architecture/#1-health-checks","title":"1. Health Checks","text":"<p>Storage Health Check:</p> <pre><code>async def check_storage_health(clients: StorageClients) -&gt; bool:\n    try:\n        # Test S3 connectivity\n        await clients.object_store.put(\"health-check\", b\"test\")\n        await clients.object_store.get(\"health-check\")\n        await clients.object_store.delete(\"health-check\")\n\n        # Test Redis connectivity\n        await clients.cache_backend.set(\"health-check\", \"test\", ttl=60)\n        value = await clients.cache_backend.get(\"health-check\")\n        assert value == \"test\"\n\n        return True\n    except Exception as e:\n        logger.error(\"storage.health_check_failed\", error=str(e))\n        return False\n</code></pre>"},{"location":"storage-architecture/#2-backup-and-recovery","title":"2. Backup and Recovery","text":"<p>S3 Backup Strategy:</p> <ul> <li>Enable versioning on S3 buckets</li> <li>Configure cross-region replication</li> <li>Set up lifecycle policies for cost optimization</li> <li>Regular backup validation</li> </ul> <p>Redis Backup Strategy:</p> <ul> <li>Enable Redis persistence (RDB + AOF)</li> <li>Regular snapshot backups</li> <li>Cross-region replication for disaster recovery</li> </ul>"},{"location":"storage-architecture/#3-capacity-planning","title":"3. Capacity Planning","text":"<p>Storage Growth Estimation:</p> <pre><code># Estimate storage growth\nestimated_pdfs_per_month = 10000\naverage_pdf_size = 2 * 1024 * 1024  # 2MB\nmonthly_growth = estimated_pdfs_per_month * average_pdf_size\n\n# Plan for 6 months retention\ntotal_capacity_needed = monthly_growth * 6\n</code></pre> <p>Redis Memory Planning:</p> <pre><code># Estimate Redis memory usage\nestimated_metadata_per_pdf = 1024  # 1KB\nestimated_pdfs = 100000\ntotal_metadata_size = estimated_pdfs * estimated_metadata_per_pdf\n\n# Plan for 2x overhead\nredis_memory_needed = total_metadata_size * 2\n</code></pre>"},{"location":"storage-architecture/#troubleshooting","title":"Troubleshooting","text":""},{"location":"storage-architecture/#1-common-issues","title":"1. Common Issues","text":"<p>S3 Connection Errors:</p> <ul> <li>Check endpoint URL and credentials</li> <li>Verify network connectivity</li> <li>Check bucket permissions</li> </ul> <p>Redis Connection Errors:</p> <ul> <li>Verify Redis URL and password</li> <li>Check Redis server status</li> <li>Verify connection pool settings</li> </ul> <p>PDF Upload Failures:</p> <ul> <li>Check file size limits</li> <li>Verify S3 bucket permissions</li> <li>Check network timeouts</li> </ul>"},{"location":"storage-architecture/#2-debugging-tools","title":"2. Debugging Tools","text":"<p>Storage Debug Script:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"Debug storage connectivity and functionality.\"\"\"\n\nimport asyncio\nfrom Medical_KG_rev.storage.clients import create_storage_clients\nfrom Medical_KG_rev.config.settings import ObjectStorageSettings, RedisCacheSettings\n\nasync def debug_storage():\n    # Create clients\n    object_settings = ObjectStorageSettings()\n    redis_settings = RedisCacheSettings()\n    clients = create_storage_clients(object_settings, redis_settings)\n\n    # Test PDF storage\n    test_data = b\"test pdf content\"\n    asset = await clients.pdf_storage_client.store_pdf(\n        tenant_id=\"debug\",\n        document_id=\"test\",\n        pdf_data=test_data\n    )\n    print(f\"Uploaded PDF: {asset.uri}\")\n\n    # Test retrieval\n    retrieved = await clients.pdf_storage_client.get_pdf_data(\n        \"debug\", \"test\", asset.checksum\n    )\n    print(f\"Retrieved PDF: {len(retrieved)} bytes\")\n\n    # Test cache\n    await clients.cache_backend.set(\"debug:test\", {\"status\": \"ok\"})\n    cached = await clients.cache_backend.get(\"debug:test\")\n    print(f\"Cached value: {cached}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(debug_storage())\n</code></pre> <p>Redis Debug Script:</p> <pre><code>#!/bin/bash\n# Debug Redis connectivity\n\nredis-cli -u \"$REDIS_URL\" ping\nredis-cli -u \"$REDIS_URL\" info memory\nredis-cli -u \"$REDIS_URL\" keys \"medical-kg:*\" | head -10\n</code></pre>"},{"location":"storage-architecture/#security-considerations","title":"Security Considerations","text":""},{"location":"storage-architecture/#1-access-control","title":"1. Access Control","text":"<p>S3 Bucket Policies:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::account:role/MedicalKGService\"\n            },\n            \"Action\": [\n                \"s3:GetObject\",\n                \"s3:PutObject\",\n                \"s3:DeleteObject\"\n            ],\n            \"Resource\": \"arn:aws:s3:::medical-kg-pdf/*\"\n        }\n    ]\n}\n</code></pre> <p>Redis ACL:</p> <pre><code># Redis 6+ ACL configuration\nuser medical-kg on &gt;password +@all ~medical-kg:*\n</code></pre>"},{"location":"storage-architecture/#2-encryption","title":"2. Encryption","text":"<p>S3 Encryption:</p> <ul> <li>Enable server-side encryption (SSE-S3 or SSE-KMS)</li> <li>Use HTTPS for all S3 operations</li> <li>Encrypt data in transit</li> </ul> <p>Redis Encryption:</p> <ul> <li>Enable TLS for Redis connections</li> <li>Use strong passwords</li> <li>Consider Redis AUTH for additional security</li> </ul>"},{"location":"storage-architecture/#3-audit-logging","title":"3. Audit Logging","text":"<p>S3 Access Logging:</p> <ul> <li>Enable S3 access logging</li> <li>Monitor for unusual access patterns</li> <li>Set up alerts for failed access attempts</li> </ul> <p>Redis Monitoring:</p> <ul> <li>Monitor Redis slow log</li> <li>Track command usage patterns</li> <li>Set up alerts for memory usage</li> </ul>"},{"location":"storage-architecture/#performance-optimization","title":"Performance Optimization","text":""},{"location":"storage-architecture/#1-s3-optimization","title":"1. S3 Optimization","text":"<p>Multipart Uploads:</p> <pre><code># For large files (&gt;100MB)\nawait client.store_pdf(\n    tenant_id=tenant_id,\n    document_id=document_id,\n    pdf_data=large_pdf_data,\n    use_multipart=True  # Future enhancement\n)\n</code></pre> <p>Connection Pooling:</p> <pre><code># Configure S3 client with connection pooling\ns3_client = boto3.client(\n    \"s3\",\n    config=Config(\n        max_pool_connections=50,\n        retries={\"max_attempts\": 3}\n    )\n)\n</code></pre>"},{"location":"storage-architecture/#2-redis-optimization","title":"2. Redis Optimization","text":"<p>Connection Pooling:</p> <pre><code>redis_client = Redis(\n    max_connections=20,\n    retry_on_timeout=True,\n    socket_keepalive=True\n)\n</code></pre> <p>Memory Optimization:</p> <pre><code># Redis configuration\nmaxmemory 2gb\nmaxmemory-policy allkeys-lru\n</code></pre>"},{"location":"storage-architecture/#3-caching-strategies","title":"3. Caching Strategies","text":"<p>Cache Warming:</p> <pre><code># Pre-load frequently accessed data\nasync def warm_cache(clients: StorageClients):\n    popular_docs = await get_popular_documents()\n    for doc in popular_docs:\n        await clients.cache_backend.set(\n            f\"pdf:{doc.tenant_id}:{doc.document_id}\",\n            doc.metadata,\n            ttl=3600\n        )\n</code></pre> <p>Cache Invalidation:</p> <pre><code># Invalidate cache on document updates\nasync def invalidate_document_cache(clients: StorageClients, tenant_id: str, document_id: str):\n    pattern = f\"medical-kg:pdf:{tenant_id}:{document_id}:*\"\n    await clients.cache_backend.delete_pattern(pattern)\n</code></pre>"},{"location":"storage-architecture/#future-enhancements","title":"Future Enhancements","text":""},{"location":"storage-architecture/#1-planned-features","title":"1. Planned Features","text":"<ul> <li>CDN Integration: CloudFront distribution for global PDF access</li> <li>Compression: Automatic PDF compression for storage optimization</li> <li>Deduplication: Content-based deduplication to reduce storage costs</li> <li>Archive Tiering: Automatic migration to cheaper storage classes</li> </ul>"},{"location":"storage-architecture/#2-scalability-improvements","title":"2. Scalability Improvements","text":"<ul> <li>Horizontal Scaling: Multiple Redis instances with clustering</li> <li>Load Balancing: S3 request distribution across regions</li> <li>Async Processing: Background tasks for large file operations</li> </ul>"},{"location":"storage-architecture/#3-monitoring-enhancements","title":"3. Monitoring Enhancements","text":"<ul> <li>Custom Dashboards: Grafana dashboards for storage metrics</li> <li>Alerting: PagerDuty integration for critical issues</li> <li>Cost Monitoring: AWS Cost Explorer integration</li> </ul>"},{"location":"storage-architecture/#conclusion","title":"Conclusion","text":"<p>The storage architecture provides a robust, scalable foundation for the Medical_KG_rev platform. By combining S3-compatible object storage with Redis caching, the system ensures data durability, performance, and operational efficiency.</p> <p>Key benefits:</p> <ul> <li>Durability: S3 provides 99.999999999% durability</li> <li>Performance: Redis caching reduces latency for frequently accessed data</li> <li>Scalability: Both components scale horizontally</li> <li>Cost-effectiveness: Lifecycle policies and caching reduce costs</li> <li>Operational simplicity: Standard APIs and tooling</li> </ul> <p>For questions or issues, refer to the troubleshooting section or contact the platform team.</p>"},{"location":"storage-quickstart/","title":"Storage Quick Start Guide","text":""},{"location":"storage-quickstart/#overview","title":"Overview","text":"<p>This guide provides a quick start for using the S3-compatible object storage and Redis caching features in Medical_KG_rev.</p>"},{"location":"storage-quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker and Docker Compose installed</li> <li>Python 3.12+ environment</li> <li>Basic understanding of S3 and Redis concepts</li> </ul>"},{"location":"storage-quickstart/#local-development-setup","title":"Local Development Setup","text":""},{"location":"storage-quickstart/#1-start-storage-services","title":"1. Start Storage Services","text":"<pre><code># Start MinIO (S3-compatible) and Redis\ndocker-compose up -d minio redis\n\n# Verify services are running\ndocker-compose ps minio redis\n</code></pre>"},{"location":"storage-quickstart/#2-configure-environment-variables","title":"2. Configure Environment Variables","text":"<pre><code># S3/MinIO configuration\nexport AWS_ACCESS_KEY_ID=minioadmin\nexport AWS_SECRET_ACCESS_KEY=minioadmin\nexport S3_ENDPOINT_URL=http://localhost:9000\nexport S3_BUCKET=medical-kg-pdf\n\n# Redis configuration\nexport REDIS_URL=redis://localhost:6379/0\n</code></pre>"},{"location":"storage-quickstart/#3-create-s3-bucket","title":"3. Create S3 Bucket","text":"<pre><code># Create bucket using AWS CLI\naws s3 mb s3://medical-kg-pdf --endpoint-url http://localhost:9000\n\n# Verify bucket creation\naws s3 ls --endpoint-url http://localhost:9000\n</code></pre>"},{"location":"storage-quickstart/#basic-usage","title":"Basic Usage","text":""},{"location":"storage-quickstart/#1-storage-client-setup","title":"1. Storage Client Setup","text":"<pre><code>from Medical_KG_rev.storage.clients import create_storage_clients\nfrom Medical_KG_rev.config.settings import ObjectStorageSettings, RedisCacheSettings\n\n# Create storage clients\nobject_settings = ObjectStorageSettings(\n    bucket=\"medical-kg-pdf\",\n    endpoint_url=\"http://localhost:9000\",\n    access_key_id=\"minioadmin\",\n    secret_access_key=\"minioadmin\",\n    use_tls=False\n)\n\nredis_settings = RedisCacheSettings(\n    url=\"redis://localhost:6379/0\",\n    use_tls=False\n)\n\nclients = create_storage_clients(object_settings, redis_settings)\n</code></pre>"},{"location":"storage-quickstart/#2-pdf-storage-operations","title":"2. PDF Storage Operations","text":"<pre><code># Store a PDF\npdf_data = b\"fake pdf content\"\nasset = await clients.pdf_storage_client.store_pdf(\n    tenant_id=\"tenant-123\",\n    document_id=\"doc-456\",\n    pdf_data=pdf_data,\n    content_type=\"application/pdf\"\n)\n\nprint(f\"Stored PDF: {asset.uri}\")\nprint(f\"Checksum: {asset.checksum}\")\nprint(f\"Size: {asset.size} bytes\")\n\n# Retrieve PDF data\npdf_data = await clients.pdf_storage_client.get_pdf_data(\n    tenant_id=\"tenant-123\",\n    document_id=\"doc-456\",\n    checksum=asset.checksum\n)\n\nprint(f\"Retrieved PDF: {len(pdf_data)} bytes\")\n\n# Generate presigned URL\npresigned_url = clients.pdf_storage_client.get_presigned_url(\n    tenant_id=\"tenant-123\",\n    document_id=\"doc-456\",\n    checksum=asset.checksum,\n    expires_in=3600\n)\n\nprint(f\"Presigned URL: {presigned_url}\")\n</code></pre>"},{"location":"storage-quickstart/#3-document-artifact-storage","title":"3. Document Artifact Storage","text":"<pre><code># Store MinerU output\nmineru_output = b'{\"pages\": 10, \"figures\": 3, \"tables\": 2}'\nuri = await clients.document_storage_client.upload_document_artifact(\n    tenant_id=\"tenant-123\",\n    document_id=\"doc-456\",\n    artifact_type=\"mineru_output\",\n    data=mineru_output,\n    file_extension=\"json\"\n)\n\nprint(f\"Stored artifact: {uri}\")\n\n# Retrieve artifact\nartifact_data = await clients.document_storage_client.get_document_artifact(\n    tenant_id=\"tenant-123\",\n    document_id=\"doc-456\",\n    artifact_type=\"mineru_output\",\n    checksum=\"abc123\",\n    file_extension=\"json\"\n)\n\nprint(f\"Retrieved artifact: {len(artifact_data)} bytes\")\n</code></pre>"},{"location":"storage-quickstart/#4-cache-operations","title":"4. Cache Operations","text":"<pre><code># Store data in cache\nawait clients.cache_backend.set(\n    \"test:key\",\n    {\"message\": \"Hello, World!\", \"timestamp\": \"2024-01-01T00:00:00Z\"},\n    ttl=3600\n)\n\n# Retrieve data from cache\ncached_data = await clients.cache_backend.get(\"test:key\")\nprint(f\"Cached data: {cached_data}\")\n\n# Check if key exists\nexists = await clients.cache_backend.exists(\"test:key\")\nprint(f\"Key exists: {exists}\")\n\n# Delete key\nawait clients.cache_backend.delete(\"test:key\")\n</code></pre>"},{"location":"storage-quickstart/#pipeline-integration","title":"Pipeline Integration","text":""},{"location":"storage-quickstart/#1-pdf-download-stage","title":"1. PDF Download Stage","text":"<pre><code>from Medical_KG_rev.orchestration.stages.pdf_download import StorageAwarePdfDownloadStage\nfrom Medical_KG_rev.orchestration.stages.types import PipelineState\n\n# Create PDF download stage\nstage = StorageAwarePdfDownloadStage(pdf_storage=clients.pdf_storage_client)\n\n# Execute stage\npipeline_state = PipelineState(\n    job_id=\"test-job\",\n    tenant_id=\"tenant-123\",\n    document_id=\"doc-456\",\n    metadata={\n        \"pdf_urls\": [\n            \"https://example.com/paper1.pdf\",\n            \"https://example.com/paper2.pdf\"\n        ]\n    }\n)\n\nresult = await stage.execute(pipeline_state)\nprint(f\"Downloaded {len(result.metadata['pdf_assets'])} PDFs\")\n</code></pre>"},{"location":"storage-quickstart/#2-pdf-gate-stage","title":"2. PDF Gate Stage","text":"<pre><code>from Medical_KG_rev.orchestration.stages.pdf_gate import SimplePdfGateStage\nfrom Medical_KG_rev.orchestration.stages.types import PdfGateStatus\n\n# Create PDF gate stage\ngate = SimplePdfGateStage()\n\n# Execute gate\npipeline_state = PipelineState(\n    job_id=\"test-job\",\n    tenant_id=\"tenant-123\",\n    document_id=\"doc-456\",\n    pdf_gate=PdfGateStatus(ir_ready=True)\n)\n\nresult = await gate.execute(pipeline_state)\nprint(f\"Gate status: {result.pdf_gate.ir_ready}\")\n</code></pre>"},{"location":"storage-quickstart/#adapter-integration","title":"Adapter Integration","text":""},{"location":"storage-quickstart/#1-storage-helper-mixin","title":"1. Storage Helper Mixin","text":"<pre><code>from Medical_KG_rev.adapters.mixins.storage_helpers import StorageHelperMixin\nfrom Medical_KG_rev.adapters.base import BaseAdapter\n\nclass MyAdapter(BaseAdapter, StorageHelperMixin):\n    def __init__(self):\n        super().__init__(name=\"my-adapter\")\n        # Storage client will be injected via context\n\n    async def fetch_and_upload_pdf(self, context, pdf_url, document_id):\n        # Fetch PDF data\n        import httpx\n        async with httpx.AsyncClient() as client:\n            response = await client.get(pdf_url)\n            pdf_data = response.content\n\n        # Upload to storage if available\n        storage_uri = await self.upload_pdf_if_available(\n            tenant_id=context.tenant_id,\n            document_id=document_id,\n            pdf_data=pdf_data\n        )\n\n        return storage_uri\n</code></pre>"},{"location":"storage-quickstart/#2-openalex-adapter-with-storage","title":"2. OpenAlex Adapter with Storage","text":"<pre><code>from Medical_KG_rev.adapters.openalex.adapter import OpenAlexAdapter\nfrom Medical_KG_rev.adapters.base import AdapterContext\n\n# Create adapter with storage\nadapter = OpenAlexAdapter()\nadapter._pdf_storage = clients.pdf_storage_client\n\n# Fetch and upload PDF\ncontext = AdapterContext(\n    tenant_id=\"tenant-123\",\n    domain=\"biomedical\",\n    correlation_id=\"corr-456\"\n)\n\nstorage_uri = await adapter.fetch_and_upload_pdf(\n    context=context,\n    pdf_url=\"https://example.com/paper.pdf\",\n    document_id=\"doc-789\"\n)\n\nprint(f\"PDF stored at: {storage_uri}\")\n</code></pre>"},{"location":"storage-quickstart/#mineru-integration","title":"MinerU Integration","text":""},{"location":"storage-quickstart/#1-mineru-service-with-storage","title":"1. MinerU Service with Storage","text":"<pre><code>from Medical_KG_rev.services.mineru.service import MineruProcessor\nfrom Medical_KG_rev.services.mineru.types import MineruRequest\n\n# Create MinerU processor with storage\nprocessor = MineruProcessor(\n    pdf_storage=clients.pdf_storage_client\n)\n\n# Process PDF from storage\nrequest = MineruRequest(\n    storage_uri=\"s3://medical-kg-pdf/pdf/tenant-123/doc-456/abc123.pdf\",\n    content=None  # Will be fetched from storage\n)\n\nresult = await processor.process_async(request)\nprint(f\"Processed PDF: {result.pages} pages, {result.figures} figures\")\n</code></pre>"},{"location":"storage-quickstart/#configuration-examples","title":"Configuration Examples","text":""},{"location":"storage-quickstart/#1-development-configuration","title":"1. Development Configuration","text":"<pre><code># config/settings.py\nENVIRONMENT_DEFAULTS = {\n    Environment.DEV: {\n        \"object_storage\": {\n            \"endpoint_url\": \"http://minio:9000\",\n            \"bucket\": \"medical-kg-pdf\",\n            \"use_tls\": False,\n        },\n        \"redis_cache\": {\n            \"url\": \"redis://redis:6379/0\",\n            \"use_tls\": False,\n        }\n    }\n}\n</code></pre>"},{"location":"storage-quickstart/#2-production-configuration","title":"2. Production Configuration","text":"<pre><code># config/settings.py\nENVIRONMENT_DEFAULTS = {\n    Environment.PROD: {\n        \"object_storage\": {\n            \"bucket\": \"medical-kg-pdf-prod\",\n            \"region\": \"us-east-1\",\n            \"use_tls\": True,\n        },\n        \"redis_cache\": {\n            \"url\": \"redis://redis-cluster:6379/0\",\n            \"use_tls\": True,\n            \"max_connections\": 20,\n        }\n    }\n}\n</code></pre>"},{"location":"storage-quickstart/#testing","title":"Testing","text":""},{"location":"storage-quickstart/#1-unit-tests","title":"1. Unit Tests","text":"<pre><code>import pytest\nfrom unittest.mock import AsyncMock, MagicMock\nfrom Medical_KG_rev.storage.clients import PdfStorageClient\n\n@pytest.mark.asyncio\nasync def test_pdf_storage():\n    # Mock storage client\n    mock_store = MagicMock()\n    mock_store.put = AsyncMock()\n\n    client = PdfStorageClient(mock_store, settings)\n\n    # Test PDF upload\n    pdf_data = b\"test pdf content\"\n    asset = await client.store_pdf(\n        tenant_id=\"test-tenant\",\n        document_id=\"test-doc\",\n        pdf_data=pdf_data\n    )\n\n    assert asset.checksum is not None\n    assert asset.size == len(pdf_data)\n</code></pre>"},{"location":"storage-quickstart/#2-integration-tests","title":"2. Integration Tests","text":"<pre><code>import pytest\nfrom moto import mock_s3\n\n@pytest.mark.integration\n@mock_s3\nasync def test_s3_integration():\n    # Test with real S3 operations\n    clients = create_storage_clients(object_settings, redis_settings)\n\n    # Test PDF storage\n    pdf_data = b\"integration test pdf\"\n    asset = await clients.pdf_storage_client.store_pdf(\n        tenant_id=\"integration-tenant\",\n        document_id=\"integration-doc\",\n        pdf_data=pdf_data\n    )\n\n    # Test retrieval\n    retrieved_data = await clients.pdf_storage_client.get_pdf_data(\n        \"integration-tenant\", \"integration-doc\", asset.checksum\n    )\n\n    assert retrieved_data == pdf_data\n</code></pre>"},{"location":"storage-quickstart/#monitoring","title":"Monitoring","text":""},{"location":"storage-quickstart/#1-health-checks","title":"1. Health Checks","text":"<pre><code>async def check_storage_health(clients):\n    try:\n        # Test S3 connectivity\n        await clients.object_store.put(\"health-check\", b\"test\")\n        await clients.object_store.get(\"health-check\")\n        await clients.object_store.delete(\"health-check\")\n\n        # Test Redis connectivity\n        await clients.cache_backend.set(\"health-check\", \"test\", ttl=60)\n        value = await clients.cache_backend.get(\"health-check\")\n        assert value == \"test\"\n\n        return True\n    except Exception as e:\n        print(f\"Health check failed: {e}\")\n        return False\n</code></pre>"},{"location":"storage-quickstart/#2-metrics","title":"2. Metrics","text":"<pre><code>from prometheus_client import Counter, Histogram\n\n# Storage metrics\npdf_uploads_total = Counter('storage_pdf_upload_total', 'Total PDF uploads')\npdf_upload_duration = Histogram('storage_pdf_upload_duration_seconds', 'PDF upload duration')\ncache_hits_total = Counter('storage_cache_hit_total', 'Cache hits')\ncache_misses_total = Counter('storage_cache_miss_total', 'Cache misses')\n\n# Usage in code\nwith pdf_upload_duration.time():\n    asset = await client.store_pdf(...)\n    pdf_uploads_total.inc()\n</code></pre>"},{"location":"storage-quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"storage-quickstart/#1-common-issues","title":"1. Common Issues","text":"<p>S3 Connection Errors:</p> <pre><code># Check MinIO status\ndocker-compose ps minio\n\n# Check bucket permissions\naws s3 ls s3://medical-kg-pdf --endpoint-url http://localhost:9000\n</code></pre> <p>Redis Connection Errors:</p> <pre><code># Check Redis status\ndocker-compose ps redis\n\n# Test Redis connectivity\nredis-cli -u \"redis://localhost:6379/0\" ping\n</code></pre>"},{"location":"storage-quickstart/#2-debug-scripts","title":"2. Debug Scripts","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"Debug storage connectivity.\"\"\"\n\nimport asyncio\nfrom Medical_KG_rev.storage.clients import create_storage_clients\nfrom Medical_KG_rev.config.settings import ObjectStorageSettings, RedisCacheSettings\n\nasync def debug_storage():\n    # Create clients\n    object_settings = ObjectStorageSettings(\n        endpoint_url=\"http://localhost:9000\",\n        bucket=\"medical-kg-pdf\"\n    )\n    redis_settings = RedisCacheSettings(url=\"redis://localhost:6379/0\")\n    clients = create_storage_clients(object_settings, redis_settings)\n\n    # Test PDF storage\n    test_data = b\"debug test pdf\"\n    asset = await clients.pdf_storage_client.store_pdf(\n        tenant_id=\"debug\",\n        document_id=\"test\",\n        pdf_data=test_data\n    )\n    print(f\"Uploaded PDF: {asset.uri}\")\n\n    # Test cache\n    await clients.cache_backend.set(\"debug:test\", {\"status\": \"ok\"})\n    cached = await clients.cache_backend.get(\"debug:test\")\n    print(f\"Cached value: {cached}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(debug_storage())\n</code></pre>"},{"location":"storage-quickstart/#next-steps","title":"Next Steps","text":"<ol> <li>Explore Documentation: Read the full Storage Architecture Documentation</li> <li>Operational Procedures: Review the Operational Runbook</li> <li>Integration Examples: Check the test files for more usage examples</li> <li>Monitoring Setup: Configure Prometheus and Grafana for production monitoring</li> <li>Security Configuration: Set up proper access controls and encryption</li> </ol>"},{"location":"storage-quickstart/#support","title":"Support","text":"<p>For questions or issues:</p> <ul> <li>Check the troubleshooting section above</li> <li>Review the operational runbook</li> <li>Contact the platform team</li> <li>Open an issue in the repository</li> </ul> <p>Happy coding! \ud83d\ude80</p>"},{"location":"api/coordinators/","title":"Coordinators API","text":"<p>The coordinators layer provides a protocol-agnostic interface between the gateway services and domain logic. Each coordinator manages a specific type of operation (chunking, embedding) and handles job lifecycle, error translation, and metrics emission.</p>"},{"location":"api/coordinators/#chunking-coordinator","title":"Chunking Coordinator","text":"<p>The <code>ChunkingCoordinator</code> coordinates synchronous chunking operations by managing job lifecycle, delegating to ChunkingService, and translating errors.</p>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.chunking.ChunkingCoordinator","title":"<code>Medical_KG_rev.gateway.coordinators.chunking.ChunkingCoordinator(lifecycle: JobLifecycleManager, chunker: ChunkingService, config: CoordinatorConfig, *, errors: ChunkingErrorTranslator | None = None)</code>","text":"<p>               Bases: <code>BaseCoordinator[ChunkingRequest, ChunkingResult]</code></p> <p>Coordinates synchronous document chunking operations.</p> <p>This class implements the coordinator pattern for document chunking, managing the complete lifecycle of chunking jobs from request validation through error handling and result assembly.</p> <p>The coordinator coordinates between the gateway service layer and the domain chunking service, providing a clean abstraction for synchronous chunking operations with comprehensive error handling and metrics.</p> <p>Attributes:</p> Name Type Description <code>_lifecycle</code> <p>JobLifecycleManager for tracking job state and metadata.</p> <code>_chunker</code> <p>ChunkingService for performing actual document chunking.</p> <code>_errors</code> <p>ChunkingErrorTranslator for translating chunking exceptions      to coordinator-friendly errors.</p> Invariants <ul> <li>self._lifecycle is never None after init</li> <li>self._chunker is never None after init</li> <li>self._errors is never None after init</li> <li>All public methods maintain job lifecycle consistency</li> </ul> Thread Safety <ul> <li>Not thread-safe: Designed for single-threaded use per coordinator instance</li> <li>Multiple coordinator instances can run concurrently</li> </ul> Lifecycle <ul> <li>Created with injected dependencies (lifecycle, chunker, config, errors)</li> <li>Used for processing chunking requests via execute method</li> <li>No explicit cleanup required (stateless operations)</li> </ul> Example <p>coordinator = ChunkingCoordinator( ...     lifecycle=JobLifecycleManager(), ...     chunker=ChunkingService(), ...     config=CoordinatorConfig(name=\"chunking\"), ...     errors=ChunkingErrorTranslator() ... ) result = coordinator.execute(ChunkingRequest( ...     document_id=\"doc1\", ...     text=\"Sample document text for chunking.\", ...     strategy=\"section\" ... )) print(f\"Processed {len(result.chunks)} chunks\")</p> <p>Initialize the chunking coordinator.</p> <p>Parameters:</p> Name Type Description Default <code>lifecycle</code> <code>JobLifecycleManager</code> <p>JobLifecycleManager for tracking job state and metadata.        Must be initialized and ready to manage jobs.</p> required <code>chunker</code> <code>ChunkingService</code> <p>ChunkingService for performing actual document chunking.      Must be configured with available chunking strategies.</p> required <code>config</code> <code>CoordinatorConfig</code> <p>CoordinatorConfig with coordinator name and settings.     Used for metrics and configuration.</p> required <code>errors</code> <code>ChunkingErrorTranslator | None</code> <p>Optional ChunkingErrorTranslator for error translation.    If None, a new translator will be created with available    strategies from the chunker.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any required dependency is None or invalid.</p> <code>ConfigurationError</code> <p>If coordinator configuration is invalid.</p> Source code in <code>src/Medical_KG_rev/gateway/coordinators/chunking.py</code> <pre><code>def __init__(\n    self,\n    lifecycle: JobLifecycleManager,\n    chunker: ChunkingService,\n    config: CoordinatorConfig,\n    *,\n    errors: ChunkingErrorTranslator | None = None,\n) -&gt; None:\n    \"\"\"Initialize the chunking coordinator.\n\n    Args:\n        lifecycle: JobLifecycleManager for tracking job state and metadata.\n                   Must be initialized and ready to manage jobs.\n        chunker: ChunkingService for performing actual document chunking.\n                 Must be configured with available chunking strategies.\n        config: CoordinatorConfig with coordinator name and settings.\n                Used for metrics and configuration.\n        errors: Optional ChunkingErrorTranslator for error translation.\n               If None, a new translator will be created with available\n               strategies from the chunker.\n\n    Raises:\n        ValueError: If any required dependency is None or invalid.\n        ConfigurationError: If coordinator configuration is invalid.\n    \"\"\"\n    super().__init__(config=config, metrics=self._metrics(config))\n    self._lifecycle = lifecycle\n    self._chunker = chunker\n    strategies = chunker.available_strategies()\n    self._errors = errors or ChunkingErrorTranslator(strategies=strategies)\n</code></pre>"},{"location":"api/coordinators/#embedding-coordinator","title":"Embedding Coordinator","text":"<p>The <code>EmbeddingCoordinator</code> coordinates embedding operations with policy enforcement, namespace resolution, and persistence.</p>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.embedding.EmbeddingCoordinator","title":"<code>Medical_KG_rev.gateway.coordinators.embedding.EmbeddingCoordinator(lifecycle: JobLifecycleManager, registry: EmbeddingModelRegistry, namespace_registry: EmbeddingNamespaceRegistry, policy: NamespaceAccessPolicy, persister: EmbeddingPersister, telemetry: EmbeddingTelemetry | None, config: CoordinatorConfig)</code>","text":"<p>               Bases: <code>BaseCoordinator[EmbeddingRequest, EmbeddingResult]</code></p> <p>Coordinates synchronous text embedding operations.</p> <p>This class implements the coordinator pattern for text embedding, managing the complete lifecycle of embedding jobs from namespace access control through model selection, embedding generation, persistence, and telemetry.</p> <p>The coordinator coordinates between the gateway service layer and the domain embedding services, providing a clean abstraction for synchronous embedding operations with comprehensive access control, persistence, and metrics.</p> <p>Attributes:</p> Name Type Description <code>_lifecycle</code> <p>JobLifecycleManager for tracking job state and metadata.</p> <code>_registry</code> <p>EmbeddingModelRegistry for model selection and configuration.</p> <code>_namespace_registry</code> <p>EmbeddingNamespaceRegistry for namespace configuration.</p> <code>_policy</code> <p>NamespaceAccessPolicy for access control evaluation.</p> <code>_persister</code> <p>EmbeddingPersister for embedding storage.</p> <code>_telemetry</code> <p>EmbeddingTelemetry for metrics emission (optional).</p> Invariants <ul> <li>self._lifecycle is never None after init</li> <li>self._registry is never None after init</li> <li>self._namespace_registry is never None after init</li> <li>self._policy is never None after init</li> <li>self._persister is never None after init</li> <li>All public methods maintain job lifecycle consistency</li> </ul> Thread Safety <ul> <li>Not thread-safe: Designed for single-threaded use per coordinator instance</li> <li>Multiple coordinator instances can run concurrently</li> </ul> Lifecycle <ul> <li>Created with injected dependencies (lifecycle, registry, policy, etc.)</li> <li>Used for processing embedding requests via execute method</li> <li>No explicit cleanup required (stateless operations)</li> </ul> Example <p>coordinator = EmbeddingCoordinator( ...     lifecycle=JobLifecycleManager(), ...     registry=EmbeddingModelRegistry(), ...     namespace_registry=EmbeddingNamespaceRegistry(), ...     policy=NamespaceAccessPolicy(), ...     persister=EmbeddingPersister(), ...     telemetry=EmbeddingTelemetry(), ...     config=CoordinatorConfig(name=\"embedding\") ... ) result = coordinator.execute(EmbeddingRequest( ...     tenant_id=\"tenant1\", ...     namespace=\"medical\", ...     texts=[\"Sample text to embed\"], ...     options=EmbeddingOptions(model=\"sentence-transformers/all-MiniLM-L6-v2\") ... )) print(f\"Generated {len(result.response.vectors)} embeddings\")</p> <p>Initialize the embedding coordinator with required dependencies.</p> <p>Parameters:</p> Name Type Description Default <code>lifecycle</code> <code>JobLifecycleManager</code> <p>Manager for tracking job lifecycle and metadata.</p> required <code>registry</code> <code>EmbeddingModelRegistry</code> <p>Registry for embedding model selection and configuration.</p> required <code>namespace_registry</code> <code>EmbeddingNamespaceRegistry</code> <p>Registry for namespace-specific configuration.</p> required <code>policy</code> <code>NamespaceAccessPolicy</code> <p>Policy engine for namespace access control evaluation.</p> required <code>persister</code> <code>EmbeddingPersister</code> <p>Service for persisting generated embeddings.</p> required <code>telemetry</code> <code>EmbeddingTelemetry | None</code> <p>Optional telemetry service for metrics emission.</p> required <code>config</code> <code>CoordinatorConfig</code> <p>Coordinator configuration settings.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If any required dependency is None.</p> Example <p>coordinator = EmbeddingCoordinator( ...     lifecycle=JobLifecycleManager(), ...     registry=EmbeddingModelRegistry(), ...     namespace_registry=EmbeddingNamespaceRegistry(), ...     policy=NamespaceAccessPolicy(), ...     persister=EmbeddingPersister(), ...     telemetry=EmbeddingTelemetry(), ...     config=CoordinatorConfig(name=\"embedding\") ... )</p> Source code in <code>src/Medical_KG_rev/gateway/coordinators/embedding.py</code> <pre><code>def __init__(\n    self,\n    lifecycle: JobLifecycleManager,\n    registry: EmbeddingModelRegistry,\n    namespace_registry: EmbeddingNamespaceRegistry,\n    policy: NamespaceAccessPolicy,\n    persister: EmbeddingPersister,\n    telemetry: EmbeddingTelemetry | None,\n    config: CoordinatorConfig,\n) -&gt; None:\n    \"\"\"Initialize the embedding coordinator with required dependencies.\n\n    Args:\n        lifecycle: Manager for tracking job lifecycle and metadata.\n        registry: Registry for embedding model selection and configuration.\n        namespace_registry: Registry for namespace-specific configuration.\n        policy: Policy engine for namespace access control evaluation.\n        persister: Service for persisting generated embeddings.\n        telemetry: Optional telemetry service for metrics emission.\n        config: Coordinator configuration settings.\n\n    Raises:\n        ValueError: If any required dependency is None.\n\n    Example:\n        &gt;&gt;&gt; coordinator = EmbeddingCoordinator(\n        ...     lifecycle=JobLifecycleManager(),\n        ...     registry=EmbeddingModelRegistry(),\n        ...     namespace_registry=EmbeddingNamespaceRegistry(),\n        ...     policy=NamespaceAccessPolicy(),\n        ...     persister=EmbeddingPersister(),\n        ...     telemetry=EmbeddingTelemetry(),\n        ...     config=CoordinatorConfig(name=\"embedding\")\n        ... )\n    \"\"\"\n    from .base import CoordinatorMetrics\n\n    super().__init__(config=config, metrics=CoordinatorMetrics.create(config.name))\n    self._lifecycle = lifecycle\n    self._registry = registry\n    self._namespace_registry = namespace_registry\n    self._policy = policy\n    self._persister = persister\n    self._telemetry = telemetry\n</code></pre>"},{"location":"api/coordinators/#base-coordinator","title":"Base Coordinator","text":"<p>The base coordinator abstractions define the common interface and configuration for all coordinators.</p>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.base.CoordinatorConfig","title":"<code>Medical_KG_rev.gateway.coordinators.base.CoordinatorConfig(name: str, retry_attempts: int = 3, retry_wait_base: float = 0.2, retry_wait_max: float = 2.0, breaker: CircuitBreaker | None = None, limiter: AsyncLimiter | None = None)</code>  <code>dataclass</code>","text":"<p>Runtime configuration for coordinator behavior and resilience.</p> <p>This class encapsulates all configuration parameters that control coordinator behavior, including retry logic, circuit breaker settings, and rate limiting configuration.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Unique name identifier for the coordinator.</p> <code>retry_attempts</code> <code>int</code> <p>Maximum number of retry attempts for failed operations.</p> <code>retry_wait_base</code> <code>float</code> <p>Base wait time in seconds for exponential backoff.</p> <code>retry_wait_max</code> <code>float</code> <p>Maximum wait time in seconds for exponential backoff.</p> <code>breaker</code> <code>CircuitBreaker | None</code> <p>Optional circuit breaker for failure protection.</p> <code>limiter</code> <code>AsyncLimiter | None</code> <p>Optional rate limiter for request throttling.</p> Invariants <ul> <li>name is never None or empty</li> <li>retry_attempts is positive</li> <li>retry_wait_base is non-negative</li> <li>retry_wait_max is greater than retry_wait_base</li> </ul> Thread Safety <ul> <li>Immutable after construction</li> <li>Safe for concurrent access</li> </ul> Lifecycle <ul> <li>Created during coordinator initialization</li> <li>Used throughout coordinator lifetime</li> <li>Not modified after creation</li> </ul> Example <p>config = CoordinatorConfig( ...     name=\"my_coordinator\", ...     retry_attempts=5, ...     retry_wait_base=0.1, ...     retry_wait_max=5.0 ... ) retrying = config.build_retrying()</p>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.base.CoordinatorConfig.build_retrying","title":"<code>build_retrying() -&gt; Retrying</code>","text":"<p>Build Retrying instance configured with exponential backoff.</p> <p>This method creates a tenacity Retrying instance configured with the coordinator's retry parameters, implementing exponential backoff with jitter for resilient operation handling.</p> <p>Returns:</p> Type Description <code>Retrying</code> <p>Retrying instance configured with stop and wait strategies.</p> Example <p>config = CoordinatorConfig(name=\"test\", retry_attempts=3) retrying = config.build_retrying()</p> Source code in <code>src/Medical_KG_rev/gateway/coordinators/base.py</code> <pre><code>def build_retrying(self) -&gt; Retrying:\n    \"\"\"Build Retrying instance configured with exponential backoff.\n\n    This method creates a tenacity Retrying instance configured with\n    the coordinator's retry parameters, implementing exponential\n    backoff with jitter for resilient operation handling.\n\n    Returns:\n        Retrying instance configured with stop and wait strategies.\n\n    Example:\n        &gt;&gt;&gt; config = CoordinatorConfig(name=\"test\", retry_attempts=3)\n        &gt;&gt;&gt; retrying = config.build_retrying()\n        &gt;&gt;&gt; # Use retrying.call() to execute operations with retry logic\n    \"\"\"\n    return Retrying(\n        stop=stop_after_attempt(self.retry_attempts),\n        wait=wait_exponential(\n            multiplier=self.retry_wait_base,\n            max=self.retry_wait_max,\n        ),\n        reraise=True,\n    )\n</code></pre>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.base.CoordinatorConfig.build_retrying--use-retryingcall-to-execute-operations-with-retry-logic","title":"Use retrying.call() to execute operations with retry logic","text":""},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.base.CoordinatorRequest","title":"<code>Medical_KG_rev.gateway.coordinators.base.CoordinatorRequest(tenant_id: str, correlation_id: str | None = None, metadata: Mapping[str, Any] | None = None)</code>  <code>dataclass</code>","text":"<p>Base class for strongly typed coordinator requests.</p> <p>This class serves as a marker base class for all coordinator request types, providing common fields for tenant identification, correlation tracking, and metadata storage.</p> <p>Attributes:</p> Name Type Description <code>tenant_id</code> <code>str</code> <p>Unique identifier for the tenant making the request.</p> <code>correlation_id</code> <code>str | None</code> <p>Optional correlation ID for request tracing.</p> <code>metadata</code> <code>Mapping[str, Any] | None</code> <p>Optional mapping of additional request metadata.</p> Invariants <ul> <li>tenant_id is never None or empty</li> <li>correlation_id is None or non-empty string</li> <li>metadata is None or non-empty mapping</li> </ul> Thread Safety <ul> <li>Immutable after construction (dataclass with frozen=True would be ideal)</li> <li>Safe for concurrent access if not modified</li> </ul> Lifecycle <ul> <li>Created by gateway service layer</li> <li>Passed to coordinator for processing</li> <li>Not modified during processing</li> </ul> Example <p>request = CoordinatorRequest( ...     tenant_id=\"tenant1\", ...     correlation_id=\"req-123\", ...     metadata={\"source\": \"api\", \"priority\": \"high\"} ... ) print(f\"Processing request for tenant: {request.tenant_id}\")</p>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.base.CoordinatorResult","title":"<code>Medical_KG_rev.gateway.coordinators.base.CoordinatorResult(job_id: str, duration_s: float, metadata: Mapping[str, Any] = dict())</code>  <code>dataclass</code>","text":"<p>Base class for typed coordinator results.</p> <p>This class serves as a base class for all coordinator result types, providing common fields for job tracking, performance metrics, and result metadata.</p> <p>Attributes:</p> Name Type Description <code>job_id</code> <code>str</code> <p>Unique identifier for the coordinator job.</p> <code>duration_s</code> <code>float</code> <p>Duration of the coordinator operation in seconds.</p> <code>metadata</code> <code>Mapping[str, Any]</code> <p>Additional result metadata and context.</p> Invariants <ul> <li>job_id is never None or empty</li> <li>duration_s is non-negative</li> <li>metadata is never None (defaults to empty dict)</li> </ul> Thread Safety <ul> <li>Immutable after construction</li> <li>Safe for concurrent access</li> </ul> Lifecycle <ul> <li>Created by coordinator after successful operation</li> <li>Returned to gateway service layer</li> <li>Used for logging and metrics collection</li> </ul> Example <p>result = CoordinatorResult( ...     job_id=\"job-123\", ...     duration_s=1.5, ...     metadata={\"status\": \"success\", \"items_processed\": 42} ... ) print(f\"Job {result.job_id} completed in {result.duration_s}s\")</p>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.base.BaseCoordinator","title":"<code>Medical_KG_rev.gateway.coordinators.base.BaseCoordinator(config: CoordinatorConfig, metrics: CoordinatorMetrics)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[_RequestT, _ResultT]</code></p> <p>Abstract base class for all gateway coordinators.</p> <p>This class provides the common infrastructure for all coordinators, including retry logic, circuit breaker protection, rate limiting, metrics collection, and error handling. Concrete coordinators must implement the _execute method to perform their specific business logic.</p> <p>The base coordinator handles all resilience concerns transparently, allowing concrete coordinators to focus on their core functionality while benefiting from automatic retry, circuit breaking, and metrics.</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>CoordinatorConfig</code> <p>Coordinator configuration including retry and resilience settings.</p> <code>metrics</code> <code>CoordinatorMetrics</code> <p>Prometheus metrics for tracking coordinator operations.</p> Invariants <ul> <li>config is never None</li> <li>metrics is never None</li> <li>_retrying is initialized in post_init</li> <li>All public methods maintain consistent error handling</li> </ul> Thread Safety <ul> <li>Thread-safe for concurrent operations</li> <li>Metrics collection is thread-safe</li> <li>Circuit breaker and rate limiter are thread-safe</li> </ul> Lifecycle <ul> <li>Created with config and metrics</li> <li>post_init initializes retry and resilience components</li> <li>Used via call method for request processing</li> <li>No explicit cleanup required</li> </ul> Example <p>class MyCoordinator(BaseCoordinator[MyRequest, MyResult]): ...     def _execute(self, request: MyRequest, **kwargs) -&gt; MyResult: ...         # Implement coordinator logic ...         return MyResult(job_id=\"123\", duration_s=1.0) coordinator = MyCoordinator( ...     config=CoordinatorConfig(name=\"my_coordinator\"), ...     metrics=CoordinatorMetrics.create(\"my_coordinator\") ... ) result = coordinator(MyRequest(tenant_id=\"tenant1\"))</p>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.base.BaseCoordinator.__call__","title":"<code>__call__(request: _RequestT, /, **kwargs: Any) -&gt; _ResultT</code>","text":"<p>Execute coordinator operation with full resilience and metrics.</p> <p>This method serves as the main entry point for coordinator operations, providing automatic retry logic, circuit breaker protection, rate limiting, metrics collection, and comprehensive error handling.</p> <p>The method coordinates between the various resilience components: 1. Logs operation start with request details 2. Times the operation using metrics histogram 3. Delegates to _execute_with_guards for resilience logic 4. Collects success/failure metrics 5. Logs operation completion or failure</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>_RequestT</code> <p>The coordinator request to process.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to _execute method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>_ResultT</code> <p>Coordinator result containing operation outcome and metadata.</p> <p>Raises:</p> Type Description <code>CoordinatorError</code> <p>If operation fails after all retry attempts.</p> Example <p>result = coordinator(request) print(f\"Operation completed in {result.duration_s}s\")</p> Source code in <code>src/Medical_KG_rev/gateway/coordinators/base.py</code> <pre><code>def __call__(self, request: _RequestT, /, **kwargs: Any) -&gt; _ResultT:\n    \"\"\"Execute coordinator operation with full resilience and metrics.\n\n    This method serves as the main entry point for coordinator operations,\n    providing automatic retry logic, circuit breaker protection, rate limiting,\n    metrics collection, and comprehensive error handling.\n\n    The method coordinates between the various resilience components:\n    1. Logs operation start with request details\n    2. Times the operation using metrics histogram\n    3. Delegates to _execute_with_guards for resilience logic\n    4. Collects success/failure metrics\n    5. Logs operation completion or failure\n\n    Args:\n        request: The coordinator request to process.\n        **kwargs: Additional keyword arguments passed to _execute method.\n\n    Returns:\n        Coordinator result containing operation outcome and metadata.\n\n    Raises:\n        CoordinatorError: If operation fails after all retry attempts.\n\n    Example:\n        &gt;&gt;&gt; result = coordinator(request)\n        &gt;&gt;&gt; print(f\"Operation completed in {result.duration_s}s\")\n    \"\"\"\n    logger.debug(\n        \"gateway.coordinator.invoke\",\n        coordinator=self.config.name,\n        tenant_id=request.tenant_id,\n        correlation_id=request.correlation_id,\n    )\n    start = time.perf_counter()\n    error: Exception | None = None\n    try:\n        with self.metrics.duration.time():\n            result = self._execute_with_guards(request, **kwargs)\n        return result\n    except Exception as exc:  # pragma: no cover - defensive logging\n        error = exc\n        raise\n    finally:\n        duration = time.perf_counter() - start\n        self.metrics.attempts.inc()\n        if error is not None:\n            self.metrics.failures.inc()\n            logger.warning(\n                \"gateway.coordinator.failed\",\n                coordinator=self.config.name,\n                tenant_id=request.tenant_id,\n                correlation_id=request.correlation_id,\n                error=str(error),\n                duration=duration,\n            )\n        else:\n            logger.info(\n                \"gateway.coordinator.completed\",\n                coordinator=self.config.name,\n                tenant_id=request.tenant_id,\n                correlation_id=request.correlation_id,\n                duration=duration,\n            )\n</code></pre>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.base.BaseCoordinator.__post_init__","title":"<code>__post_init__() -&gt; None</code>","text":"<p>Initialize coordinator resilience components after dataclass construction.</p> <p>This method is called automatically after dataclass construction to set up the retry logic, rate limiter, and circuit breaker components based on the coordinator configuration.</p> Example <p>coordinator = MyCoordinator(config=config, metrics=metrics)</p> Source code in <code>src/Medical_KG_rev/gateway/coordinators/base.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Initialize coordinator resilience components after dataclass construction.\n\n    This method is called automatically after dataclass construction to\n    set up the retry logic, rate limiter, and circuit breaker components\n    based on the coordinator configuration.\n\n    Example:\n        &gt;&gt;&gt; coordinator = MyCoordinator(config=config, metrics=metrics)\n        &gt;&gt;&gt; # __post_init__ is called automatically\n        &gt;&gt;&gt; assert coordinator._retrying is not None\n    \"\"\"\n    self._retrying = self.config.build_retrying()\n    self._limiter = self.config.limiter\n    self._breaker = self.config.breaker\n</code></pre>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.base.BaseCoordinator.__post_init__--post_init-is-called-automatically","title":"post_init is called automatically","text":"<p>assert coordinator._retrying is not None</p>"},{"location":"api/coordinators/#job-lifecycle-manager","title":"Job Lifecycle Manager","text":"<p>The <code>JobLifecycleManager</code> tracks job states and publishes SSE events for real-time status updates.</p>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager","title":"<code>Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager(ledger: JobLedger, events: EventStreamManager, pipeline_name: str = 'gateway-direct', pipeline_version: str = 'v1', retry_attempts: int = 3, retry_wait_base: float = 0.1, retry_wait_max: float = 1.0)</code>  <code>dataclass</code>","text":"<p>Manages job lifecycle operations with ledger persistence and SSE events.</p> <p>This class provides a high-level interface for managing job state transitions in the gateway coordinator system. It coordinates between the job ledger for persistence and the event stream manager for real-time updates.</p> <p>The manager handles job creation, state transitions (processing, completed, failed, cancelled), metadata updates, and automatic retry logic for ledger operations. All state changes trigger corresponding SSE events for real-time monitoring and client updates.</p> <p>Attributes:</p> Name Type Description <code>ledger</code> <code>JobLedger</code> <p>JobLedger instance for job persistence and state management.</p> <code>events</code> <code>EventStreamManager</code> <p>EventStreamManager instance for SSE event publishing.</p> <code>pipeline_name</code> <code>str</code> <p>Name of the pipeline processing jobs (default: \"gateway-direct\").</p> <code>pipeline_version</code> <code>str</code> <p>Version of the pipeline (default: \"v1\").</p> <code>retry_attempts</code> <code>int</code> <p>Maximum number of retry attempts for ledger operations.</p> <code>retry_wait_base</code> <code>float</code> <p>Base wait time in seconds for exponential backoff.</p> <code>retry_wait_max</code> <code>float</code> <p>Maximum wait time in seconds for exponential backoff.</p> <code>_retrying</code> <code>Retrying</code> <p>Retrying instance for ledger operation retry logic.</p> Invariants <ul> <li>ledger is never None</li> <li>events is never None</li> <li>pipeline_name is never None or empty</li> <li>pipeline_version is never None or empty</li> <li>retry_attempts is positive</li> <li>retry_wait_base is non-negative</li> <li>retry_wait_max is greater than retry_wait_base</li> <li>_retrying is initialized in post_init</li> </ul> Thread Safety <ul> <li>Thread-safe for concurrent operations</li> <li>Ledger operations are atomic</li> <li>SSE event publishing is thread-safe</li> </ul> Lifecycle <ul> <li>Created with ledger and events dependencies</li> <li>post_init initializes retry logic</li> <li>Used by coordinators for job management</li> <li>No explicit cleanup required</li> </ul> Example <p>manager = JobLifecycleManager( ...     ledger=JobLedger(), ...     events=EventStreamManager(), ...     pipeline_name=\"embedding-pipeline\", ...     pipeline_version=\"v2\" ... ) job_id = manager.create_job(\"tenant1\", \"embed\", metadata={\"model\": \"bert\"}) manager.mark_completed(job_id, {\"embeddings\": 100})</p>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager.__post_init__","title":"<code>__post_init__() -&gt; None</code>","text":"<p>Initialize retry logic after dataclass construction.</p> <p>This method is called automatically after dataclass construction to set up the retry logic for ledger operations using exponential backoff with configurable parameters.</p> Example <p>manager = JobLifecycleManager(ledger=ledger, events=events)</p> Source code in <code>src/Medical_KG_rev/gateway/coordinators/job_lifecycle.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Initialize retry logic after dataclass construction.\n\n    This method is called automatically after dataclass construction to\n    set up the retry logic for ledger operations using exponential\n    backoff with configurable parameters.\n\n    Example:\n        &gt;&gt;&gt; manager = JobLifecycleManager(ledger=ledger, events=events)\n        &gt;&gt;&gt; # __post_init__ is called automatically\n        &gt;&gt;&gt; assert manager._retrying is not None\n    \"\"\"\n    self._retrying = Retrying(\n        stop=stop_after_attempt(self.retry_attempts),\n        wait=wait_exponential(\n            multiplier=self.retry_wait_base,\n            max=self.retry_wait_max,\n        ),\n        reraise=True,\n    )\n</code></pre>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager.__post_init__--post_init-is-called-automatically","title":"post_init is called automatically","text":"<p>assert manager._retrying is not None</p>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager.cancel","title":"<code>cancel(job_id: str, *, reason: str, metadata: Mapping[str, Any] | None = None) -&gt; None</code>","text":"<p>Cancel a job and emit cancellation SSE event.</p> <p>This method marks a job as cancelled in the ledger and publishes an SSE event to notify clients of the cancellation. The cancellation reason and optional metadata are included in both the ledger entry and the SSE event.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Unique identifier for the job to cancel.</p> required <code>reason</code> <code>str</code> <p>Human-readable reason for the cancellation.</p> required <code>metadata</code> <code>Mapping[str, Any] | None</code> <p>Optional metadata to include with the cancellation.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If ledger operations fail after retry attempts.</p> Example <p>manager.cancel( ...     \"job-123\", ...     reason=\"User requested cancellation\", ...     metadata={\"cancelled_by\": \"user\"} ... )</p> Source code in <code>src/Medical_KG_rev/gateway/coordinators/job_lifecycle.py</code> <pre><code>def cancel(\n    self,\n    job_id: str,\n    *,\n    reason: str,\n    metadata: Mapping[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"Cancel a job and emit cancellation SSE event.\n\n    This method marks a job as cancelled in the ledger\n    and publishes an SSE event to notify clients of the cancellation.\n    The cancellation reason and optional metadata are included\n    in both the ledger entry and the SSE event.\n\n    Args:\n        job_id: Unique identifier for the job to cancel.\n        reason: Human-readable reason for the cancellation.\n        metadata: Optional metadata to include with the cancellation.\n\n    Raises:\n        RuntimeError: If ledger operations fail after retry attempts.\n\n    Example:\n        &gt;&gt;&gt; manager.cancel(\n        ...     \"job-123\",\n        ...     reason=\"User requested cancellation\",\n        ...     metadata={\"cancelled_by\": \"user\"}\n        ... )\n        &gt;&gt;&gt; # Job is marked cancelled and SSE event is published\n    \"\"\"\n    payload = {\"reason\": reason, **dict(metadata or {})}\n    logger.info(\"gateway.job.cancel\", job_id=job_id, payload=payload)\n    self._call_ledger(self.ledger.mark_cancelled, job_id, reason=reason)\n    self.events.publish(JobEvent(job_id=job_id, type=\"jobs.cancelled\", payload=payload))\n</code></pre>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager.cancel--job-is-marked-cancelled-and-sse-event-is-published","title":"Job is marked cancelled and SSE event is published","text":""},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager.create_job","title":"<code>create_job(tenant_id: str, operation: str, *, metadata: Mapping[str, Any] | None = None, job_id: str | None = None) -&gt; str</code>","text":"<p>Create a new job entry and emit the initial SSE event.</p> <p>This method creates a new job in the ledger with a unique ID, marks it as processing, and publishes an SSE event to notify clients of the job start. The job ID can be provided or auto-generated if not specified.</p> <p>Parameters:</p> Name Type Description Default <code>tenant_id</code> <code>str</code> <p>Unique identifier for the tenant creating the job.</p> required <code>operation</code> <code>str</code> <p>The operation type being performed (e.g., \"embed\", \"chunk\").</p> required <code>metadata</code> <code>Mapping[str, Any] | None</code> <p>Optional metadata to attach to the job.</p> <code>None</code> <code>job_id</code> <code>str | None</code> <p>Optional custom job ID (auto-generated if not provided).</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The job ID (provided or generated) for the created job.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If ledger operations fail after retry attempts.</p> Example <p>job_id = manager.create_job( ...     tenant_id=\"tenant1\", ...     operation=\"embed\", ...     metadata={\"model\": \"bert\", \"texts\": 5} ... ) print(f\"Created job: {job_id}\")</p> Source code in <code>src/Medical_KG_rev/gateway/coordinators/job_lifecycle.py</code> <pre><code>def create_job(\n    self,\n    tenant_id: str,\n    operation: str,\n    *,\n    metadata: Mapping[str, Any] | None = None,\n    job_id: str | None = None,\n) -&gt; str:\n    \"\"\"Create a new job entry and emit the initial SSE event.\n\n    This method creates a new job in the ledger with a unique ID,\n    marks it as processing, and publishes an SSE event to notify\n    clients of the job start. The job ID can be provided or\n    auto-generated if not specified.\n\n    Args:\n        tenant_id: Unique identifier for the tenant creating the job.\n        operation: The operation type being performed (e.g., \"embed\", \"chunk\").\n        metadata: Optional metadata to attach to the job.\n        job_id: Optional custom job ID (auto-generated if not provided).\n\n    Returns:\n        The job ID (provided or generated) for the created job.\n\n    Raises:\n        RuntimeError: If ledger operations fail after retry attempts.\n\n    Example:\n        &gt;&gt;&gt; job_id = manager.create_job(\n        ...     tenant_id=\"tenant1\",\n        ...     operation=\"embed\",\n        ...     metadata={\"model\": \"bert\", \"texts\": 5}\n        ... )\n        &gt;&gt;&gt; print(f\"Created job: {job_id}\")\n    \"\"\"\n\n    job_id = job_id or f\"job-{uuid.uuid4().hex[:12]}\"\n    doc_key = f\"{operation}:{job_id}\"\n    payload = {\n        \"operation\": operation,\n        \"pipeline\": self.pipeline_name,\n        \"pipeline_version\": self.pipeline_version,\n    }\n    if metadata:\n        payload.update(dict(metadata))\n\n    logger.info(\n        \"gateway.job.create\",\n        tenant_id=tenant_id,\n        job_id=job_id,\n        operation=operation,\n    )\n    self._call_ledger(\n        self.ledger.create,\n        job_id=job_id,\n        doc_key=doc_key,\n        tenant_id=tenant_id,\n        pipeline=operation,\n        metadata=payload,\n    )\n    self._call_ledger(self.ledger.mark_processing, job_id, stage=operation)\n    self.events.publish(\n        JobEvent(job_id=job_id, type=\"jobs.started\", payload={\"operation\": operation})\n    )\n    return job_id\n</code></pre>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager.idempotent_create","title":"<code>idempotent_create(*, job_id: str, doc_key: str, tenant_id: str, pipeline: str, metadata: Mapping[str, Any]) -&gt; JobLedgerEntry</code>","text":"<p>Create a job entry idempotently, returning existing entry if present.</p> <p>This method creates a job entry in the ledger if it doesn't exist, or returns the existing entry if it does. This provides resilience against duplicate job creation attempts and supports job recovery scenarios.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Unique identifier for the job.</p> required <code>doc_key</code> <code>str</code> <p>Document key for the job entry.</p> required <code>tenant_id</code> <code>str</code> <p>Unique identifier for the tenant.</p> required <code>pipeline</code> <code>str</code> <p>Pipeline name processing the job.</p> required <code>metadata</code> <code>Mapping[str, Any]</code> <p>Metadata to attach to the job.</p> required <p>Returns:</p> Type Description <code>JobLedgerEntry</code> <p>JobLedgerEntry representing the created or existing job.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If ledger operations fail after retry attempts.</p> Example <p>entry = manager.idempotent_create( ...     job_id=\"job-123\", ...     doc_key=\"embed:job-123\", ...     tenant_id=\"tenant1\", ...     pipeline=\"embedding\", ...     metadata={\"model\": \"bert\"} ... ) print(f\"Job status: {entry.status}\")</p> Source code in <code>src/Medical_KG_rev/gateway/coordinators/job_lifecycle.py</code> <pre><code>def idempotent_create(\n    self,\n    *,\n    job_id: str,\n    doc_key: str,\n    tenant_id: str,\n    pipeline: str,\n    metadata: Mapping[str, Any],\n) -&gt; JobLedgerEntry:\n    \"\"\"Create a job entry idempotently, returning existing entry if present.\n\n    This method creates a job entry in the ledger if it doesn't exist,\n    or returns the existing entry if it does. This provides resilience\n    against duplicate job creation attempts and supports job recovery\n    scenarios.\n\n    Args:\n        job_id: Unique identifier for the job.\n        doc_key: Document key for the job entry.\n        tenant_id: Unique identifier for the tenant.\n        pipeline: Pipeline name processing the job.\n        metadata: Metadata to attach to the job.\n\n    Returns:\n        JobLedgerEntry representing the created or existing job.\n\n    Raises:\n        RuntimeError: If ledger operations fail after retry attempts.\n\n    Example:\n        &gt;&gt;&gt; entry = manager.idempotent_create(\n        ...     job_id=\"job-123\",\n        ...     doc_key=\"embed:job-123\",\n        ...     tenant_id=\"tenant1\",\n        ...     pipeline=\"embedding\",\n        ...     metadata={\"model\": \"bert\"}\n        ... )\n        &gt;&gt;&gt; print(f\"Job status: {entry.status}\")\n    \"\"\"\n    logger.info(\n        \"gateway.job.idempotent_create\",\n        job_id=job_id,\n        doc_key=doc_key,\n        pipeline=pipeline,\n    )\n    return self._call_ledger(\n        self.ledger.idempotent_create,\n        job_id=job_id,\n        doc_key=doc_key,\n        tenant_id=tenant_id,\n        pipeline=pipeline,\n        metadata=dict(metadata),\n    )\n</code></pre>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager.mark_completed","title":"<code>mark_completed(job_id: str, payload: Mapping[str, Any] | None = None) -&gt; None</code>","text":"<p>Mark a job as completed and emit completion SSE event.</p> <p>This method updates the job status to completed in the ledger and publishes an SSE event to notify clients of the completion. Optional payload data can be included in the completion event.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Unique identifier for the job to mark as completed.</p> required <code>payload</code> <code>Mapping[str, Any] | None</code> <p>Optional payload data to include in the completion event.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If ledger operations fail after retry attempts.</p> Example <p>manager.mark_completed(\"job-123\", {\"embeddings\": 100, \"duration\": 5.2})</p> Source code in <code>src/Medical_KG_rev/gateway/coordinators/job_lifecycle.py</code> <pre><code>def mark_completed(self, job_id: str, payload: Mapping[str, Any] | None = None) -&gt; None:\n    \"\"\"Mark a job as completed and emit completion SSE event.\n\n    This method updates the job status to completed in the ledger\n    and publishes an SSE event to notify clients of the completion.\n    Optional payload data can be included in the completion event.\n\n    Args:\n        job_id: Unique identifier for the job to mark as completed.\n        payload: Optional payload data to include in the completion event.\n\n    Raises:\n        RuntimeError: If ledger operations fail after retry attempts.\n\n    Example:\n        &gt;&gt;&gt; manager.mark_completed(\"job-123\", {\"embeddings\": 100, \"duration\": 5.2})\n        &gt;&gt;&gt; # Job is marked completed and SSE event is published\n    \"\"\"\n    metadata = dict(payload or {})\n    logger.info(\"gateway.job.complete\", job_id=job_id, metadata=metadata)\n    self._call_ledger(self.ledger.mark_completed, job_id, metadata=metadata)\n    self.events.publish(\n        JobEvent(job_id=job_id, type=\"jobs.completed\", payload=metadata)\n    )\n</code></pre>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager.mark_completed--job-is-marked-completed-and-sse-event-is-published","title":"Job is marked completed and SSE event is published","text":""},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager.mark_failed","title":"<code>mark_failed(job_id: str, *, reason: str, stage: str = 'error', metadata: Mapping[str, Any] | None = None) -&gt; None</code>","text":"<p>Mark a job as failed and emit failure SSE event.</p> <p>This method updates the job status to failed in the ledger and publishes an SSE event to notify clients of the failure. The failure reason and optional metadata are included in both the ledger entry and the SSE event.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Unique identifier for the job to mark as failed.</p> required <code>reason</code> <code>str</code> <p>Human-readable reason for the failure.</p> required <code>stage</code> <code>str</code> <p>Stage where the failure occurred (default: \"error\").</p> <code>'error'</code> <code>metadata</code> <code>Mapping[str, Any] | None</code> <p>Optional metadata to include with the failure.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If ledger operations fail after retry attempts.</p> Example <p>manager.mark_failed( ...     \"job-123\", ...     reason=\"Model loading failed\", ...     stage=\"initialization\", ...     metadata={\"error_code\": \"MODEL_NOT_FOUND\"} ... )</p> Source code in <code>src/Medical_KG_rev/gateway/coordinators/job_lifecycle.py</code> <pre><code>def mark_failed(\n    self,\n    job_id: str,\n    *,\n    reason: str,\n    stage: str = \"error\",\n    metadata: Mapping[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"Mark a job as failed and emit failure SSE event.\n\n    This method updates the job status to failed in the ledger\n    and publishes an SSE event to notify clients of the failure.\n    The failure reason and optional metadata are included in\n    both the ledger entry and the SSE event.\n\n    Args:\n        job_id: Unique identifier for the job to mark as failed.\n        reason: Human-readable reason for the failure.\n        stage: Stage where the failure occurred (default: \"error\").\n        metadata: Optional metadata to include with the failure.\n\n    Raises:\n        RuntimeError: If ledger operations fail after retry attempts.\n\n    Example:\n        &gt;&gt;&gt; manager.mark_failed(\n        ...     \"job-123\",\n        ...     reason=\"Model loading failed\",\n        ...     stage=\"initialization\",\n        ...     metadata={\"error_code\": \"MODEL_NOT_FOUND\"}\n        ... )\n        &gt;&gt;&gt; # Job is marked failed and SSE event is published\n    \"\"\"\n    payload = {\"reason\": reason, **dict(metadata or {})}\n    logger.warning(\n        \"gateway.job.fail\",\n        job_id=job_id,\n        reason=reason,\n        stage=stage,\n        metadata=payload,\n    )\n    self._call_ledger(\n        self.ledger.mark_failed,\n        job_id,\n        stage=stage,\n        reason=reason,\n        metadata=dict(metadata or {}),\n    )\n    self.events.publish(JobEvent(job_id=job_id, type=\"jobs.failed\", payload=payload))\n</code></pre>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager.mark_failed--job-is-marked-failed-and-sse-event-is-published","title":"Job is marked failed and SSE event is published","text":""},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager.update_metadata","title":"<code>update_metadata(job_id: str, metadata: Mapping[str, Any]) -&gt; None</code>","text":"<p>Update job metadata in the ledger.</p> <p>This method updates the metadata associated with a job in the ledger. This is useful for tracking progress, intermediate results, or other job-specific information during processing.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Unique identifier for the job to update.</p> required <code>metadata</code> <code>Mapping[str, Any]</code> <p>New metadata to associate with the job.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If ledger operations fail after retry attempts.</p> Example <p>manager.update_metadata(\"job-123\", {\"progress\": 50, \"processed\": 25})</p> Source code in <code>src/Medical_KG_rev/gateway/coordinators/job_lifecycle.py</code> <pre><code>def update_metadata(self, job_id: str, metadata: Mapping[str, Any]) -&gt; None:\n    \"\"\"Update job metadata in the ledger.\n\n    This method updates the metadata associated with a job in the ledger.\n    This is useful for tracking progress, intermediate results, or other\n    job-specific information during processing.\n\n    Args:\n        job_id: Unique identifier for the job to update.\n        metadata: New metadata to associate with the job.\n\n    Raises:\n        RuntimeError: If ledger operations fail after retry attempts.\n\n    Example:\n        &gt;&gt;&gt; manager.update_metadata(\"job-123\", {\"progress\": 50, \"processed\": 25})\n        &gt;&gt;&gt; # Job metadata is updated in the ledger\n    \"\"\"\n    logger.debug(\"gateway.job.metadata\", job_id=job_id, metadata=dict(metadata))\n    self._call_ledger(self.ledger.update_metadata, job_id, dict(metadata))\n</code></pre>"},{"location":"api/coordinators/#Medical_KG_rev.gateway.coordinators.job_lifecycle.JobLifecycleManager.update_metadata--job-metadata-is-updated-in-the-ledger","title":"Job metadata is updated in the ledger","text":""},{"location":"api/embedding/","title":"Embedding API","text":"<p>The embedding services provide policy enforcement, namespace management, persistence, and telemetry for embedding operations.</p>"},{"location":"api/embedding/#evaluation-test-sets","title":"Evaluation Test Sets","text":"<p>Utilities for loading and validating evaluation test sets.</p>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.QueryType","title":"<code>Medical_KG_rev.services.evaluation.test_sets.QueryType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of supported query intents used for stratification.</p> <p>This enumeration defines the different types of queries used in evaluation test sets, enabling stratified sampling and analysis of retrieval performance across different query types.</p> Values <p>EXACT_TERM: Queries using exact medical terminology PARAPHRASE: Queries using paraphrased or alternative terms COMPLEX_CLINICAL: Complex clinical scenario queries</p> Thread Safety <p>Enum values are immutable and thread-safe.</p> <p>Examples:</p> <p>query_type = QueryType.EXACT_TERM if query_type == QueryType.COMPLEX_CLINICAL:     # Handle complex clinical query</p>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.QueryJudgment","title":"<code>Medical_KG_rev.services.evaluation.test_sets.QueryJudgment(query_id: str, query_text: str, query_type: QueryType, relevant_docs: tuple[tuple[str, float], ...], metadata: Mapping[str, object] = dict())</code>  <code>dataclass</code>","text":"<p>Single query with graded relevance labels.</p> <p>This dataclass represents a single query with its associated relevance judgments for evaluation purposes. It provides methods for accessing relevance information and validation.</p> <p>Attributes:</p> Name Type Description <code>query_id</code> <code>str</code> <p>Unique identifier for the query</p> <code>query_text</code> <code>str</code> <p>The query text</p> <code>query_type</code> <code>QueryType</code> <p>Type of query for stratification</p> <code>relevant_docs</code> <code>tuple[tuple[str, float], ...]</code> <p>Tuple of (doc_id, relevance_grade) pairs</p> <code>metadata</code> <code>Mapping[str, object]</code> <p>Additional metadata for the query</p> Thread Safety <p>Immutable dataclass, thread-safe.</p> <p>Examples:</p> <p>judgment = QueryJudgment(     query_id=\"q1\",     query_text=\"diabetes treatment\",     query_type=QueryType.EXACT_TERM,     relevant_docs=((\"doc1\", 3.0), (\"doc2\", 2.0)) ) relevance_map = judgment.as_relevance_mapping()</p>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.QueryJudgment.as_relevance_mapping","title":"<code>as_relevance_mapping() -&gt; dict[str, float]</code>","text":"<p>Convert relevant documents to a mapping.</p> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>Dictionary mapping document IDs to relevance grades</p> <p>Raises:</p> Type Description <code>None</code> <p>This method never raises exceptions.</p> Source code in <code>src/Medical_KG_rev/services/evaluation/test_sets.py</code> <pre><code>def as_relevance_mapping(self) -&gt; dict[str, float]:\n    \"\"\"Convert relevant documents to a mapping.\n\n    Returns:\n        Dictionary mapping document IDs to relevance grades\n\n    Raises:\n        None: This method never raises exceptions.\n    \"\"\"\n    return {doc_id: float(grade) for doc_id, grade in self.relevant_docs}\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.QueryJudgment.has_relevant_document","title":"<code>has_relevant_document() -&gt; bool</code>","text":"<p>Check if the query has any relevant documents.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if any document has relevance grade &gt; 0</p> <p>Raises:</p> Type Description <code>None</code> <p>This method never raises exceptions.</p> Source code in <code>src/Medical_KG_rev/services/evaluation/test_sets.py</code> <pre><code>def has_relevant_document(self) -&gt; bool:\n    \"\"\"Check if the query has any relevant documents.\n\n    Returns:\n        True if any document has relevance grade &gt; 0\n\n    Raises:\n        None: This method never raises exceptions.\n    \"\"\"\n    return any(grade &gt; 0 for _, grade in self.relevant_docs)\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.TestSet","title":"<code>Medical_KG_rev.services.evaluation.test_sets.TestSet(name: str, version: str, queries: tuple[QueryJudgment, ...], source: Path | None = None)</code>  <code>dataclass</code>","text":"<p>In-memory representation of a retrieval evaluation dataset.</p> <p>This dataclass represents a complete evaluation test set with queries, relevance judgments, and metadata. It provides methods for stratification, splitting, validation, and serialization.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the test set</p> <code>version</code> <code>str</code> <p>Version identifier</p> <code>queries</code> <code>tuple[QueryJudgment, ...]</code> <p>Tuple of query judgments</p> <code>source</code> <code>Path | None</code> <p>Optional source file path</p> Thread Safety <p>Immutable dataclass, thread-safe.</p> <p>Examples:</p> <p>test_set = TestSet(     name=\"medical_queries\",     version=\"1.0\",     queries=(query1, query2, query3) ) eval_set, holdout_set = test_set.split(holdout_ratio=0.2)</p>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.TestSet.describe","title":"<code>describe() -&gt; dict[str, float]</code>","text":"<p>Generate descriptive statistics for the test set.</p> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>Dictionary mapping query types to counts</p> <p>Raises:</p> Type Description <code>None</code> <p>This method never raises exceptions.</p> Source code in <code>src/Medical_KG_rev/services/evaluation/test_sets.py</code> <pre><code>def describe(self) -&gt; dict[str, float]:\n    \"\"\"Generate descriptive statistics for the test set.\n\n    Returns:\n        Dictionary mapping query types to counts\n\n    Raises:\n        None: This method never raises exceptions.\n    \"\"\"\n    stratified = self.stratify()\n    return {key.value: float(len(bucket)) for key, bucket in stratified.items()}\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.TestSet.ensure_quality","title":"<code>ensure_quality() -&gt; None</code>","text":"<p>Validate schema constraints defined in the specification.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the test set fails quality validation</p> Source code in <code>src/Medical_KG_rev/services/evaluation/test_sets.py</code> <pre><code>def ensure_quality(self) -&gt; None:\n    \"\"\"Validate schema constraints defined in the specification.\n\n    Raises:\n        ValueError: If the test set fails quality validation\n    \"\"\"\n    ids = {query.query_id for query in self.queries}\n    if len(ids) != len(self.queries):\n        raise ValueError(\"Query identifiers must be unique\")\n    for query in self.queries:\n        if not query.query_text.strip():\n            raise ValueError(f\"Query '{query.query_id}' has empty text\")\n        if not query.has_relevant_document():\n            raise ValueError(f\"Query '{query.query_id}' is missing relevant documents\")\n        for doc_id, grade in query.relevant_docs:\n            if not doc_id:\n                raise ValueError(f\"Query '{query.query_id}' contains blank doc_id\")\n            if grade &lt; 0 or grade &gt; 3:\n                raise ValueError(\n                    f\"Query '{query.query_id}' has invalid grade {grade}; expected range 0-3\"\n                )\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.TestSet.split","title":"<code>split(*, holdout_ratio: float = 0.2, seed: int = 7) -&gt; tuple[TestSet, TestSet]</code>","text":"<p>Return (evaluation, hold-out) splits preserving stratification.</p> <p>Parameters:</p> Name Type Description Default <code>holdout_ratio</code> <code>float</code> <p>Fraction of queries to reserve for holdout</p> <code>0.2</code> <code>seed</code> <code>int</code> <p>Random seed for reproducible splits</p> <code>7</code> <p>Returns:</p> Type Description <code>tuple[TestSet, TestSet]</code> <p>Tuple of (evaluation_set, holdout_set)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If holdout_ratio is not between 0 and 1</p> Source code in <code>src/Medical_KG_rev/services/evaluation/test_sets.py</code> <pre><code>def split(self, *, holdout_ratio: float = 0.2, seed: int = 7) -&gt; tuple[TestSet, TestSet]:\n    \"\"\"Return (evaluation, hold-out) splits preserving stratification.\n\n    Args:\n        holdout_ratio: Fraction of queries to reserve for holdout\n        seed: Random seed for reproducible splits\n\n    Returns:\n        Tuple of (evaluation_set, holdout_set)\n\n    Raises:\n        ValueError: If holdout_ratio is not between 0 and 1\n    \"\"\"\n    if not 0 &lt; holdout_ratio &lt; 1:\n        raise ValueError(\"holdout_ratio must be between 0 and 1\")\n    rng = Random(seed)\n    evaluation: list[QueryJudgment] = []\n    holdout: list[QueryJudgment] = []\n    for _, bucket in self.stratify().items():\n        items = list(bucket)\n        rng.shuffle(items)\n        cutoff = max(1, int(len(items) * holdout_ratio)) if len(items) &gt; 1 else 0\n        holdout.extend(items[:cutoff])\n        evaluation.extend(items[cutoff:])\n    return (\n        TestSet(name=f\"{self.name}-eval\", version=self.version, queries=tuple(evaluation)),\n        TestSet(name=f\"{self.name}-holdout\", version=self.version, queries=tuple(holdout)),\n    )\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.TestSet.stratify","title":"<code>stratify() -&gt; dict[QueryType, tuple[QueryJudgment, ...]]</code>","text":"<p>Stratify queries by type.</p> <p>Returns:</p> Type Description <code>dict[QueryType, tuple[QueryJudgment, ...]]</code> <p>Dictionary mapping query types to query tuples</p> <p>Raises:</p> Type Description <code>None</code> <p>This method never raises exceptions.</p> Source code in <code>src/Medical_KG_rev/services/evaluation/test_sets.py</code> <pre><code>def stratify(self) -&gt; dict[QueryType, tuple[QueryJudgment, ...]]:\n    \"\"\"Stratify queries by type.\n\n    Returns:\n        Dictionary mapping query types to query tuples\n\n    Raises:\n        None: This method never raises exceptions.\n    \"\"\"\n    buckets: dict[QueryType, list[QueryJudgment]] = defaultdict(list)\n    for record in self.queries:\n        buckets[record.query_type].append(record)\n    return {key: tuple(value) for key, value in buckets.items()}\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.TestSet.to_payload","title":"<code>to_payload() -&gt; dict[str, object]</code>","text":"<p>Convert the test set to a serializable payload.</p> <p>Returns:</p> Type Description <code>dict[str, object]</code> <p>Dictionary representation suitable for serialization</p> <p>Raises:</p> Type Description <code>None</code> <p>This method never raises exceptions.</p> Source code in <code>src/Medical_KG_rev/services/evaluation/test_sets.py</code> <pre><code>def to_payload(self) -&gt; dict[str, object]:\n    \"\"\"Convert the test set to a serializable payload.\n\n    Returns:\n        Dictionary representation suitable for serialization\n\n    Raises:\n        None: This method never raises exceptions.\n    \"\"\"\n    return {\n        \"name\": self.name,\n        \"version\": self.version,\n        \"queries\": [\n            {\n                \"query_id\": query.query_id,\n                \"query_text\": query.query_text,\n                \"query_type\": query.query_type.value,\n                \"relevant_docs\": [\n                    {\"doc_id\": doc_id, \"grade\": grade} for doc_id, grade in query.relevant_docs\n                ],\n                \"metadata\": dict(query.metadata),\n            }\n            for query in self.queries\n        ],\n    }\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.TestSetManager","title":"<code>Medical_KG_rev.services.evaluation.test_sets.TestSetManager(root: str | Path | None = None)</code>","text":"<p>Loads and caches evaluation datasets stored on disk.</p> <p>This class provides a manager for loading and caching evaluation test sets from both filesystem and packaged resources. It supports version validation, quality checking, and efficient caching.</p> <p>Attributes:</p> Name Type Description <code>root</code> <p>Optional filesystem root for test sets</p> <code>_resource_root</code> <code>Traversable | None</code> <p>Packaged resource root for test sets</p> <code>_cache</code> <code>dict[tuple[str, str | None], TestSet]</code> <p>Cache of loaded test sets</p> Thread Safety <p>Thread-safe for concurrent access to cached test sets.</p> Performance <p>Efficient caching prevents repeated file I/O. Lazy loading of test set data.</p> <p>Examples:</p>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.TestSetManager--load-from-packaged-resources","title":"Load from packaged resources","text":"<p>manager = TestSetManager() test_set = manager.load(\"medical_queries\")</p>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.TestSetManager--load-from-filesystem","title":"Load from filesystem","text":"<p>manager = TestSetManager(root=\"/path/to/test_sets\") test_set = manager.load(\"custom_queries\")</p> <p>Initialize the test set manager.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>str | Path | None</code> <p>Optional filesystem root for test sets</p> <code>None</code> <p>Raises:</p> Type Description <code>None</code> <p>Initialization always succeeds.</p> Source code in <code>src/Medical_KG_rev/services/evaluation/test_sets.py</code> <pre><code>def __init__(self, root: str | Path | None = None) -&gt; None:\n    \"\"\"Initialize the test set manager.\n\n    Args:\n        root: Optional filesystem root for test sets\n\n    Raises:\n        None: Initialization always succeeds.\n    \"\"\"\n    self.root = Path(root) if root is not None else None\n    self._resource_root: Traversable | None\n    if self.root is None:\n        self._resource_root = (\n            resources.files(_DATA_PACKAGE) / _DEFAULT_DATASET_SUBDIR\n        )\n    else:\n        self._resource_root = None\n    self._cache: dict[tuple[str, str | None], TestSet] = {}\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.TestSetManager.load","title":"<code>load(name: str, *, expected_version: str | None = None) -&gt; TestSet</code>","text":"<p>Load a test set from storage.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the test set to load</p> required <code>expected_version</code> <code>str | None</code> <p>Optional expected version for validation</p> <code>None</code> <p>Returns:</p> Type Description <code>TestSet</code> <p>Loaded and validated test set</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the test set is not found</p> <code>ValueError</code> <p>If version validation fails</p> <code>ValueError</code> <p>If quality validation fails</p> Source code in <code>src/Medical_KG_rev/services/evaluation/test_sets.py</code> <pre><code>def load(self, name: str, *, expected_version: str | None = None) -&gt; TestSet:\n    \"\"\"Load a test set from storage.\n\n    Args:\n        name: Name of the test set to load\n        expected_version: Optional expected version for validation\n\n    Returns:\n        Loaded and validated test set\n\n    Raises:\n        FileNotFoundError: If the test set is not found\n        ValueError: If version validation fails\n        ValueError: If quality validation fails\n    \"\"\"\n    cache_key = (name, expected_version)\n    if cache_key in self._cache:\n        return self._cache[cache_key]\n    path = self._resolve_path(name)\n    raw = self._load_yaml(path)\n    version = str(raw.get(\"version\") or \"unknown\")\n    if expected_version is not None and version != expected_version:\n        raise ValueError(\n            f\"Requested version '{expected_version}' but file {path} declares version '{version}'\"\n        )\n    queries = _parse_queries(raw.get(\"queries\", []))\n    source_path = path if isinstance(path, Path) else None\n    test_set = TestSet(\n        name=name,\n        version=version,\n        queries=tuple(queries),\n        source=source_path,\n    )\n    test_set.ensure_quality()\n    self._cache[cache_key] = test_set\n    return test_set\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.services.evaluation.test_sets.TestSetManager.refresh","title":"<code>refresh(name: str, *, new_queries: Sequence[Mapping[str, object]], version: str) -&gt; TestSet</code>","text":"<p>Create a new version of a dataset replacing the cached entry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the test set</p> required <code>new_queries</code> <code>Sequence[Mapping[str, object]]</code> <p>New query data to replace existing queries</p> required <code>version</code> <code>str</code> <p>Version identifier for the new dataset</p> required <p>Returns:</p> Type Description <code>TestSet</code> <p>New test set with updated queries</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If manager was initialized without filesystem root</p> <code>ValueError</code> <p>If quality validation fails</p> <code>IOError</code> <p>If file writing fails</p> Source code in <code>src/Medical_KG_rev/services/evaluation/test_sets.py</code> <pre><code>def refresh(self, name: str, *, new_queries: Sequence[Mapping[str, object]], version: str) -&gt; TestSet:\n    \"\"\"Create a new version of a dataset replacing the cached entry.\n\n    Args:\n        name: Name of the test set\n        new_queries: New query data to replace existing queries\n        version: Version identifier for the new dataset\n\n    Returns:\n        New test set with updated queries\n\n    Raises:\n        RuntimeError: If manager was initialized without filesystem root\n        ValueError: If quality validation fails\n        IOError: If file writing fails\n    \"\"\"\n    if self.root is None:\n        raise RuntimeError(\n            \"Cannot refresh packaged datasets; provide a filesystem root when instantiating\"\n        )\n    latest = self.root / f\"{name}.yaml\"\n    archive = self.root / name / f\"{version}.yaml\"\n    archive.parent.mkdir(parents=True, exist_ok=True)\n    payload = {\"version\": version, \"queries\": list(new_queries)}\n    serialised = yaml.safe_dump(payload, sort_keys=False)\n    archive.write_text(serialised, encoding=\"utf-8\")\n    latest.write_text(serialised, encoding=\"utf-8\")\n    test_set = TestSet(name=name, version=version, queries=tuple(_parse_queries(new_queries)), source=archive)\n    test_set.ensure_quality()\n    self._cache[(name, version)] = test_set\n    self._cache[(name, None)] = test_set\n    return test_set\n</code></pre>"},{"location":"api/embedding/#test-mocks","title":"Test Mocks","text":"<p>Mock classes for testing embedding framework delegates.</p>"},{"location":"api/embedding/#Medical_KG_rev.embeddings.frameworks.test_mocks.BatchOnly","title":"<code>Medical_KG_rev.embeddings.frameworks.test_mocks.BatchOnly</code>","text":"<p>Mock embedding class that only supports batch embedding.</p> <p>This mock class simulates an embedding model that only supports batch embedding operations, returning deterministic embeddings based on text length.</p> Thread Safety <p>Thread-safe for testing purposes.</p> <p>Examples:</p> <p>embedder = BatchOnly() embeddings = embedder.embed_documents([\"text1\", \"text2\"])</p>"},{"location":"api/embedding/#Medical_KG_rev.embeddings.frameworks.test_mocks.BatchOnly--returns-30-30-30-30-30-30","title":"Returns: [[3.0, 3.0, 3.0], [3.0, 3.0, 3.0]]","text":""},{"location":"api/embedding/#Medical_KG_rev.embeddings.frameworks.test_mocks.BatchOnly.embed","title":"<code>embed(texts)</code>","text":"<p>Embed multiple texts (alias for embed_documents).</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <p>List of text strings to embed</p> required <p>Returns:</p> Type Description <p>List of embedding vectors</p> Source code in <code>src/Medical_KG_rev/embeddings/frameworks/test_mocks.py</code> <pre><code>def embed(self, texts):  # pragma: no cover - invoked via delegate helper\n    \"\"\"Embed multiple texts (alias for embed_documents).\n\n    Args:\n        texts: List of text strings to embed\n\n    Returns:\n        List of embedding vectors\n    \"\"\"\n    return [[float(len(text))] * 3 for text in texts]\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.embeddings.frameworks.test_mocks.BatchOnly.embed_documents","title":"<code>embed_documents(texts)</code>","text":"<p>Embed multiple documents in batch.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <p>List of text strings to embed</p> required <p>Returns:</p> Type Description <p>List of embedding vectors</p> Source code in <code>src/Medical_KG_rev/embeddings/frameworks/test_mocks.py</code> <pre><code>def embed_documents(self, texts):  # pragma: no cover - invoked via delegate helper\n    \"\"\"Embed multiple documents in batch.\n\n    Args:\n        texts: List of text strings to embed\n\n    Returns:\n        List of embedding vectors\n    \"\"\"\n    return [[float(len(text))] * 3 for text in texts]\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.embeddings.frameworks.test_mocks.QueryOnly","title":"<code>Medical_KG_rev.embeddings.frameworks.test_mocks.QueryOnly()</code>","text":"<p>Mock embedding class that only supports query embedding.</p> <p>This mock class simulates an embedding model that only supports query embedding operations, with call tracking for verification.</p> <p>Attributes:</p> Name Type Description <code>calls</code> <code>list[str]</code> <p>List of texts that have been embedded</p> Thread Safety <p>Thread-safe for testing purposes.</p> <p>Examples:</p> <p>embedder = QueryOnly() embedding = embedder.embed_query(\"test\") assert \"test\" in embedder.calls</p> <p>Initialize the query-only embedder.</p> <p>Raises:</p> Type Description <code>None</code> <p>Initialization always succeeds.</p> Source code in <code>src/Medical_KG_rev/embeddings/frameworks/test_mocks.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the query-only embedder.\n\n    Raises:\n        None: Initialization always succeeds.\n    \"\"\"\n    self.calls: list[str] = []\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.embeddings.frameworks.test_mocks.QueryOnly.embed_queries","title":"<code>embed_queries(texts)</code>","text":"<p>Embed multiple query texts.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <p>List of query texts to embed</p> required <p>Returns:</p> Type Description <p>List of embedding vectors</p> Source code in <code>src/Medical_KG_rev/embeddings/frameworks/test_mocks.py</code> <pre><code>def embed_queries(self, texts):  # pragma: no cover - invoked via delegate helper\n    \"\"\"Embed multiple query texts.\n\n    Args:\n        texts: List of query texts to embed\n\n    Returns:\n        List of embedding vectors\n    \"\"\"\n    self.calls.extend(texts)\n    return [[float(len(text)), float(len(text)) + 1.0] for text in texts]\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.embeddings.frameworks.test_mocks.QueryOnly.embed_query","title":"<code>embed_query(text)</code>","text":"<p>Embed a single query text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>Query text to embed</p> required <p>Returns:</p> Type Description <p>Embedding vector</p> Source code in <code>src/Medical_KG_rev/embeddings/frameworks/test_mocks.py</code> <pre><code>def embed_query(self, text):  # pragma: no cover - invoked via delegate helper\n    \"\"\"Embed a single query text.\n\n    Args:\n        text: Query text to embed\n\n    Returns:\n        Embedding vector\n    \"\"\"\n    self.calls.append(text)\n    length = float(len(text))\n    return [length, length + 1.0]\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.embeddings.frameworks.test_mocks.LlamaStyle","title":"<code>Medical_KG_rev.embeddings.frameworks.test_mocks.LlamaStyle</code>","text":"<p>Mock embedding class with LlamaIndex-style interface.</p> <p>This mock class simulates an embedding model with LlamaIndex-style interface, supporting both single and batch operations.</p> Thread Safety <p>Thread-safe for testing purposes.</p> <p>Examples:</p> <p>embedder = LlamaStyle() embedding = embedder.get_text_embedding(\"test\")</p>"},{"location":"api/embedding/#Medical_KG_rev.embeddings.frameworks.test_mocks.LlamaStyle--returns-40-20-10","title":"Returns: [4.0, 2.0, 1.0]","text":""},{"location":"api/embedding/#Medical_KG_rev.embeddings.frameworks.test_mocks.LlamaStyle.embed","title":"<code>embed(texts)</code>","text":"<p>Embed multiple texts (alias for embed_documents).</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <p>List of text strings to embed</p> required <p>Returns:</p> Type Description <p>List of embedding vectors</p> Source code in <code>src/Medical_KG_rev/embeddings/frameworks/test_mocks.py</code> <pre><code>def embed(self, texts):  # pragma: no cover - invoked via delegate helper\n    \"\"\"Embed multiple texts (alias for embed_documents).\n\n    Args:\n        texts: List of text strings to embed\n\n    Returns:\n        List of embedding vectors\n    \"\"\"\n    return [[float(len(text)), float(len(text)) / 2.0, float(len(text)) / 4.0] for text in texts]\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.embeddings.frameworks.test_mocks.LlamaStyle.embed_documents","title":"<code>embed_documents(texts)</code>","text":"<p>Embed multiple documents in batch.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <p>List of text strings to embed</p> required <p>Returns:</p> Type Description <p>List of embedding vectors</p> Source code in <code>src/Medical_KG_rev/embeddings/frameworks/test_mocks.py</code> <pre><code>def embed_documents(self, texts):  # pragma: no cover - invoked via delegate helper\n    \"\"\"Embed multiple documents in batch.\n\n    Args:\n        texts: List of text strings to embed\n\n    Returns:\n        List of embedding vectors\n    \"\"\"\n    return [[float(len(text)), float(len(text)) / 2.0, float(len(text)) / 4.0] for text in texts]\n</code></pre>"},{"location":"api/embedding/#Medical_KG_rev.embeddings.frameworks.test_mocks.LlamaStyle.get_text_embedding","title":"<code>get_text_embedding(text)</code>","text":"<p>Get embedding for a single text (LlamaIndex style).</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>Text to embed</p> required <p>Returns:</p> Type Description <p>Embedding vector</p> Source code in <code>src/Medical_KG_rev/embeddings/frameworks/test_mocks.py</code> <pre><code>def get_text_embedding(self, text):  # pragma: no cover - invoked via delegate helper\n    \"\"\"Get embedding for a single text (LlamaIndex style).\n\n    Args:\n        text: Text to embed\n\n    Returns:\n        Embedding vector\n    \"\"\"\n    base = float(len(text))\n    return [base, base / 2.0, base / 4.0]\n</code></pre>"},{"location":"api/orchestration/","title":"Orchestration API","text":"<p>The orchestration modules provide stage-based pipeline execution with Dagster integration.</p>"},{"location":"api/orchestration/#built-in-stage-plugins","title":"Built-in Stage Plugins","text":"<p>Built-in stage plugin implementations for Dagster orchestration.</p>"},{"location":"api/orchestration/#Medical_KG_rev.orchestration.stages.plugins.builtin.CoreStagePlugin","title":"<code>Medical_KG_rev.orchestration.stages.plugins.builtin.CoreStagePlugin()</code>","text":"<p>               Bases: <code>StagePlugin</code></p> <p>Core stage plugin providing default ingest\u2192KG pipeline implementations.</p> <p>This plugin provides the standard stage implementations for the Medical_KG_rev pipeline, including ingest, parse, validation, chunking, embedding, indexing, and knowledge graph stages. It serves as the default plugin for most pipeline configurations.</p> <p>Attributes:</p> Name Type Description <code>_adapter_manager</code> <code>AdapterPluginManager | None</code> <p>Plugin manager for adapter instances</p> <code>_pipeline_resource</code> <code>HaystackPipelineResource | None</code> <p>Haystack pipeline resource for ML components</p> Thread Safety <p>Thread-safe once initialized. Stage instances created by this plugin should be stateless or thread-safe.</p> Lifecycle <ol> <li>Initialize with metadata</li> <li>Call initialise() with required dependencies</li> <li>Use health_check() to verify dependencies</li> <li>Create stages via create_stage()</li> </ol> <p>Examples:</p> <p>plugin = CoreStagePlugin() context = StagePluginContext({     \"adapter_manager\": adapter_manager,     \"haystack_pipeline\": pipeline_resource }) plugin.initialise(context) stage = plugin.create_stage(definition, context)</p> <p>Initialize the core stage plugin with metadata.</p> <p>Sets up the plugin metadata including supported stage types and description. Dependencies are initialized later via initialise().</p> <p>Raises:</p> Type Description <code>None</code> <p>Initialization always succeeds.</p> Source code in <code>src/Medical_KG_rev/orchestration/stages/plugins/builtin.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the core stage plugin with metadata.\n\n    Sets up the plugin metadata including supported stage types and\n    description. Dependencies are initialized later via initialise().\n\n    Raises:\n        None: Initialization always succeeds.\n    \"\"\"\n    super().__init__(\n        StagePluginMetadata(\n            name=\"core-stages\",\n            version=\"1.0.0\",\n            stage_types=(\n                \"ingest\",\n                \"parse\",\n                \"ir-validation\",\n                \"chunk\",\n                \"embed\",\n                \"index\",\n                \"extract\",\n                \"knowledge-graph\",\n                \"pdf-download\",\n                \"pdf-gate\",\n            ),\n            description=\"Built-in stage implementations\",\n        )\n    )\n    self._adapter_manager: AdapterPluginManager | None = None\n    self._pipeline_resource: HaystackPipelineResource | None = None\n</code></pre>"},{"location":"api/orchestration/#Medical_KG_rev.orchestration.stages.plugins.builtin.CoreStagePlugin.create_stage","title":"<code>create_stage(definition: StageDefinition, context: StagePluginContext) -&gt; object</code>","text":"<p>Create a stage instance based on the stage definition.</p> <p>Parameters:</p> Name Type Description Default <code>definition</code> <code>StageDefinition</code> <p>Stage definition containing type and configuration</p> required <code>context</code> <code>StagePluginContext</code> <p>Plugin context (unused but required by interface)</p> required <p>Returns:</p> Type Description <code>object</code> <p>Stage instance appropriate for the given definition</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If stage type is unsupported or configuration is invalid</p> <code>RuntimeError</code> <p>If required dependencies are not initialized</p> Source code in <code>src/Medical_KG_rev/orchestration/stages/plugins/builtin.py</code> <pre><code>def create_stage(self, definition: StageDefinition, context: StagePluginContext) -&gt; object:\n    \"\"\"Create a stage instance based on the stage definition.\n\n    Args:\n        definition: Stage definition containing type and configuration\n        context: Plugin context (unused but required by interface)\n\n    Returns:\n        Stage instance appropriate for the given definition\n\n    Raises:\n        ValueError: If stage type is unsupported or configuration is invalid\n        RuntimeError: If required dependencies are not initialized\n    \"\"\"\n    assert self._adapter_manager is not None\n    assert self._pipeline_resource is not None\n\n    stage_type = definition.stage_type\n    config: Mapping[str, Any] = definition.config\n    if stage_type == \"ingest\":\n        adapter = config.get(\"adapter\")\n        if not adapter:\n            raise ValueError(f\"Stage '{definition.name}' requires an adapter\")\n        strict = bool(config.get(\"strict\", False))\n        domain_value = config.get(\"domain\")\n        domain = AdapterDomain(domain_value) if domain_value is not None else AdapterDomain.BIOMEDICAL\n        parameters = config.get(\"parameters\", {}) if isinstance(config, Mapping) else {}\n        return AdapterIngestStage(\n            self._adapter_manager,\n            adapter_name=str(adapter),\n            strict=strict,\n            default_domain=domain,\n            extra_parameters=parameters if isinstance(parameters, Mapping) else {},\n        )\n    if stage_type == \"parse\":\n        return AdapterParseStage()\n    if stage_type == \"ir-validation\":\n        return IRValidationStage()\n    if stage_type == \"chunk\":\n        splitter = self._pipeline_resource.splitter\n        # SimpleDocumentSplitter implements the required run() method for DocumentSplitter interface\n        return HaystackChunker(splitter, chunker_name=\"haystack.semantic\", granularity=\"paragraph\")\n    if stage_type == \"embed\":\n        embedder = self._pipeline_resource.embedder\n        return HaystackEmbedder(embedder=embedder, require_gpu=False, sparse_expander=None)\n    if stage_type == \"index\":\n        return HaystackIndexWriter(\n            dense_writer=self._pipeline_resource.dense_writer,\n            sparse_writer=self._pipeline_resource.sparse_writer,\n        )\n    if stage_type == \"extract\":\n        return NoOpExtractStage()\n    if stage_type == \"knowledge-graph\":\n        return NoOpKnowledgeGraphStage()\n    if stage_type == \"pdf-download\":\n        return StorageAwarePdfDownloadStage()\n    if stage_type == \"pdf-gate\":\n        return SimplePdfGateStage()\n    raise ValueError(f\"Unsupported stage type '{stage_type}' for core plugin\")\n</code></pre>"},{"location":"api/orchestration/#Medical_KG_rev.orchestration.stages.plugins.builtin.CoreStagePlugin.health_check","title":"<code>health_check(context: StagePluginContext) -&gt; None</code>","text":"<p>Verify that all required dependencies are properly initialized.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>StagePluginContext</code> <p>Plugin context (unused but required by interface)</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If any required dependency is not available</p> Source code in <code>src/Medical_KG_rev/orchestration/stages/plugins/builtin.py</code> <pre><code>def health_check(self, context: StagePluginContext) -&gt; None:\n    \"\"\"Verify that all required dependencies are properly initialized.\n\n    Args:\n        context: Plugin context (unused but required by interface)\n\n    Raises:\n        RuntimeError: If any required dependency is not available\n    \"\"\"\n    if not isinstance(self._adapter_manager, AdapterPluginManager):\n        raise RuntimeError(\"Adapter manager not available for core stage plugin\")\n    if not isinstance(self._pipeline_resource, HaystackPipelineResource):\n        raise RuntimeError(\"Haystack pipeline resource not available\")\n</code></pre>"},{"location":"api/orchestration/#Medical_KG_rev.orchestration.stages.plugins.builtin.CoreStagePlugin.initialise","title":"<code>initialise(context: StagePluginContext) -&gt; None</code>","text":"<p>Initialize the plugin with required dependencies.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>StagePluginContext</code> <p>Plugin context containing required dependencies</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If required dependencies are missing from context</p> <code>TypeError</code> <p>If dependencies have incorrect types</p> Source code in <code>src/Medical_KG_rev/orchestration/stages/plugins/builtin.py</code> <pre><code>def initialise(self, context: StagePluginContext) -&gt; None:\n    \"\"\"Initialize the plugin with required dependencies.\n\n    Args:\n        context: Plugin context containing required dependencies\n\n    Raises:\n        KeyError: If required dependencies are missing from context\n        TypeError: If dependencies have incorrect types\n    \"\"\"\n    self._adapter_manager = context.require(\"adapter_manager\")\n    self._pipeline_resource = context.require(\"haystack_pipeline\")\n</code></pre>"},{"location":"api/orchestration/#Medical_KG_rev.orchestration.stages.plugins.builtin.PdfTwoPhasePlugin","title":"<code>Medical_KG_rev.orchestration.stages.plugins.builtin.PdfTwoPhasePlugin()</code>","text":"<p>               Bases: <code>StagePlugin</code></p> <p>Plugin providing download and gate stages for the pdf-two-phase pipeline.</p> <p>This plugin specializes in PDF processing workflows, providing stages for downloading PDFs and gating pipeline execution based on MinerU readiness. It's designed for two-phase PDF processing where the first phase handles PDF acquisition and the second phase waits for MinerU processing completion.</p> <p>Attributes:</p> Name Type Description <code>_ledger</code> <code>JobLedger | None</code> <p>Job ledger for tracking PDF processing state</p> Thread Safety <p>Thread-safe once initialized. Stage instances created by this plugin should be stateless or thread-safe.</p> Lifecycle <ol> <li>Initialize with metadata</li> <li>Call initialise() with job ledger dependency</li> <li>Use health_check() to verify ledger availability</li> <li>Create stages via create_stage()</li> </ol> <p>Examples:</p> <p>plugin = PdfTwoPhasePlugin() context = StagePluginContext({\"job_ledger\": ledger}) plugin.initialise(context) stage = plugin.create_stage(definition, context)</p> <p>Initialize the PDF two-phase plugin with metadata.</p> <p>Sets up the plugin metadata including supported stage types and description. Dependencies are initialized later via initialise().</p> <p>Raises:</p> Type Description <code>None</code> <p>Initialization always succeeds.</p> Source code in <code>src/Medical_KG_rev/orchestration/stages/plugins/builtin.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the PDF two-phase plugin with metadata.\n\n    Sets up the plugin metadata including supported stage types and\n    description. Dependencies are initialized later via initialise().\n\n    Raises:\n        None: Initialization always succeeds.\n    \"\"\"\n    super().__init__(\n        StagePluginMetadata(\n            name=\"pdf-two-phase\",\n            version=\"1.0.0\",\n            stage_types=(\"download\", \"gate\"),\n            description=\"PDF download + gate pipeline stages\",\n        )\n    )\n    self._ledger: JobLedger | None = None\n</code></pre>"},{"location":"api/orchestration/#Medical_KG_rev.orchestration.stages.plugins.builtin.PdfTwoPhasePlugin.create_stage","title":"<code>create_stage(definition: StageDefinition, context: StagePluginContext) -&gt; object</code>","text":"<p>Create a stage instance based on the stage definition.</p> <p>Parameters:</p> Name Type Description Default <code>definition</code> <code>StageDefinition</code> <p>Stage definition containing type and configuration</p> required <code>context</code> <code>StagePluginContext</code> <p>Plugin context (unused but required by interface)</p> required <p>Returns:</p> Type Description <code>object</code> <p>Stage instance appropriate for the given definition</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If stage type is unsupported or configuration is invalid</p> <code>RuntimeError</code> <p>If required dependencies are not initialized</p> Source code in <code>src/Medical_KG_rev/orchestration/stages/plugins/builtin.py</code> <pre><code>def create_stage(self, definition: StageDefinition, context: StagePluginContext) -&gt; object:\n    \"\"\"Create a stage instance based on the stage definition.\n\n    Args:\n        definition: Stage definition containing type and configuration\n        context: Plugin context (unused but required by interface)\n\n    Returns:\n        Stage instance appropriate for the given definition\n\n    Raises:\n        ValueError: If stage type is unsupported or configuration is invalid\n        RuntimeError: If required dependencies are not initialized\n    \"\"\"\n    assert self._ledger is not None\n    if definition.stage_type == \"download\":\n        return _PdfDownloadStage(self._ledger)\n    if definition.stage_type == \"gate\":\n        return _PdfGateStage(self._ledger, gate_name=definition.name)\n    raise ValueError(f\"Unsupported stage type '{definition.stage_type}' for PDF plugin\")\n</code></pre>"},{"location":"api/orchestration/#Medical_KG_rev.orchestration.stages.plugins.builtin.PdfTwoPhasePlugin.health_check","title":"<code>health_check(context: StagePluginContext) -&gt; None</code>","text":"<p>Verify that all required dependencies are properly initialized.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>StagePluginContext</code> <p>Plugin context (unused but required by interface)</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If any required dependency is not available</p> Source code in <code>src/Medical_KG_rev/orchestration/stages/plugins/builtin.py</code> <pre><code>def health_check(self, context: StagePluginContext) -&gt; None:\n    \"\"\"Verify that all required dependencies are properly initialized.\n\n    Args:\n        context: Plugin context (unused but required by interface)\n\n    Raises:\n        RuntimeError: If any required dependency is not available\n    \"\"\"\n    if not isinstance(self._ledger, JobLedger):\n        raise RuntimeError(\"Job ledger unavailable for PDF plugin\")\n</code></pre>"},{"location":"api/orchestration/#Medical_KG_rev.orchestration.stages.plugins.builtin.PdfTwoPhasePlugin.initialise","title":"<code>initialise(context: StagePluginContext) -&gt; None</code>","text":"<p>Initialize the plugin with required dependencies.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>StagePluginContext</code> <p>Plugin context containing required dependencies</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If required dependencies are missing from context</p> <code>TypeError</code> <p>If dependencies have incorrect types</p> Source code in <code>src/Medical_KG_rev/orchestration/stages/plugins/builtin.py</code> <pre><code>def initialise(self, context: StagePluginContext) -&gt; None:\n    \"\"\"Initialize the plugin with required dependencies.\n\n    Args:\n        context: Plugin context containing required dependencies\n\n    Raises:\n        KeyError: If required dependencies are missing from context\n        TypeError: If dependencies have incorrect types\n    \"\"\"\n    self._ledger = context.require(\"job_ledger\")\n</code></pre>"},{"location":"api/orchestration/#Medical_KG_rev.orchestration.stages.plugins.builtin._PdfDownloadStage","title":"<code>Medical_KG_rev.orchestration.stages.plugins.builtin._PdfDownloadStage(ledger: JobLedger)</code>","text":"<p>Download stage that records PDF acquisition in the ledger and state.</p> <p>This private stage implementation handles PDF download operations for the two-phase PDF processing pipeline. It extracts PDF URLs from payloads, creates download artifacts, and records the download completion in the job ledger.</p> <p>Attributes:</p> Name Type Description <code>_ledger</code> <p>Job ledger for tracking download state</p> Thread Safety <p>Thread-safe. The ledger is assumed to be thread-safe.</p> <p>Examples:</p> <p>stage = _PdfDownloadStage(ledger) artifacts = stage.execute(context, state)</p> <p>Initialize the PDF download stage.</p> <p>Parameters:</p> Name Type Description Default <code>ledger</code> <code>JobLedger</code> <p>Job ledger for tracking download state</p> required <p>Raises:</p> Type Description <code>None</code> <p>Initialization always succeeds.</p> Source code in <code>src/Medical_KG_rev/orchestration/stages/plugins/builtin.py</code> <pre><code>def __init__(self, ledger: JobLedger) -&gt; None:\n    \"\"\"Initialize the PDF download stage.\n\n    Args:\n        ledger: Job ledger for tracking download state\n\n    Raises:\n        None: Initialization always succeeds.\n    \"\"\"\n    self._ledger = ledger\n</code></pre>"},{"location":"api/orchestration/#Medical_KG_rev.orchestration.stages.plugins.builtin._PdfDownloadStage.execute","title":"<code>execute(ctx: StageContext, state: PipelineState) -&gt; list[DownloadArtifact]</code>","text":"<p>Execute the PDF download stage.</p> <p>Extracts PDF URLs from payloads, creates download artifacts, and records the download completion in the job ledger.</p> <p>Parameters:</p> Name Type Description Default <code>ctx</code> <code>StageContext</code> <p>Stage execution context</p> required <code>state</code> <code>PipelineState</code> <p>Current pipeline state</p> required <p>Returns:</p> Type Description <code>list[DownloadArtifact]</code> <p>List of download artifacts created from payloads</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no payloads are available or payloads lack required URLs</p> Source code in <code>src/Medical_KG_rev/orchestration/stages/plugins/builtin.py</code> <pre><code>def execute(self, ctx: StageContext, state: PipelineState) -&gt; list[DownloadArtifact]:\n    \"\"\"Execute the PDF download stage.\n\n    Extracts PDF URLs from payloads, creates download artifacts, and records\n    the download completion in the job ledger.\n\n    Args:\n        ctx: Stage execution context\n        state: Current pipeline state\n\n    Returns:\n        List of download artifacts created from payloads\n\n    Raises:\n        ValueError: If no payloads are available or payloads lack required URLs\n    \"\"\"\n    payloads = list(state.require_payloads())\n    if not payloads:\n        raise ValueError(\"PDF download stage requires payloads with source metadata\")\n\n    document_id = ctx.doc_id or state.context.doc_id or f\"doc-{ctx.correlation_id or 'pdf'}\"\n    tenant = ctx.tenant_id\n    artifacts: list[DownloadArtifact] = []\n    for index, payload in enumerate(payloads):\n        uri = str(payload.get(\"pdf_url\") or payload.get(\"download_url\") or payload.get(\"uri\") or \"\")\n        if not uri:\n            raise ValueError(\"PDF payload missing 'pdf_url' or 'download_url'\")\n        artifacts.append(\n            DownloadArtifact(\n                document_id=document_id,\n                tenant_id=tenant,\n                uri=uri,\n                metadata={\"payload_index\": index, \"source\": payload.get(\"source\")},\n            )\n        )\n\n    job_id = ctx.job_id or state.job_id\n    if job_id:\n        self._ledger.set_pdf_downloaded(job_id, True)\n    logger.info(\n        \"dagster.stage.pdf_download.completed\",\n        job_id=job_id,\n        artifacts=len(artifacts),\n    )\n    return artifacts\n</code></pre>"},{"location":"api/orchestration/#Medical_KG_rev.orchestration.stages.plugins.builtin._PdfGateStage","title":"<code>Medical_KG_rev.orchestration.stages.plugins.builtin._PdfGateStage(ledger: JobLedger, *, gate_name: str)</code>","text":"<p>Gate stage that validates MinerU readiness using the job ledger.</p> <p>This private stage implementation handles pipeline gating for PDF processing. It checks the job ledger to determine if MinerU processing is complete and either allows pipeline continuation or raises a gate not ready exception.</p> <p>Attributes:</p> Name Type Description <code>_ledger</code> <p>Job ledger for checking processing state</p> <code>_gate_name</code> <p>Name of this gate for logging and error reporting</p> Thread Safety <p>Thread-safe. The ledger is assumed to be thread-safe.</p> <p>Examples:</p> <p>stage = _PdfGateStage(ledger, gate_name=\"mineru-ready\") decision = stage.execute(context, state)</p> <p>Initialize the PDF gate stage.</p> <p>Parameters:</p> Name Type Description Default <code>ledger</code> <code>JobLedger</code> <p>Job ledger for checking processing state</p> required <code>gate_name</code> <code>str</code> <p>Name of this gate for logging and error reporting</p> required <p>Raises:</p> Type Description <code>None</code> <p>Initialization always succeeds.</p> Source code in <code>src/Medical_KG_rev/orchestration/stages/plugins/builtin.py</code> <pre><code>def __init__(self, ledger: JobLedger, *, gate_name: str) -&gt; None:\n    \"\"\"Initialize the PDF gate stage.\n\n    Args:\n        ledger: Job ledger for checking processing state\n        gate_name: Name of this gate for logging and error reporting\n\n    Raises:\n        None: Initialization always succeeds.\n    \"\"\"\n    self._ledger = ledger\n    self._gate_name = gate_name\n</code></pre>"},{"location":"api/orchestration/#Medical_KG_rev.orchestration.stages.plugins.builtin._PdfGateStage.execute","title":"<code>execute(ctx: StageContext, state: PipelineState) -&gt; GateDecision</code>","text":"<p>Execute the PDF gate stage.</p> <p>Checks the job ledger to determine if MinerU processing is complete. If ready, returns a gate decision allowing continuation. If not ready, raises a PipelineGateNotReady exception to block pipeline execution.</p> <p>Parameters:</p> Name Type Description Default <code>ctx</code> <code>StageContext</code> <p>Stage execution context</p> required <code>state</code> <code>PipelineState</code> <p>Current pipeline state</p> required <p>Returns:</p> Type Description <code>GateDecision</code> <p>Gate decision indicating readiness status</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no job identifier is available for ledger lookup</p> <code>PipelineGateNotReady</code> <p>If MinerU processing is not yet complete</p> Source code in <code>src/Medical_KG_rev/orchestration/stages/plugins/builtin.py</code> <pre><code>def execute(self, ctx: StageContext, state: PipelineState) -&gt; GateDecision:\n    \"\"\"Execute the PDF gate stage.\n\n    Checks the job ledger to determine if MinerU processing is complete.\n    If ready, returns a gate decision allowing continuation. If not ready,\n    raises a PipelineGateNotReady exception to block pipeline execution.\n\n    Args:\n        ctx: Stage execution context\n        state: Current pipeline state\n\n    Returns:\n        Gate decision indicating readiness status\n\n    Raises:\n        ValueError: If no job identifier is available for ledger lookup\n        PipelineGateNotReady: If MinerU processing is not yet complete\n    \"\"\"\n    job_id = ctx.job_id or state.job_id\n    if not job_id:\n        raise ValueError(\"PDF gate requires a job identifier for ledger lookup\")\n    entry = self._ledger.get(job_id)\n    ready = bool(entry and entry.pdf_ir_ready)\n    decision = GateDecision(name=self._gate_name, ready=ready)\n    if not ready:\n        logger.info(\n            \"dagster.stage.pdf_gate.blocked\",\n            job_id=job_id,\n            gate=self._gate_name,\n        )\n        raise PipelineGateNotReady(\n            f\"MinerU IR not ready for job {job_id}\", gate=self._gate_name\n        )\n    logger.info(\n        \"dagster.stage.pdf_gate.ready\",\n        job_id=job_id,\n        gate=self._gate_name,\n    )\n    return decision\n</code></pre>"},{"location":"api/services/","title":"Services API","text":"<p>The services layer provides domain-specific implementations for chunking, embedding, and retrieval operations.</p>"},{"location":"api/services/#gateway-service","title":"Gateway Service","text":"<p>The <code>GatewayService</code> acts as a protocol-agnostic service layer between protocol handlers (REST/GraphQL/gRPC) and domain logic.</p>"},{"location":"api/services/#Medical_KG_rev.gateway.services.GatewayService","title":"<code>Medical_KG_rev.gateway.services.GatewayService(events: EventStreamManager, orchestrator: DagsterOrchestrator, ledger: JobLedger, adapter_manager: AdapterPluginManager = get_plugin_manager(), stage_factory: StageFactory | None = None, chunker: ChunkingService | None = None, chunking_error_translator: ChunkingErrorTranslator | None = None, retriever: HaystackRetriever = HaystackRetriever(), shacl: ShaclValidator = ShaclValidator.default(), ucum: UCUMValidator = UCUMValidator(), fhir: FHIRValidator = FHIRValidator(), embedding_registry: EmbeddingModelRegistry = EmbeddingModelRegistry(), namespace_registry: EmbeddingNamespaceRegistry | None = None, namespace_policy: NamespaceAccessPolicy | None = None, namespace_policy_settings: NamespacePolicySettings | None = None, embedding_persister: EmbeddingPersister | None = None, embedding_persister_settings: PersisterRuntimeSettings | None = None, embedding_telemetry: EmbeddingTelemetry | None = None, job_lifecycle: JobLifecycleManager | None = None, chunking_coordinator: ChunkingCoordinator | None = None, embedding_coordinator: EmbeddingCoordinator | None = None, chunking_errors: ChunkingErrorTranslator | None = None)</code>  <code>dataclass</code>","text":"<p>Coordinates business logic shared across protocols.</p> <p>This class serves as the main entry point for all gateway operations, providing a protocol-agnostic interface to domain services. It manages job lifecycle, coordinates between subsystems, and handles error translation.</p> <p>Attributes:</p> Name Type Description <code>events</code> <code>EventStreamManager</code> <p>EventStreamManager for publishing SSE events</p> <code>orchestrator</code> <code>DagsterOrchestrator</code> <p>DagsterOrchestrator for pipeline execution</p> <code>ledger</code> <code>JobLedger</code> <p>JobLedger for tracking job status and metadata</p> <code>adapter_manager</code> <code>AdapterPluginManager</code> <p>AdapterPluginManager for data source management</p> <code>chunker</code> <code>ChunkingService | None</code> <p>ChunkingService for document chunking operations</p> <code>retriever</code> <code>HaystackRetriever</code> <p>HaystackRetriever for document retrieval</p> <code>shacl</code> <code>ShaclValidator</code> <p>ShaclValidator for knowledge graph validation</p> <code>ucum</code> <code>UCUMValidator</code> <p>UCUMValidator for medical unit validation</p> <code>fhir</code> <code>FHIRValidator</code> <p>FHIRValidator for FHIR resource validation</p> <code>embedding_registry</code> <code>EmbeddingModelRegistry</code> <p>EmbeddingModelRegistry for model management</p> <code>namespace_registry</code> <code>EmbeddingNamespaceRegistry | None</code> <p>EmbeddingNamespaceRegistry for namespace management</p> <code>namespace_policy</code> <code>NamespaceAccessPolicy | None</code> <p>NamespaceAccessPolicy for access control</p> <code>embedding_persister</code> <code>EmbeddingPersister | None</code> <p>EmbeddingPersister for vector storage</p> <code>embedding_telemetry</code> <code>EmbeddingTelemetry | None</code> <p>EmbeddingTelemetry for metrics collection</p> <code>job_lifecycle</code> <code>JobLifecycleManager | None</code> <p>JobLifecycleManager for job state tracking</p> <code>chunking_coordinator</code> <code>ChunkingCoordinator | None</code> <p>ChunkingCoordinator for chunking operations</p> <code>embedding_coordinator</code> <code>EmbeddingCoordinator | None</code> <p>EmbeddingCoordinator for embedding operations</p> Invariants <ul> <li>All coordinators are initialized after post_init</li> <li>Job lifecycle manager is always available</li> <li>Event stream manager is always available</li> </ul> Thread Safety <ul> <li>Not thread-safe: Designed for single-threaded request handling</li> <li>Shared state includes job ledger and event stream manager</li> </ul> Lifecycle <ul> <li>Created via get_gateway_service() factory function</li> <li>Initialized with dependency injection</li> <li>Coordinates operations until process shutdown</li> </ul> Example <p>service = get_gateway_service() chunks = service.chunk_document(ChunkRequest( ...     tenant_id=\"tenant1\", ...     document_id=\"doc1\", ...     text=\"Sample text for chunking\" ... )) print(f\"Created {len(chunks)} chunks\")</p>"},{"location":"api/services/#Medical_KG_rev.gateway.services.GatewayService.__post_init__","title":"<code>__post_init__() -&gt; None</code>","text":"<p>Initialize coordinators and dependencies after dataclass creation.</p> <p>This method sets up all coordinator instances and ensures dependencies are properly initialized. It follows a lazy initialization pattern where coordinators are created only when needed.</p> Side Effects <ul> <li>Creates JobLifecycleManager instance</li> <li>Initializes ChunkingCoordinator with dependencies</li> <li>Initializes EmbeddingCoordinator with dependencies</li> <li>Sets up namespace policy and embedding persister</li> <li>Configures error translators</li> </ul> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If required dependencies cannot be initialized</p> Source code in <code>src/Medical_KG_rev/gateway/services.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Initialize coordinators and dependencies after dataclass creation.\n\n    This method sets up all coordinator instances and ensures dependencies\n    are properly initialized. It follows a lazy initialization pattern\n    where coordinators are created only when needed.\n\n    Side Effects:\n        - Creates JobLifecycleManager instance\n        - Initializes ChunkingCoordinator with dependencies\n        - Initializes EmbeddingCoordinator with dependencies\n        - Sets up namespace policy and embedding persister\n        - Configures error translators\n\n    Raises:\n        RuntimeError: If required dependencies cannot be initialized\n    \"\"\"\n    self.job_lifecycle = JobLifecycleManager(self.ledger, self.events)\n    if self.stage_factory is None:\n        self.stage_factory = _build_stage_factory(\n            self.adapter_manager,\n            self.ledger,\n        )\n    if self.chunker is None:\n        self.chunker = ChunkingService(stage_factory=self.stage_factory)\n    if self.chunking_error_translator is None:\n        self.chunking_error_translator = ChunkingErrorTranslator(\n            strategies=self.chunker.available_strategies(),\n        )\n    if self.namespace_registry is None:\n        self.namespace_registry = self.embedding_registry.namespace_registry\n    if self.embedding_telemetry is None:\n        self.embedding_telemetry = StandardEmbeddingTelemetry()\n    if self.namespace_policy is None:\n        if self.namespace_policy_settings is None:\n            self.namespace_policy_settings = NamespacePolicySettings()\n        self.namespace_policy = self._build_namespace_policy()\n    self.namespace_policy_settings = self.namespace_policy.settings\n    if self.embedding_persister is None:\n        router = getattr(self.embedding_registry, \"storage_router\", None)\n        if router is None:\n            raise RuntimeError(\"Embedding registry missing storage router\")\n        settings = self.embedding_persister_settings or PersisterRuntimeSettings()\n        self.embedding_persister = build_persister(\n            router,\n            telemetry=self.embedding_telemetry,\n            settings=settings,\n        )\n        self.embedding_persister_settings = settings\n    if self.chunking_coordinator is None:\n        self.chunking_coordinator = ChunkingCoordinator(\n            lifecycle=self.job_lifecycle,\n            chunker=self.chunker,\n            config=self._build_coordinator_config(\"chunking\"),\n            errors=self.chunking_error_translator,\n        )\n    if self.embedding_coordinator is None:\n        if self.namespace_registry is None:\n            raise RuntimeError(\"Namespace registry not initialised\")\n        if self.embedding_persister is None:\n            raise RuntimeError(\"Embedding persister not initialised\")\n        if self.namespace_policy is None:\n            raise RuntimeError(\"Namespace policy not initialised\")\n        self.embedding_coordinator = EmbeddingCoordinator(\n            lifecycle=self.job_lifecycle,\n            registry=self.embedding_registry,\n            namespace_registry=self.namespace_registry,\n            policy=self.namespace_policy,\n            persister=self.embedding_persister,\n            telemetry=self.embedding_telemetry,\n            config=self._build_coordinator_config(\"embedding\", retry_attempts=4),\n        )\n</code></pre>"},{"location":"api/services/#Medical_KG_rev.gateway.services.GatewayService.chunk_document","title":"<code>chunk_document(request: ChunkRequest) -&gt; Sequence[DocumentChunk]</code>","text":"<p>Chunk a document into smaller segments for processing.</p> <p>This method coordinates document chunking by delegating to the ChunkingCoordinator. It handles error translation and metrics emission.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>ChunkRequest</code> <p>ChunkRequest containing document text and chunking parameters - tenant_id: Tenant identifier for multi-tenancy - document_id: Unique document identifier - text: Document text to chunk - strategy: Chunking strategy (e.g., \"section\", \"semantic\") - chunk_size: Maximum tokens per chunk - overlap: Token overlap between chunks - options: Additional metadata and configuration</p> required <p>Returns:</p> Type Description <code>Sequence[DocumentChunk]</code> <p>Sequence of DocumentChunk objects with content and metadata</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If chunking coordinator is not initialized</p> <code>GatewayError</code> <p>If chunking fails with translated error details</p> Note <p>Emits 'chunk' duration metric and delegates to ChunkingCoordinator</p> Example <p>request = ChunkRequest( ...     tenant_id=\"tenant1\", ...     document_id=\"doc1\", ...     text=\"Long document text...\", ...     strategy=\"section\" ... ) chunks = service.chunk_document(request) print(f\"Created {len(chunks)} chunks\")</p> Source code in <code>src/Medical_KG_rev/gateway/services.py</code> <pre><code>def chunk_document(self, request: ChunkRequest) -&gt; Sequence[DocumentChunk]:\n    \"\"\"Chunk a document into smaller segments for processing.\n\n    This method coordinates document chunking by delegating to the\n    ChunkingCoordinator. It handles error translation and metrics emission.\n\n    Args:\n        request: ChunkRequest containing document text and chunking parameters\n            - tenant_id: Tenant identifier for multi-tenancy\n            - document_id: Unique document identifier\n            - text: Document text to chunk\n            - strategy: Chunking strategy (e.g., \"section\", \"semantic\")\n            - chunk_size: Maximum tokens per chunk\n            - overlap: Token overlap between chunks\n            - options: Additional metadata and configuration\n\n    Returns:\n        Sequence of DocumentChunk objects with content and metadata\n\n    Raises:\n        RuntimeError: If chunking coordinator is not initialized\n        GatewayError: If chunking fails with translated error details\n\n    Note:\n        Emits 'chunk' duration metric and delegates to ChunkingCoordinator\n\n    Example:\n        &gt;&gt;&gt; request = ChunkRequest(\n        ...     tenant_id=\"tenant1\",\n        ...     document_id=\"doc1\",\n        ...     text=\"Long document text...\",\n        ...     strategy=\"section\"\n        ... )\n        &gt;&gt;&gt; chunks = service.chunk_document(request)\n        &gt;&gt;&gt; print(f\"Created {len(chunks)} chunks\")\n    \"\"\"\n    if self.chunking_coordinator is None:\n        raise RuntimeError(\"Chunking coordinator not initialised\")\n\n    coordinator_request = CoordinatorChunkingRequest(\n        tenant_id=request.tenant_id,\n        correlation_id=None,\n        metadata={\"document_id\": request.document_id},\n        document_id=request.document_id,\n        text=request.text,\n        strategy=request.strategy,\n        chunk_size=request.chunk_size,\n        overlap=int(request.overlap) if request.overlap is not None else None,\n        options=request.options,\n    )\n    try:\n        result: ChunkingResult = self.chunking_coordinator(coordinator_request)\n    except CoordinatorError as exc:\n        translator = self.chunking_error_translator or ChunkingErrorTranslator(\n            strategies=self.chunker.available_strategies()\n        )\n        context = exc.context if isinstance(exc.context, Mapping) else {}\n        detail = translator.translate(exc, command=None)\n        if detail is not None:\n            raise GatewayError(detail.detail) from exc\n        raise\n    observe_job_duration(\"chunk\", result.duration_s)\n    return list(result.chunks)\n</code></pre>"},{"location":"api/services/#Medical_KG_rev.gateway.services.GatewayService.embed","title":"<code>embed(request: EmbedRequest) -&gt; EmbeddingResponse</code>","text":"<p>Generate embeddings for text inputs using configured models.</p> <p>This method coordinates embedding generation by delegating to the EmbeddingCoordinator. It handles namespace policy evaluation, model selection, persistence, and telemetry collection.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>EmbedRequest</code> <p>EmbedRequest containing texts and embedding parameters - tenant_id: Tenant identifier for multi-tenancy - namespace: Embedding namespace for model selection - texts: List of text strings to embed - options: EmbeddingOptions with model and normalization settings</p> required <p>Returns:</p> Type Description <code>EmbeddingResponse</code> <p>EmbeddingResponse with generated vectors and metadata</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If embedding coordinator or components not initialized</p> <code>GatewayError</code> <p>If namespace access denied or embedding fails</p> Note <p>Emits 'embed' duration metric and delegates to EmbeddingCoordinator Validates namespace access via policy evaluation Persists embeddings via configured persister</p> Example <p>request = EmbedRequest( ...     tenant_id=\"tenant1\", ...     namespace=\"clinical\", ...     texts=[\"Sample text to embed\"], ...     options=EmbeddingOptions(model=\"clinical-bert\") ... ) response = service.embed(request) print(f\"Generated {len(response.embeddings)} embeddings\")</p> Source code in <code>src/Medical_KG_rev/gateway/services.py</code> <pre><code>def embed(self, request: EmbedRequest) -&gt; EmbeddingResponse:\n    \"\"\"Generate embeddings for text inputs using configured models.\n\n    This method coordinates embedding generation by delegating to the\n    EmbeddingCoordinator. It handles namespace policy evaluation, model\n    selection, persistence, and telemetry collection.\n\n    Args:\n        request: EmbedRequest containing texts and embedding parameters\n            - tenant_id: Tenant identifier for multi-tenancy\n            - namespace: Embedding namespace for model selection\n            - texts: List of text strings to embed\n            - options: EmbeddingOptions with model and normalization settings\n\n    Returns:\n        EmbeddingResponse with generated vectors and metadata\n\n    Raises:\n        RuntimeError: If embedding coordinator or components not initialized\n        GatewayError: If namespace access denied or embedding fails\n\n    Note:\n        Emits 'embed' duration metric and delegates to EmbeddingCoordinator\n        Validates namespace access via policy evaluation\n        Persists embeddings via configured persister\n\n    Example:\n        &gt;&gt;&gt; request = EmbedRequest(\n        ...     tenant_id=\"tenant1\",\n        ...     namespace=\"clinical\",\n        ...     texts=[\"Sample text to embed\"],\n        ...     options=EmbeddingOptions(model=\"clinical-bert\")\n        ... )\n        &gt;&gt;&gt; response = service.embed(request)\n        &gt;&gt;&gt; print(f\"Generated {len(response.embeddings)} embeddings\")\n    \"\"\"\n    if self.embedding_coordinator is None:\n        raise RuntimeError(\"Embedding coordinator not initialised\")\n    if self.namespace_registry is None or self.namespace_policy is None or self.embedding_persister is None:\n        raise RuntimeError(\"Embedding components not initialised\")\n\n    started = perf_counter()\n    options = request.options or EmbeddingOptions()\n    namespace = request.namespace\n\n    try:\n        decision = self.namespace_policy.evaluate(\n            namespace=namespace,\n            tenant_id=request.tenant_id,\n            required_scope=Scopes.EMBED_WRITE,\n        )\n    except Exception as exc:  # pragma: no cover - defensive\n        detail = ProblemDetail(\n            title=\"Namespace policy failure\",\n            status=500,\n            type=\"https://httpstatuses.com/500\",\n            detail=str(exc),\n        )\n        raise GatewayError(detail) from exc\n\n    if not decision.allowed:\n        detail = ProblemDetail(\n            title=\"Namespace access denied\",\n            status=403,\n            type=\"https://httpstatuses.com/403\",\n            detail=decision.reason or \"Access to namespace not permitted\",\n        )\n        raise GatewayError(detail)\n\n    config = decision.config or self.namespace_registry.get(namespace)\n\n    job_id = self._new_job(request.tenant_id, \"embed\")\n    correlation_id = uuid.uuid4().hex\n    model_name = options.model or config.model_id\n\n    if self.embedding_telemetry:\n        self.embedding_telemetry.record_embedding_started(\n            namespace=namespace,\n            tenant_id=request.tenant_id,\n            model=model_name,\n        )\n\n    texts: list[str] = []\n    ids: list[str] = []\n    metadata_payload: list[dict[str, Any]] = []\n    for index, text in enumerate(request.texts):\n        if not isinstance(text, str) or not text.strip():\n            detail = ProblemDetail(\n                title=\"Invalid embedding input\",\n                status=400,\n                type=\"https://httpstatuses.com/400\",\n                detail=\"Embedding texts must be non-empty strings\",\n            )\n            self._fail_job(job_id, detail.detail or detail.title)\n            raise GatewayError(detail)\n        body = text.strip()\n        chunk_id = f\"{job_id}:chunk:{index}\"\n        texts.append(body)\n        ids.append(chunk_id)\n        metadata_payload.append(\n            {\n                \"input_index\": index,\n                \"job_id\": job_id,\n                \"namespace\": namespace,\n                \"tenant_id\": request.tenant_id,\n            }\n        )\n\n    if not texts:\n        payload = {\"embeddings\": 0, \"model\": model_name, \"namespace\": namespace}\n        self.ledger.update_metadata(job_id, payload)\n        self._complete_job(job_id, payload=payload)\n        metadata = EmbeddingMetadata(\n            provider=config.provider,\n            dimension=config.dim,\n            duration_ms=0.0,\n            model=model_name,\n        )\n        return EmbeddingResponse(namespace=namespace, embeddings=(), metadata=metadata)\n\n    coordinator_request = CoordinatorEmbeddingRequest(\n        tenant_id=request.tenant_id,\n        correlation_id=None,\n        metadata={\"namespace\": request.namespace},\n        namespace=request.namespace,\n        texts=request.texts,\n        options=request.options,\n    )\n    try:\n        result: EmbeddingResult = self.embedding_coordinator(coordinator_request)\n    except CoordinatorError as exc:\n        detail = exc.context.get(\"problem\") if isinstance(exc.context, dict) else None\n        if isinstance(detail, ProblemDetail):\n            raise GatewayError(detail) from exc\n        raise\n    observe_job_duration(\"embed\", result.duration_s)\n    if result.response is None:\n        raise RuntimeError(\"Embedding coordinator returned no response\")\n    return result.response\n</code></pre>"},{"location":"api/services/#chunking-errors","title":"Chunking Errors","text":"<p>Error translation utilities for converting chunking exceptions into API-facing payloads.</p>"},{"location":"api/services/#Medical_KG_rev.gateway.chunking_errors.ChunkingErrorReport","title":"<code>Medical_KG_rev.gateway.chunking_errors.ChunkingErrorReport(problem: ProblemDetail, severity: str, metric: str | None = None, job_id: str | None = None)</code>  <code>dataclass</code>","text":"<p>Structured view of a translated chunking error.</p> <p>This dataclass represents the result of error translation, providing a structured view of chunking errors suitable for API responses and monitoring systems.</p> <p>Attributes:</p> Name Type Description <code>problem</code> <code>ProblemDetail</code> <p>Standardized problem detail for API response</p> <code>severity</code> <code>str</code> <p>Error severity level (client, fatal, retryable)</p> <code>metric</code> <code>str | None</code> <p>Optional metric name for monitoring</p> <code>job_id</code> <code>str | None</code> <p>Optional job identifier for correlation</p> Thread Safety <p>Immutable dataclass, thread-safe.</p> <p>Examples:</p> <p>report = ChunkingErrorReport(     problem=problem_detail,     severity=\"client\",     metric=\"ProfileNotFoundError\",     job_id=\"job-123\" )</p>"},{"location":"api/services/#Medical_KG_rev.gateway.chunking_errors.ChunkingErrorTranslator","title":"<code>Medical_KG_rev.gateway.chunking_errors.ChunkingErrorTranslator(*, strategies: Sequence[str], base_path: str = '/v1/chunk')</code>","text":"<p>Map domain-specific chunking failures to <code>ProblemDetail</code> payloads.</p> <p>This class provides comprehensive error translation for chunking operations, converting various exception types into standardized ProblemDetail objects suitable for API responses. It handles configuration errors, resource unavailability, processing failures, and system errors.</p> <p>Attributes:</p> Name Type Description <code>_strategies</code> <p>Available chunking strategies for validation</p> <code>_base_path</code> <p>Base path for error instance URLs</p> Thread Safety <p>Thread-safe and stateless. Safe for concurrent use.</p> Performance <p>Lightweight translation with minimal overhead. No external dependencies or I/O operations.</p> <p>Examples:</p> <p>translator = ChunkingErrorTranslator(     strategies=[\"semantic\", \"fixed\"],     base_path=\"/v1/chunk\" ) report = translator.translate(exception, command=chunk_command)</p> <p>Initialize the chunking error translator.</p> <p>Parameters:</p> Name Type Description Default <code>strategies</code> <code>Sequence[str]</code> <p>Available chunking strategies for validation</p> required <code>base_path</code> <code>str</code> <p>Base path for error instance URLs</p> <code>'/v1/chunk'</code> <p>Raises:</p> Type Description <code>None</code> <p>Initialization always succeeds.</p> Source code in <code>src/Medical_KG_rev/gateway/chunking_errors.py</code> <pre><code>def __init__(self, *, strategies: Sequence[str], base_path: str = \"/v1/chunk\") -&gt; None:\n    \"\"\"Initialize the chunking error translator.\n\n    Args:\n        strategies: Available chunking strategies for validation\n        base_path: Base path for error instance URLs\n\n    Raises:\n        None: Initialization always succeeds.\n    \"\"\"\n    self._strategies = tuple(strategies)\n    self._base_path = base_path.rstrip(\"/\")\n</code></pre>"},{"location":"api/services/#Medical_KG_rev.gateway.chunking_errors.ChunkingErrorTranslator.from_context","title":"<code>from_context(context: Mapping[str, Any]) -&gt; ProblemDetail | None</code>","text":"<p>Extract a ProblemDetail from a context mapping.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Mapping[str, Any]</code> <p>Context mapping potentially containing a problem</p> required <p>Returns:</p> Type Description <code>ProblemDetail | None</code> <p>ProblemDetail if found, None otherwise</p> <p>Raises:</p> Type Description <code>None</code> <p>This method never raises exceptions.</p> Source code in <code>src/Medical_KG_rev/gateway/chunking_errors.py</code> <pre><code>def from_context(self, context: Mapping[str, Any]) -&gt; ProblemDetail | None:\n    \"\"\"Extract a ProblemDetail from a context mapping.\n\n    Args:\n        context: Context mapping potentially containing a problem\n\n    Returns:\n        ProblemDetail if found, None otherwise\n\n    Raises:\n        None: This method never raises exceptions.\n    \"\"\"\n    problem = context.get(\"problem\")\n    if isinstance(problem, ProblemDetail):\n        return problem\n    return None\n</code></pre>"},{"location":"api/services/#Medical_KG_rev.gateway.chunking_errors.ChunkingErrorTranslator.translate","title":"<code>translate(exc: Exception, *, command: ChunkCommand, job_id: str | None = None) -&gt; ChunkingErrorReport | None</code>","text":"<p>Translate a chunking exception into a structured error report.</p> <p>Analyzes the exception type and converts it into a ChunkingErrorReport with appropriate HTTP status codes, severity levels, and error details. Returns None for unrecognized exception types.</p> <p>Parameters:</p> Name Type Description Default <code>exc</code> <code>Exception</code> <p>The exception to translate</p> required <code>command</code> <code>ChunkCommand</code> <p>Chunk command providing context</p> required <code>job_id</code> <code>str | None</code> <p>Optional job identifier for correlation</p> <code>None</code> <p>Returns:</p> Type Description <code>ChunkingErrorReport | None</code> <p>Structured error report or None if exception is not recognized</p> <p>Raises:</p> Type Description <code>None</code> <p>This method never raises exceptions.</p> Source code in <code>src/Medical_KG_rev/gateway/chunking_errors.py</code> <pre><code>def translate(\n    self,\n    exc: Exception,\n    *,\n    command: ChunkCommand,\n    job_id: str | None = None,\n) -&gt; ChunkingErrorReport | None:\n    \"\"\"Translate a chunking exception into a structured error report.\n\n    Analyzes the exception type and converts it into a ChunkingErrorReport\n    with appropriate HTTP status codes, severity levels, and error details.\n    Returns None for unrecognized exception types.\n\n    Args:\n        exc: The exception to translate\n        command: Chunk command providing context\n        job_id: Optional job identifier for correlation\n\n    Returns:\n        Structured error report or None if exception is not recognized\n\n    Raises:\n        None: This method never raises exceptions.\n    \"\"\"\n    profile = self._profile(command)\n    instance = f\"{self._base_path}/{command.document_id}\"\n\n    if isinstance(exc, ProfileNotFoundError):\n        detail = self._problem(\n            title=\"Chunking profile not found\",\n            status=400,\n            detail=str(exc) or \"Requested chunking profile is unavailable\",\n            instance=instance,\n            extensions={\"profile\": profile} if profile else None,\n        )\n        return ChunkingErrorReport(detail, \"client\", \"ProfileNotFoundError\", job_id)\n\n    if isinstance(exc, TokenizerMismatchError):\n        detail = self._problem(\n            title=\"Tokenizer mismatch\",\n            status=500,\n            detail=str(exc) or \"Tokenizer mismatch between profile and text\",\n            instance=instance,\n        )\n        return ChunkingErrorReport(detail, \"fatal\", \"TokenizerMismatchError\", job_id)\n\n    if isinstance(exc, ChunkingFailedError):\n        message = exc.detail or str(exc) or \"Chunking process failed\"\n        detail = self._problem(\n            title=\"Chunking failed\",\n            status=500,\n            detail=message,\n            instance=instance,\n        )\n        return ChunkingErrorReport(detail, \"fatal\", \"ChunkingFailedError\", job_id)\n\n    if isinstance(exc, InvalidDocumentError):\n        detail = self._problem(\n            title=\"Invalid document payload\",\n            status=400,\n            detail=str(exc) or \"Chunking requests must include text\",\n            instance=instance,\n        )\n        return ChunkingErrorReport(detail, \"client\", \"InvalidDocumentError\", job_id)\n\n    if isinstance(exc, ChunkerConfigurationError):\n        detail = self._problem(\n            title=\"Chunker configuration invalid\",\n            status=422,\n            detail=str(exc) or \"Chunking configuration is invalid\",\n            instance=instance,\n            extensions={\"valid_strategies\": list(self._strategies)},\n        )\n        return ChunkingErrorReport(detail, \"client\", \"ChunkerConfigurationError\", job_id)\n\n    if isinstance(exc, ChunkingUnavailableError):\n        retry_after = max(1, int(round(exc.retry_after)))\n        detail = self._problem(\n            title=\"Chunking temporarily unavailable\",\n            status=503,\n            detail=str(exc) or \"Chunking temporarily unavailable\",\n            instance=instance,\n            extensions={\"retry_after\": retry_after},\n        )\n        return ChunkingErrorReport(detail, \"retryable\", \"ChunkingUnavailableError\", job_id)\n\n    if isinstance(exc, MineruOutOfMemoryError):\n        detail = self._problem(\n            title=\"MinerU out of memory\",\n            status=503,\n            detail=str(exc) or \"MinerU exhausted GPU memory\",\n            instance=instance,\n            type_=\"https://medical-kg/errors/mineru-oom\",\n            extensions={\"reason\": \"gpu_out_of_memory\"},\n        )\n        return ChunkingErrorReport(detail, \"retryable\", \"MineruOutOfMemoryError\", job_id)\n\n    if isinstance(exc, MineruGpuUnavailableError):\n        detail = self._problem(\n            title=\"MinerU GPU unavailable\",\n            status=503,\n            detail=str(exc) or \"MinerU GPU unavailable\",\n            instance=instance,\n            type_=\"https://medical-kg/errors/mineru-gpu-unavailable\",\n            extensions={\"reason\": \"gpu_unavailable\"},\n        )\n        return ChunkingErrorReport(detail, \"retryable\", \"MineruGpuUnavailableError\", job_id)\n\n    if isinstance(exc, MemoryError):\n        detail = self._problem(\n            title=\"Chunking resources exhausted\",\n            status=503,\n            detail=str(exc) or \"Chunking operation exhausted available memory\",\n            instance=instance,\n            extensions={\"retry_after\": 60},\n        )\n        return ChunkingErrorReport(detail, \"retryable\", \"MemoryError\", job_id)\n\n    if isinstance(exc, TimeoutError):\n        detail = self._problem(\n            title=\"Chunking operation timed out\",\n            status=503,\n            detail=str(exc) or \"Chunking operation timed out\",\n            instance=instance,\n            extensions={\"retry_after\": 30},\n        )\n        return ChunkingErrorReport(detail, \"retryable\", \"TimeoutError\", job_id)\n\n    if isinstance(exc, RuntimeError) and \"GPU semantic checks\" in str(exc):\n        detail = self._problem(\n            title=\"GPU unavailable for semantic chunking\",\n            status=503,\n            detail=str(exc),\n            instance=instance,\n            extensions={\"reason\": \"gpu_unavailable\"},\n        )\n        return ChunkingErrorReport(detail, \"retryable\", \"GpuUnavailable\", job_id)\n\n    return None\n</code></pre>"},{"location":"api/services/#presentation-errors","title":"Presentation Errors","text":"<p>Error payload helpers for presentation formatting.</p>"},{"location":"api/services/#Medical_KG_rev.gateway.presentation.errors.ErrorDetail","title":"<code>Medical_KG_rev.gateway.presentation.errors.ErrorDetail(status: int, code: str, title: str, detail: str | None = None, meta: Mapping[str, Any] = dict())</code>  <code>dataclass</code>","text":"<p>Structured error metadata for JSON:API responses.</p> <p>This dataclass represents error information in a format compatible with the JSON:API specification. It provides structured error details suitable for API responses.</p> <p>Attributes:</p> Name Type Description <code>status</code> <code>int</code> <p>HTTP status code</p> <code>code</code> <code>str</code> <p>Error code identifier</p> <code>title</code> <code>str</code> <p>Human-readable error title</p> <code>detail</code> <code>str | None</code> <p>Optional detailed error message</p> <code>meta</code> <code>Mapping[str, Any]</code> <p>Optional additional metadata</p> Thread Safety <p>Immutable dataclass, thread-safe.</p> <p>Examples:</p> <p>error = ErrorDetail(     status=400,     code=\"INVALID_REQUEST\",     title=\"Invalid request format\",     detail=\"The request body is malformed\" )</p>"},{"location":"api/services/#Medical_KG_rev.gateway.presentation.errors.ErrorDetail.as_json","title":"<code>as_json() -&gt; dict[str, Any]</code>","text":"<p>Serialize the error detail to JSON-compatible dictionary.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary representation suitable for JSON serialization</p> <p>Raises:</p> Type Description <code>None</code> <p>This method never raises exceptions.</p> Source code in <code>src/Medical_KG_rev/gateway/presentation/errors.py</code> <pre><code>def as_json(self) -&gt; dict[str, Any]:\n    \"\"\"Serialize the error detail to JSON-compatible dictionary.\n\n    Returns:\n        Dictionary representation suitable for JSON serialization\n\n    Raises:\n        None: This method never raises exceptions.\n    \"\"\"\n    payload = {\n        \"status\": str(self.status),\n        \"code\": self.code,\n        \"title\": self.title,\n    }\n    if self.detail:\n        payload[\"detail\"] = self.detail\n    if self.meta:\n        payload[\"meta\"] = dict(self.meta)\n    return payload\n</code></pre>"},{"location":"architecture/foundation/","title":"Foundation Infrastructure Architecture","text":"<p>The foundation layer establishes the shared building blocks used by every other OpenSpec change. It provides:</p> <ul> <li>Federated Intermediate Representation (IR) built on Pydantic models.</li> <li>Domain overlays for medical (FHIR-aligned), finance (XBRL) and legal   (LegalDocML) content.</li> <li>Configuration management backed by Pydantic Settings with optional Vault   integration and feature flag support.</li> <li>Shared utilities for HTTP access, structured logging, telemetry, span   manipulation and identifier generation.</li> <li>Adapter SDK enabling declarative data source integrations with lifecycle   hooks and testing helpers.</li> <li>Storage abstractions that decouple application logic from concrete   backends while supporting async usage patterns.</li> </ul> <p>Subsequent architectural layers (gateway, adapters, orchestration, GPU services, retrieval, security and observability) build on these primitives.</p>"},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>The Medical KG platform is composed of multiple services connected through a multi-protocol gateway.</p> <ul> <li>Gateway \u2013 FastAPI application exposing REST, GraphQL, gRPC, SOAP, and SSE protocols. Shared services and adapters live in <code>src/Medical_KG_rev/gateway</code>.</li> <li>Ingestion Pipeline \u2013 Kafka-backed orchestration layer that coordinates adapters and workers defined in <code>src/Medical_KG_rev/orchestration</code>.</li> <li>Storage \u2013 Neo4j for the knowledge graph and OpenSearch for indexing and retrieval.</li> <li>ML/GPU Services \u2013 Embedding and extraction workloads offload to GPU-enabled microservices.</li> <li>Observability \u2013 Prometheus, Grafana, Jaeger, Sentry, and Loki deliver unified telemetry across the stack.</li> </ul> <p>Refer to <code>docs/architecture</code> and the Engineering Blueprint PDF for deeper diagrams and sequence flows.</p>"},{"location":"chunking/API/","title":"Chunking API Overview","text":"<p>The chunking module exposes a high-level service and factory used by ingestion and retrieval pipelines.</p>"},{"location":"chunking/API/#service-interface","title":"Service Interface","text":"<pre><code>from Medical_KG_rev.chunking import ChunkingService, ChunkingOptions\n\nservice = ChunkingService()\nchunks = service.chunk_text(\n    tenant_id=\"tenant-123\",\n    document_id=\"doc-456\",\n    text=\"Introduction...\",\n    options=ChunkingOptions(strategy=\"semantic_splitter\", granularity=\"paragraph\"),\n)\n</code></pre> <p>The <code>ChunkingService</code> resolves multi-granularity profiles from <code>config/chunking.yaml</code> and preserves full provenance (<code>chunk.meta['block_ids']</code>, <code>chunk.start_char</code>, <code>chunk.end_char</code>).</p>"},{"location":"chunking/API/#ingestion-integration","title":"Ingestion Integration","text":"<p><code>IngestionService</code> wraps <code>ChunkingService</code> to manage chunk storage, latency telemetry, and profile detection.</p> <pre><code>from Medical_KG_rev.services.ingestion import IngestionService\n\nservice = IngestionService()\nrun = service.chunk_document(document, tenant_id=\"tenant-123\", source_hint=\"pmc\")\nprint(run.granularity_counts)\n</code></pre>"},{"location":"chunking/API/#retrieval-integration","title":"Retrieval Integration","text":"<p><code>RetrievalService</code> now exposes granularity-aware search with weighted fusion and window merging.</p> <pre><code>results = retrieval_service.search(\"chunks\", \"hypertension\", filters={\"granularity\": \"paragraph\"})\nfor result in results:\n    print(result.granularity, result.text[:80])\n</code></pre>"},{"location":"chunking/AdapterGuide/","title":"Chunking Adapter Developer Guide","text":"<p>This guide describes how to integrate new third-party chunking adapters with the modular chunking system. Adapters wrap external frameworks and expose them through the <code>BaseChunker</code> protocol so that chunkers can be configured declaratively.</p>"},{"location":"chunking/AdapterGuide/#design-principles","title":"Design Principles","text":"<ul> <li>Provenance first \u2013 adapters must populate <code>Chunk.meta['block_ids']</code> so downstream components can   trace chunks back to their origin blocks.</li> <li>Offset fidelity \u2013 adapters must translate framework offsets to character offsets relative to the   <code>Document</code> input using the shared <code>OffsetMapper</code> helper.</li> <li>Graceful degradation \u2013 adapters should raise <code>ChunkerConfigurationError</code> when optional   dependencies are missing and avoid importing heavy frameworks at module import time.</li> </ul>"},{"location":"chunking/AdapterGuide/#implementation-steps","title":"Implementation Steps","text":"<ol> <li>Create adapter module \u2013 add a class that implements <code>BaseChunker</code> and wraps the target framework.</li> <li>Resolve framework splitter/parser \u2013 lazily import the framework inside the constructor to keep    import failures isolated.</li> <li>Map outputs to contexts \u2013 use <code>OffsetMapper</code> to project framework chunks back to <code>BlockContext</code>    instances before calling <code>ChunkAssembler</code>.</li> <li>Register the adapter \u2013 add the adapter to <code>chunking/registry.py</code> so it can be referenced from    configuration files.</li> <li>Document parameters \u2013 update <code>docs/chunking/Chunkers.md</code> with configuration hints and defaults.</li> </ol>"},{"location":"chunking/AdapterGuide/#testing-checklist","title":"Testing Checklist","text":"<ul> <li>Add unit tests under <code>tests/chunking/test_framework_adapters.py</code> using   <code>pytest.importorskip</code> to execute the adapter when the dependency is available.</li> <li>Include at least one end-to-end evaluation through the <code>ChunkingEvaluationRunner</code> to verify chunk   quality and boundary behaviour.</li> </ul>"},{"location":"chunking/Chunkers/","title":"Chunker Catalogue","text":"<p>This document summarises the algorithms, parameters, and intended use cases for the bundled chunkers.</p>"},{"location":"chunking/Chunkers/#stable-chunkers","title":"Stable Chunkers","text":"Chunker Algorithm Key Parameters Use Cases <code>section_aware</code> Rule-based section segmentation using IMRaD/SPL heuristics <code>section_rules</code> Regulatory filings, PubMed articles <code>semantic_splitter</code> Embedding coherence drift detection <code>tau_coh</code>, <code>min_tokens</code>, <code>model_name</code> Dense retrieval pipelines, Q&amp;A <code>sliding_window</code> Fixed token windows with overlap <code>target_tokens</code>, <code>overlap_ratio</code> Dense embedding backfill, fallback <code>table</code> Table preservation with row/summary modes <code>mode</code>, <code>include_caption</code> Structured data ingestion <code>clinical_role</code> PICO and endpoint heuristics <code>taxonomy_path</code>, <code>role_threshold</code> Clinical trial extraction"},{"location":"chunking/Chunkers/#experimental-chunkers","title":"Experimental Chunkers","text":"Chunker Description <code>llm_chaptering</code> Few-shot prompted boundary detection with semantic drift validation <code>discourse_segmenter</code> Connective-driven EDU segmentation <code>grobid_section</code> Aligns MinerU output with Grobid TEI sections <code>layout_aware</code> Groups blocks by layout regions (DocTR/Docling output) <code>graph_rag</code> Jaccard similarity graph with community summarisation <code>text_tiling</code>, <code>c99</code>, <code>bayes_seg</code>, <code>lda_topic</code> Classical lexical and topic segmentation techniques <code>semantic_cluster</code>, <code>graph_partition</code> Embedding clustering and community detection"},{"location":"chunking/Chunkers/#adapter-chunkers","title":"Adapter Chunkers","text":"Adapter Framework Notes <code>langchain.*</code> LangChain text splitters Requires <code>langchain-text-splitters</code> <code>llama_index.*</code> LlamaIndex node parsers Requires <code>llama-index-core</code> <code>haystack.preprocessor</code> Haystack PreProcessor Requires <code>haystack-ai</code> <code>unstructured.adapter</code> Unstructured partitioner Requires <code>unstructured</code> <p>Refer to <code>docs/chunking/AdapterGuide.md</code> for integration details.</p>"},{"location":"chunking/ConfigurationExamples/","title":"Chunking Configuration Examples","text":"<p>The chunking subsystem is configured through <code>config/chunking.yaml</code>. This document provides example profiles for common corpora.</p>"},{"location":"chunking/ConfigurationExamples/#default-research-profile","title":"Default Research Profile","text":"<pre><code>default_profile: research\nprofiles:\n  research:\n    enable_multi_granularity: true\n    primary:\n      strategy: semantic_splitter\n      granularity: paragraph\n      params:\n        tau_coh: 0.82\n        min_tokens: 200\n    auxiliaries:\n      - strategy: section_aware\n        granularity: section\n      - strategy: sliding_window\n        granularity: window\n        params:\n          target_tokens: 400\n          overlap_ratio: 0.2\n</code></pre>"},{"location":"chunking/ConfigurationExamples/#clinicaltrialsgov-profile","title":"ClinicalTrials.gov Profile","text":"<pre><code>profiles:\n  ctgov:\n    enable_multi_granularity: true\n    primary:\n      strategy: clinical_role\n      granularity: paragraph\n    auxiliaries:\n      - strategy: llm_chaptering\n        granularity: section\n        params:\n          prompt_version: v2\n      - strategy: table\n        granularity: table\n</code></pre>"},{"location":"chunking/ConfigurationExamples/#drug-label-spl-profile","title":"Drug Label (SPL) Profile","text":"<pre><code>profiles:\n  spl:\n    enable_multi_granularity: false\n    primary:\n      strategy: layout_aware\n      granularity: section\n      params:\n        overlap_threshold: 0.25\n</code></pre>"},{"location":"chunking/Evaluation/","title":"Chunking Evaluation Harness","text":"<p>The evaluation harness in <code>eval/chunking_eval.py</code> computes segmentation and retrieval metrics for any registered chunker.</p>"},{"location":"chunking/Evaluation/#running-the-harness","title":"Running the Harness","text":"<pre><code>python -m eval.chunking_eval\n</code></pre> <p>The CLI prints boundary F1, Recall@20, nDCG@10, and average latency for each configured chunker. To customise the evaluated chunkers from code:</p> <pre><code>from eval.chunking_eval import ChunkingEvaluationRunner\n\nrunner = ChunkingEvaluationRunner([\"semantic_splitter\", \"llm_chaptering\"])\nresults = runner.run()\n</code></pre>"},{"location":"chunking/Evaluation/#metrics","title":"Metrics","text":"<ul> <li>Boundary F1 \u2013 compares chunk start offsets against gold annotations.</li> <li>Recall@20 \u2013 proportion of relevant chunks retrieved in the top 20 lexical matches.</li> <li>nDCG@10 / nDCG@20 \u2013 ranking quality for the top 10 and 20 chunks.</li> <li>Latency \u2013 average wall-clock latency per document in milliseconds.</li> </ul> <p>Gold annotations live under <code>eval/gold/</code> and currently contain 10 documents for PMC, SPL, and ClinicalTrials.gov samples.</p>"},{"location":"chunking/Setup/","title":"Chunking Environment Setup","text":""},{"location":"chunking/Setup/#python-extras","title":"Python Extras","text":"<p>Install framework adapters and advanced chunkers via the optional Poetry extra:</p> <pre><code>poetry install -E chunking\n</code></pre>"},{"location":"chunking/Setup/#nltk-punkt-tokeniser","title":"NLTK Punkt Tokeniser","text":"<p>Download the Punkt sentence model once per environment:</p> <pre><code>python -m nltk.downloader punkt\n</code></pre>"},{"location":"chunking/Setup/#spacy-english-model","title":"spaCy English Model","text":"<p>Install the small English model for spaCy-based sentence splitting:</p> <pre><code>python -m spacy download en_core_web_sm\n</code></pre>"},{"location":"chunking/Setup/#validation","title":"Validation","text":"<p>Run the quick health check to verify resources:</p> <pre><code>python - &lt;&lt;'PY'\nfrom Medical_KG_rev.chunking.sentence_splitters import NLTKSentenceSplitter, SpacySentenceSplitter\nprint(NLTKSentenceSplitter().split(\"Sentence one. Sentence two.\"))\nprint(len(SpacySentenceSplitter().split(\"Sentence one. Sentence two.\")))\nPY\n</code></pre>"},{"location":"contributing/documentation_standards/","title":"Documentation Standards","text":"<p>This guide outlines the documentation standards for the Medical KG project, including docstring conventions, section headers, and automated quality checks.</p>"},{"location":"contributing/documentation_standards/#overview","title":"Overview","text":"<p>Documentation is critical for maintaining code quality and enabling effective collaboration. This project follows Google-style docstrings and enforces consistent code organization through section headers.</p>"},{"location":"contributing/documentation_standards/#why-documentation-matters","title":"Why Documentation Matters","text":"<ul> <li>Code Understanding: Clear docstrings help developers understand purpose, parameters, and behavior</li> <li>API Discovery: Well-documented APIs are easier to discover and use correctly</li> <li>Maintenance: Documentation reduces the time needed to understand and modify code</li> <li>Quality Assurance: Automated checks ensure documentation standards are maintained</li> </ul>"},{"location":"contributing/documentation_standards/#standards-we-follow","title":"Standards We Follow","text":"<ul> <li>Google-style docstrings for all modules, classes, and functions</li> <li>Section headers for consistent code organization</li> <li>Type hints for all function parameters and return values</li> <li>Inline comments for complex logic and design decisions</li> </ul>"},{"location":"contributing/documentation_standards/#google-style-docstrings","title":"Google-Style Docstrings","text":""},{"location":"contributing/documentation_standards/#module-docstrings","title":"Module Docstrings","text":"<p>Every module should start with a comprehensive docstring:</p> <pre><code>\"\"\"One-line summary of module purpose.\n\nThis module provides detailed explanation of what the module does, its role\nin the larger system, and key design decisions.\n\nKey Responsibilities:\n    - Responsibility 1: Be specific about what the module handles\n    - Responsibility 2: Include data transformations, external calls, etc.\n    - Responsibility 3: Mention any caching, rate limiting, etc.\n\nCollaborators:\n    - Upstream: List modules/services that call into this one\n    - Downstream: List modules/services this one depends on\n\nSide Effects:\n    - Database writes, external API calls, file I/O, metric emission\n    - Global state modifications, cache updates\n    - None if pure/functional\n\nThread Safety:\n    - Thread-safe: All public functions can be called from multiple threads\n    - Not thread-safe: Must be called from single thread\n    - Conditionally safe: Describe conditions\n\nPerformance Characteristics:\n    - Time complexity for main operations\n    - Memory usage patterns\n    - Rate limits or throttling behavior\n\nExample:\n    &gt;&gt;&gt; from Medical_KG_rev.gateway.coordinators import ChunkingCoordinator\n    &gt;&gt;&gt; coordinator = ChunkingCoordinator(...)\n    &gt;&gt;&gt; result = coordinator.execute(request)\n\"\"\"\n</code></pre>"},{"location":"contributing/documentation_standards/#class-docstrings","title":"Class Docstrings","text":"<p>Classes should document their purpose, attributes, invariants, and usage:</p> <pre><code>class ChunkingCoordinator:\n    \"\"\"Coordinates synchronous chunking operations.\n\n    This class implements the coordinator pattern for chunking operations.\n    It coordinates between gateway services and chunking domain logic to\n    provide protocol-agnostic chunking capabilities.\n\n    Attributes:\n        _lifecycle: JobLifecycleManager for tracking job states\n        _chunker: ChunkingService for actual chunking operations\n        _errors: ChunkingErrorTranslator for error translation\n\n    Invariants:\n        - self._lifecycle is never None after __init__\n        - self._chunker is never None after __init__\n        - self._errors is never None after __init__\n\n    Thread Safety:\n        - Not thread-safe: Must be called from single thread\n\n    Lifecycle:\n        - Created with dependencies injected\n        - Used for coordinating chunking operations\n        - No explicit cleanup required\n\n    Example:\n        &gt;&gt;&gt; coordinator = ChunkingCoordinator(\n        ...     lifecycle=JobLifecycleManager(),\n        ...     chunker=ChunkingService(),\n        ...     config=CoordinatorConfig(name=\"chunking\")\n        ... )\n        &gt;&gt;&gt; result = coordinator.execute(ChunkingRequest(...))\n        &gt;&gt;&gt; print(f\"Processed {len(result.chunks)} chunks\")\n    \"\"\"\n</code></pre>"},{"location":"contributing/documentation_standards/#functionmethod-docstrings","title":"Function/Method Docstrings","text":"<p>Functions should document parameters, return values, exceptions, and behavior:</p> <pre><code>def execute(self, request: ChunkingRequest) -&gt; ChunkingResult:\n    \"\"\"Execute chunking operation with job lifecycle management.\n\n    Coordinates the full chunking workflow: creates job entry, extracts\n    document text, creates chunking command, delegates to chunking service,\n    handles exceptions, assembles results, and marks job completed.\n\n    Args:\n        request: ChunkingRequest with document and chunking parameters\n            - document_id: Unique identifier for document being chunked\n            - text: Optional document text (can also be in options[\"text\"])\n            - strategy: Chunking strategy name, defaults to \"section\"\n            - chunk_size: Maximum tokens per chunk, defaults to profile setting\n            - overlap: Token overlap between chunks, defaults to profile setting\n            - options: Additional metadata and configuration\n\n    Returns:\n        ChunkingResult with chunks and metadata:\n            - chunks: Sequence of DocumentChunk objects with content and metadata\n            - job_id: Unique identifier for this chunking job\n            - duration_s: Time taken to complete chunking operation\n            - metadata: Additional operation metadata\n\n    Raises:\n        CoordinatorError: For all handled errors after translation\n            - ProfileNotFoundError: When chunking profile doesn't exist\n            - InvalidDocumentError: When document text is empty or invalid\n            - ChunkingUnavailableError: When chunking service is unavailable\n\n    Note:\n        Emits metrics for failures, updates job lifecycle\n\n    Example:\n        &gt;&gt;&gt; request = ChunkingRequest(\n        ...     document_id=\"doc1\",\n        ...     text=\"Sample document text\",\n        ...     strategy=\"section\"\n        ... )\n        &gt;&gt;&gt; result = coordinator.execute(request)\n        &gt;&gt;&gt; assert len(result.chunks) &gt; 0\n    \"\"\"\n</code></pre>"},{"location":"contributing/documentation_standards/#dataclass-docstrings","title":"Dataclass Docstrings","text":"<p>Dataclasses should document each field:</p> <pre><code>@dataclass\nclass ChunkingRequest:\n    \"\"\"Request for chunking operation.\n\n    Attributes:\n        document_id: Unique identifier for document being chunked\n        text: Optional document text (can also be in options[\"text\"])\n        strategy: Chunking strategy name (e.g., \"section\", \"semantic\"), defaults to \"section\"\n        chunk_size: Maximum tokens per chunk, defaults to profile setting\n        overlap: Token overlap between chunks, defaults to profile setting\n        options: Additional metadata and configuration\n    \"\"\"\n    document_id: str\n    text: str | None = None\n    strategy: str = \"section\"\n    chunk_size: int | None = None\n    overlap: int | None = None\n    options: dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"contributing/documentation_standards/#section-headers","title":"Section Headers","text":"<p>Code should be organized into labeled sections with consistent ordering:</p>"},{"location":"contributing/documentation_standards/#gateway-coordinator-module-structure","title":"Gateway Coordinator Module Structure","text":"<pre><code># ============================================================================\n# IMPORTS\n# ============================================================================\n# (stdlib imports)\n# (blank line)\n# (third-party imports)\n# (blank line)\n# (first-party imports from Medical_KG_rev)\n# (blank line)\n# (relative imports)\n\n# ============================================================================\n# REQUEST/RESPONSE MODELS\n# ============================================================================\n# (Dataclasses for request and result types used by coordinator)\n\n# ============================================================================\n# COORDINATOR IMPLEMENTATION\n# ============================================================================\n# (Main coordinator class with __init__ and public execute method)\n\n# ============================================================================\n# PRIVATE HELPERS\n# ============================================================================\n# (Private methods for text extraction, metadata handling, etc.)\n\n# ============================================================================\n# ERROR TRANSLATION\n# ============================================================================\n# (Methods for translating exceptions to coordinator errors)\n\n# ============================================================================\n# EXPORTS\n# ============================================================================\n# (__all__ list)\n</code></pre>"},{"location":"contributing/documentation_standards/#service-layer-module-structure","title":"Service Layer Module Structure","text":"<pre><code># ============================================================================\n# IMPORTS\n# ============================================================================\n\n# ============================================================================\n# TYPE DEFINITIONS &amp; CONSTANTS\n# ============================================================================\n\n# ============================================================================\n# SERVICE CLASS DEFINITION\n# ============================================================================\n\n# ============================================================================\n# CHUNKING ENDPOINTS\n# ============================================================================\n\n# ============================================================================\n# EMBEDDING ENDPOINTS\n# ============================================================================\n\n# ============================================================================\n# RETRIEVAL ENDPOINTS\n# ============================================================================\n\n# ============================================================================\n# ADAPTER MANAGEMENT ENDPOINTS\n# ============================================================================\n\n# ============================================================================\n# VALIDATION ENDPOINTS\n# ============================================================================\n\n# ============================================================================\n# EXTRACTION ENDPOINTS\n# ============================================================================\n\n# ============================================================================\n# ADMIN &amp; UTILITY ENDPOINTS\n# ============================================================================\n\n# ============================================================================\n# PRIVATE HELPERS\n# ============================================================================\n</code></pre>"},{"location":"contributing/documentation_standards/#ordering-rules-within-sections","title":"Ordering Rules Within Sections","text":"<ul> <li>Imports: stdlib, third-party, first-party, relative (each group alphabetically sorted)</li> <li>Classes: Base classes before subclasses, interfaces before implementations</li> <li>Class methods: <code>__init__</code> first, public methods (alphabetically), private methods (alphabetically), static/class methods last</li> <li>Functions: Public functions before private functions, alphabetical within each group</li> </ul>"},{"location":"contributing/documentation_standards/#running-checks-locally","title":"Running Checks Locally","text":""},{"location":"contributing/documentation_standards/#ruff-docstring-check","title":"Ruff Docstring Check","text":"<pre><code>ruff check --select D src/Medical_KG_rev/gateway src/Medical_KG_rev/services src/Medical_KG_rev/orchestration\n</code></pre>"},{"location":"contributing/documentation_standards/#section-header-check","title":"Section Header Check","text":"<pre><code>python scripts/check_section_headers.py\n</code></pre>"},{"location":"contributing/documentation_standards/#docstring-coverage-check","title":"Docstring Coverage Check","text":"<pre><code>python scripts/check_docstring_coverage.py --min-coverage 90\n</code></pre>"},{"location":"contributing/documentation_standards/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Install pre-commit hooks to run checks automatically:</p> <pre><code>pre-commit install\npre-commit run --all-files\n</code></pre>"},{"location":"contributing/documentation_standards/#interpreting-errors","title":"Interpreting Errors","text":""},{"location":"contributing/documentation_standards/#common-ruff-docstring-errors","title":"Common Ruff Docstring Errors","text":"<ul> <li>D100: Missing docstring in public module</li> <li>Fix: Add module docstring at top of file</li> <li>D101: Missing docstring in public class</li> <li>Fix: Add docstring immediately after class definition</li> <li>D102: Missing docstring in public method</li> <li>Fix: Add docstring immediately after method definition</li> <li>D103: Missing docstring in public function</li> <li>Fix: Add docstring immediately after function definition</li> <li>D107: Missing docstring in init</li> <li>Fix: Add docstring to init method</li> </ul>"},{"location":"contributing/documentation_standards/#section-header-errors","title":"Section Header Errors","text":"<ul> <li>Missing section header: Add required section headers per <code>section_headers.md</code></li> <li>Incorrect order: Reorder sections to match canonical order</li> <li>Missing content: Ensure each section contains appropriate code</li> </ul>"},{"location":"contributing/documentation_standards/#docstring-coverage-errors","title":"Docstring Coverage Errors","text":"<ul> <li>Coverage &lt; 90%: Add docstrings to modules, classes, and functions</li> <li>Missing Args section: Add Args section for functions with parameters</li> <li>Missing Returns section: Add Returns section for functions that return values</li> <li>Missing Raises section: Add Raises section for functions that raise exceptions</li> </ul>"},{"location":"contributing/documentation_standards/#templates","title":"Templates","text":"<p>Reference templates in <code>openspec/changes/add-pipeline-structure-documentation/templates/</code>:</p> <ul> <li><code>module_docstring.py</code>: Module-level docstring template</li> <li><code>class_docstring.py</code>: Class-level docstring template</li> <li><code>function_docstring.py</code>: Function-level docstring template</li> <li><code>dataclass_docstring.py</code>: Dataclass docstring template</li> <li><code>protocol_docstring.py</code>: Protocol docstring template</li> <li><code>exception_handler_docstring.py</code>: Exception handler docstring template</li> <li><code>async_docstring.py</code>: Async function docstring template</li> <li><code>decorator_docstring.py</code>: Decorator docstring template</li> <li><code>property_docstring.py</code>: Property docstring template</li> <li><code>constant_docstring.py</code>: Constant docstring template</li> <li><code>test_docstring.py</code>: Test function docstring template</li> </ul>"},{"location":"contributing/documentation_standards/#examples","title":"Examples","text":""},{"location":"contributing/documentation_standards/#before-poor-documentation","title":"Before (Poor Documentation)","text":"<pre><code>def chunk_text(text, strategy=\"section\"):\n    chunks = []\n    # ... implementation\n    return chunks\n</code></pre>"},{"location":"contributing/documentation_standards/#after-good-documentation","title":"After (Good Documentation)","text":"<pre><code>def chunk_text(text: str, strategy: str = \"section\") -&gt; list[DocumentChunk]:\n    \"\"\"Chunk document text into smaller segments.\n\n    Splits the input text into chunks using the specified strategy.\n    Each chunk contains a portion of the original text with metadata.\n\n    Args:\n        text: The document text to chunk. Must be non-empty string.\n        strategy: Chunking strategy to use. Valid values: \"section\", \"semantic\".\n            Defaults to \"section\".\n\n    Returns:\n        List of DocumentChunk objects containing:\n            - content: The chunk text content\n            - metadata: Chunk metadata including position and strategy\n\n    Raises:\n        ValueError: If text is empty or strategy is invalid\n        ChunkingError: If chunking operation fails\n\n    Example:\n        &gt;&gt;&gt; chunks = chunk_text(\"This is a sample document.\", \"section\")\n        &gt;&gt;&gt; assert len(chunks) &gt; 0\n        &gt;&gt;&gt; assert chunks[0].content == \"This is a sample document.\"\n    \"\"\"\n    if not text:\n        raise ValueError(\"Text cannot be empty\")\n\n    # ... implementation\n    return chunks\n</code></pre>"},{"location":"contributing/documentation_standards/#best-practices","title":"Best Practices","text":"<ol> <li>Write docstrings first: Document the interface before implementing</li> <li>Be specific: Include exact parameter types, valid ranges, and constraints</li> <li>Include examples: Show typical usage patterns</li> <li>Document side effects: Mention metrics, logging, external calls</li> <li>Keep docstrings up to date: Update when changing function signatures</li> <li>Use type hints: Complement docstrings with type annotations</li> <li>Add inline comments: Explain complex logic and design decisions</li> </ol>"},{"location":"contributing/documentation_standards/#getting-help","title":"Getting Help","text":"<ul> <li>Check existing code for examples of good documentation</li> <li>Refer to the templates in the <code>templates/</code> directory</li> <li>Run the automated checks to identify specific issues</li> <li>Ask team members for review and feedback</li> </ul>"},{"location":"devops/ci-cd/","title":"CI/CD Pipeline","text":"<p>The Medical KG repository ships with a comprehensive GitHub Actions pipeline that enforces code quality, contract compliance, and automated deployments.</p>"},{"location":"devops/ci-cd/#workflow-overview","title":"Workflow Overview","text":"Job Purpose Lint &amp; Static Analysis Runs Black, Ruff, and MyPy against <code>src/</code> and <code>tests/</code> to ensure formatting and type safety. Unit Tests Executes the full pytest suite (excluding load tests) with coverage reporting. Coverage artifacts are uploaded for inspection. Integration Tests Boots the local Docker Compose stack (gateway, Kafka, Neo4j, OpenSearch) and runs gateway, orchestration, and service integration tests. Contract Validation Executes pytest contract suites, Schemathesis fuzzing, GraphQL Inspector diff, and Buf breaking-change detection against <code>origin/main</code>. Performance Tests Nightly/dispatch job executing k6 scenarios (<code>retrieve_latency</code>, <code>ingest_throughput</code>, <code>concurrency</code>) with latency thresholds. Docker Image Builds and pushes <code>ghcr.io/&lt;org&gt;/medical-kg</code> images tagged with the commit SHA and <code>latest</code>. Deploy Staging Applies the Kubernetes overlay in <code>ops/k8s/overlays/staging</code> automatically for commits on <code>main</code>. Deploy Production Requires manual approval before applying the production overlay; runs only on <code>main</code>. Docs Builds the MkDocs site and publishes to GitHub Pages. Branch Protection Optional workflow-dispatch job that enforces protection rules using <code>peter-evans/create-or-update-branch-protection</code>."},{"location":"devops/ci-cd/#required-secrets","title":"Required Secrets","text":"Secret Description <code>GITHUB_TOKEN</code> Provided automatically; used for pushing container images and docs. <code>ADMIN_TOKEN</code> Personal access token with <code>repo</code> and <code>admin:repo_hook</code> scope for branch protection automation. <code>KUBE_CONFIG</code> (optional) When supplied, enables direct <code>kubectl</code> access during deployment steps."},{"location":"devops/ci-cd/#running-locally","title":"Running Locally","text":"<pre><code>poetry install --with dev\npytest\npytest tests/contract\nschemathesis run --app=Medical_KG_rev.gateway.app:create_app docs/openapi.yaml\n</code></pre> <p>Use <code>docker compose -f ops/docker-compose.yml up</code> to reproduce the integration environment before running tests.</p>"},{"location":"devops/kubernetes/","title":"Kubernetes Deployment","text":"<p>Kustomize manifests under <code>ops/k8s/</code> support both staging and production environments.</p>"},{"location":"devops/kubernetes/#base-resources","title":"Base Resources","text":"<ul> <li>Namespace \u2013 <code>medical-kg</code> isolates all gateway workloads.</li> <li>ConfigMap / Secret \u2013 Provide runtime configuration and Sentry DSN injection.</li> <li>Deployments \u2013 <code>gateway</code> (FastAPI) and <code>ingest-worker</code> (background processing).</li> <li>Service &amp; Ingress \u2013 Expose the HTTP gateway via <code>medical-kg.local</code> (override host in overlays).</li> <li>HorizontalPodAutoscaler \u2013 Scales the gateway between 2 and 6 replicas targeting 70% CPU.</li> </ul>"},{"location":"devops/kubernetes/#overlays","title":"Overlays","text":"Overlay Purpose <code>staging</code> Single replica deployments with staging container tags. Useful for QA clusters. <code>production</code> Multi-replica deployments using the <code>latest</code> image tag and higher replica counts."},{"location":"devops/kubernetes/#deployment-workflow","title":"Deployment Workflow","text":"<pre><code># Staging\nkubectl apply -k ops/k8s/overlays/staging\n\n# Production (requires manual approval in CI)\nkubectl apply -k ops/k8s/overlays/production\n</code></pre> <p>Update <code>ops/k8s/base/configmap-gateway.yaml</code> for telemetry endpoints (Jaeger, OTLP) and supply secrets via the <code>gateway-sentry</code> secret or an external secret manager.</p>"},{"location":"devops/local-environments/","title":"Local Environments","text":"<p>The repository provides a fully integrated Docker Compose stack for development and QA located at <code>ops/docker-compose.yml</code>.</p>"},{"location":"devops/local-environments/#services","title":"Services","text":"Service Purpose <code>gateway</code> FastAPI multi-protocol gateway with metrics, tracing, and Sentry hooks. <code>kafka</code> / <code>zookeeper</code> Event bus for ingestion orchestration. <code>neo4j</code> Knowledge graph backing store. <code>opensearch</code> Vector + document search index. <code>jaeger</code> Trace collection and visualization. <code>prometheus</code> Metrics storage. <code>grafana</code> Dashboarding. <code>loki</code> / <code>promtail</code> Structured log aggregation."},{"location":"devops/local-environments/#usage","title":"Usage","text":"<pre><code>cp .env.example .env\ndocker compose -f ops/docker-compose.yml up --build\n# Access services:\n# Gateway: http://localhost:8000\n# Grafana: http://localhost:3000 (admin/admin)\n# Prometheus: http://localhost:9090\n# Jaeger: http://localhost:16686\n</code></pre> <p>Use <code>docker compose down -v</code> to stop the stack and remove volumes.</p>"},{"location":"devops/local-environments/#health-checks","title":"Health Checks","text":"<p>Each service defines <code>healthcheck</code> commands. The helper script <code>scripts/wait_for_services.sh</code> waits until the gateway exposes <code>/openapi.json</code>, ensuring readiness for integration tests.</p>"},{"location":"devops/observability/","title":"Observability Stack","text":"<p>The platform emits structured logs, metrics, traces, and error reports to provide full visibility into gateway operations.</p>"},{"location":"devops/observability/#metrics","title":"Metrics","text":"<ul> <li>Prometheus endpoint \u2013 <code>/metrics</code> exposes default and custom metrics (<code>api_requests_total</code>, <code>job_duration_seconds</code>, <code>business_events_total</code>, <code>gpu_utilization_percent</code>).</li> <li>Custom counters \u2013 Business events increment when ingestion or retrieval logic runs. Histograms capture request and job durations.</li> <li>GPU telemetry \u2013 Utilization gauges derive from the CUDA runtime when available; otherwise, values default to <code>0</code>.</li> </ul> <p>Prometheus is configured via <code>ops/monitoring/prometheus.yml</code> and loaded automatically in Docker Compose and Kubernetes deployments.</p>"},{"location":"devops/observability/#distributed-tracing","title":"Distributed Tracing","text":"<ul> <li>OpenTelemetry instrumentation wraps FastAPI and gRPC servers via <code>Medical_KG_rev/observability/tracing.py</code>.</li> <li>Traces default to Jaeger exporters in Docker Compose; override with <code>MK_TELEMETRY__EXPORTER</code> and <code>MK_TELEMETRY__ENDPOINT</code>.</li> <li>Correlation IDs propagate through logs, traces, and HTTP headers (<code>X-Correlation-ID</code>).</li> </ul>"},{"location":"devops/observability/#logging","title":"Logging","text":"<ul> <li>Logs are JSON-formatted with sensitive fields redacted per <code>LoggingSettings.scrub_fields</code>.</li> <li>Correlation IDs are generated by middleware and attached to every log line and span.</li> <li>Loki and Promtail aggregate container logs in local environments. Update <code>ops/monitoring/promtail-config.yml</code> to tail additional paths.</li> </ul>"},{"location":"devops/observability/#dashboards-alerts","title":"Dashboards &amp; Alerts","text":"<p>Grafana dashboards reside in <code>ops/monitoring/grafana/dashboards/</code>:</p> <ul> <li><code>system_health.json</code> \u2013 request rate, error rate, and latency overview.</li> <li><code>api_latency.json</code> \u2013 per-endpoint latency tables.</li> <li><code>gpu_utilization.json</code> \u2013 GPU memory usage.</li> <li><code>job_processing.json</code> \u2013 job duration histograms and business counters.</li> </ul> <p>Prometheus alert rules in <code>ops/monitoring/alerts.yml</code> cover latency regressions and error spikes.</p>"},{"location":"devops/observability/#error-tracking","title":"Error Tracking","text":"<p>Sentry integration is controlled via <code>MK_OBSERVABILITY__SENTRY__DSN</code>. When set, the middleware adds FastAPI and logging integrations with contextual tags (environment, correlation ID). Configure alert policies directly in Sentry.</p>"},{"location":"devops/vllm-deployment/","title":"vLLM Split-Container Deployment Guide","text":"<p>This guide walks through provisioning the vLLM server and MinerU workers across development and production environments.</p>"},{"location":"devops/vllm-deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster with NVIDIA GPU nodes (RTX 5090 or comparable)</li> <li>NVIDIA device plugin and drivers installed</li> <li>Container registry access for MinerU worker image</li> <li>Prometheus and Grafana stack deployed (for metrics + dashboards)</li> </ul>"},{"location":"devops/vllm-deployment/#1-local-validation","title":"1. Local Validation","text":"<ol> <li>Launch the vLLM server locally:    <code>bash    docker compose -f docker-compose.vllm.yml up -d vllm-server    curl http://localhost:8000/health</code></li> <li>Start a MinerU worker and run the smoke test:    <code>bash    docker compose up -d mineru-worker    bash scripts/test_vllm_api.sh</code></li> <li>Run targeted unit tests:    <code>bash    PYTHONPATH=src pytest tests/services/mineru -k vllm -v</code></li> </ol>"},{"location":"devops/vllm-deployment/#2-build-images","title":"2. Build Images","text":"<ol> <li>Build and push the worker image:    <code>bash    docker build -f ops/docker/Dockerfile.mineru-worker -t ghcr.io/your-org/mineru-worker:split-container .    docker push ghcr.io/your-org/mineru-worker:split-container</code></li> <li>Pull the official <code>vllm/vllm-openai</code> image and tag the approved version.</li> </ol>"},{"location":"devops/vllm-deployment/#3-deploy-to-kubernetes","title":"3. Deploy to Kubernetes","text":"<p>Apply the manifests in the recommended order:</p> <pre><code>kubectl apply -f ops/k8s/base/pvc-huggingface-cache.yaml\nkubectl apply -f ops/k8s/base/configmap-vllm-server.yaml\nkubectl apply -f ops/k8s/base/deployment-vllm-server.yaml\nkubectl apply -f ops/k8s/base/service-vllm-server.yaml\nkubectl apply -f ops/k8s/base/networkpolicy-vllm-server.yaml\nkubectl apply -f ops/k8s/base/deployment-mineru-workers.yaml\nkubectl apply -f ops/k8s/base/servicemonitor-vllm-server.yaml\n</code></pre> <p>Verify:</p> <pre><code>kubectl get pods -n medical-kg | grep -E 'vllm|mineru'\n</code></pre>"},{"location":"devops/vllm-deployment/#4-post-deployment-validation","title":"4. Post-Deployment Validation","text":"<ol> <li>Execute the smoke script within a worker pod:    <code>bash    kubectl exec -n medical-kg deployment/mineru-workers -- bash /app/scripts/test_vllm_api.sh</code></li> <li>Confirm metrics ingestion by querying Prometheus for <code>mineru_vllm_request_duration_seconds</code>.</li> <li>Import the Grafana dashboard:    <code>bash    curl -X POST http://grafana:3000/api/dashboards/import \\      -H \"Content-Type: application/json\" \\      -d @ops/monitoring/grafana/dashboards/vllm-server.json</code></li> </ol>"},{"location":"devops/vllm-deployment/#5-rollback-strategy","title":"5. Rollback Strategy","text":"<ul> <li><code>kubectl rollout undo deployment/vllm-server -n medical-kg</code></li> <li><code>kubectl rollout undo deployment/mineru-workers -n medical-kg</code></li> </ul> <p>Always scale workers to zero before rolling back the vLLM deployment to avoid request failures.</p>"},{"location":"devops/vllm-deployment/#6-operational-checklist","title":"6. Operational Checklist","text":"<ul> <li>[ ] vLLM <code>/health</code> endpoint returns 200</li> <li>[ ] MinerU worker readiness probes are green</li> <li>[ ] Prometheus is scraping <code>vllm_*</code> and <code>mineru_vllm_*</code> series</li> <li>[ ] Grafana dashboard updated with live data</li> <li>[ ] Alertmanager receiving notifications from <code>alerts-vllm.yml</code></li> </ul> <p>Keep this guide alongside the runbook to accelerate operational tasks and incident response.</p>"},{"location":"guides/adapter-sdk/","title":"Adapter SDK Guide","text":"<p>The adapter SDK makes it straightforward to add new biomedical data sources by standardising the ingestion lifecycle.</p>"},{"location":"guides/adapter-sdk/#lifecycle","title":"Lifecycle","text":"<ol> <li><code>fetch(request)</code> \u2192 Pull raw payloads from an upstream service and return an    <code>AdapterResponse</code> envelope.</li> <li><code>parse(response, request)</code> \u2192 Transform payloads into canonical IR objects    such as <code>Document</code> instances.</li> <li><code>validate(response, request)</code> \u2192 Enforce structural rules before the    orchestrator persists or forwards the documents.</li> </ol> <p>The <code>AdapterPluginManager</code> materialises this lifecycle as an <code>AdapterPipeline</code>. When you call <code>manager.invoke(name, request)</code> the manager returns an <code>AdapterInvocationResult</code> containing the underlying <code>AdapterExecutionContext</code>, canonical response, validation outcome, and detailed stage timings. The historic <code>execute</code>/<code>run</code> helpers now build on top of <code>invoke</code>\u2014<code>execute</code> returns the context while <code>run</code> continues to raise when the pipeline cannot produce a valid <code>AdapterResponse</code>.</p>"},{"location":"guides/adapter-sdk/#registry","title":"Registry","text":"<p>Adapters are registered with the pluggy-backed <code>Medical_KG_rev.adapters.AdapterPluginManager</code>. Registration may happen at runtime (e.g. <code>manager.register(ClinicalTrialsAdapterPlugin())</code>) or via entry points declared in <code>pyproject.toml</code>. The manager groups adapters by domain, exposes metadata through the gateway, and drives orchestration execution.</p>"},{"location":"guides/adapter-sdk/#yaml-configuration","title":"YAML Configuration","text":"<p>The SDK includes <code>load_adapter_config</code> to parse YAML descriptors that map HTTP requests to IR fields. These descriptors produce legacy adapter classes that can be wrapped by domain-specific plugins (e.g. <code>ClinicalTrialsAdapterPlugin</code>) while teams incrementally migrate business logic into first-class plugin implementations.</p>"},{"location":"guides/adapter-sdk/#testing","title":"Testing","text":"<p>Instantiate a plugin directly (or use <code>AdapterPluginManager</code>) to exercise the full lifecycle in tests. Using the manager exposes the pipeline context and telemetry so you can assert on intermediate artefacts and timings:</p> <pre><code>request = AdapterRequest(\n    tenant_id=\"tenant\", correlation_id=\"corr\", domain=AdapterDomain.BIOMEDICAL\n)\nmanager = AdapterPluginManager()\nmanager.register(ClinicalTrialsAdapterPlugin())\nresult = manager.invoke(\"clinicaltrials\", request)\nassert result.ok\nassert result.metrics.duration_ms &gt; 0\nassert result.response is not None\n</code></pre>"},{"location":"guides/chunking-profiles/","title":"Chunking Profiles","text":"<p>Profile-driven chunking standardizes how different biomedical sources are processed. Each profile specifies the target token budget, section alignment, sentence segmenter, and filter pipeline.</p>"},{"location":"guides/chunking-profiles/#profile-overview","title":"Profile Overview","text":"Profile Domain Chunker Sentence Segmenter Key Metadata <code>pmc-imrad</code> Literature LangChain RecursiveCharacterTextSplitter with IMRaD-aware metadata hooks Hugging Face tokenizer (abbreviation merging enabled) <code>Abstract</code>, <code>Introduction</code>, <code>Methods</code>, <code>Results</code>, <code>Discussion</code>, with provenance offsets <code>ctgov-registry</code> Clinical trials Custom registry chunker built on <code>SentenceWindowNodeParser</code> syntok Eligibility, Outcome, Adverse Event, Results sections <code>spl-label</code> Drug labels SPL-aware recursive chunker with LOINC mapping Hugging Face tokenizer Indications, Dosage, Warnings, Adverse Reactions, Clinical Pharmacology <code>guideline</code> Clinical guidelines Recommendation/evidence chunker with heuristic paragraph aggregation syntok Recommendation statements, evidence summaries, strength/grade metadata"},{"location":"guides/chunking-profiles/#configuration-files","title":"Configuration Files","text":"<p>Configuration lives under <code>config/chunking/profiles/*.yaml</code>. Example excerpt from <code>pmc-imrad</code>:</p> <pre><code>name: pmc-imrad\ndomain: literature\ntarget_tokens: 800\nsentence_splitter: huggingface\nchunker:\n  type: langchain\n  options:\n    splitter: recursive\nfilters:\n  - boilerplate\n  - deduplicate-furniture\n  - prune-references\n</code></pre> <p>To load profiles programmatically:</p> <pre><code>from Medical_KG_rev.services.chunking.profiles.loader import load_profiles\n\nprofiles = load_profiles()\nimrad = profiles[\"pmc-imrad\"]\nprint(imrad.target_tokens)\n</code></pre>"},{"location":"guides/chunking-profiles/#extending-profiles","title":"Extending Profiles","text":"<ol> <li>Create a new YAML file under <code>config/chunking/profiles/</code>.</li> <li>Add the profile to the chunker registry via    <code>Medical_KG_rev.services.chunking.registry.register_profile</code>.</li> <li>Update documentation and run <code>pytest tests/chunking/test_profiles.py</code>.</li> <li>Verify the profile-specific chunker passes <code>scripts/check_chunking_dependencies.py</code>.</li> </ol>"},{"location":"guides/chunking-profiles/#operational-guidelines","title":"Operational Guidelines","text":"<ul> <li>Keep token budgets under the embedding model limit with a 10% safety margin.</li> <li>Ensure every chunk emits <code>section_label</code>, <code>intent_hint</code>, and ordered   <code>char_offsets</code>.</li> <li>Document fallback behavior (naive sentence splitting) in case of tokenizer   failures and monitor via Prometheus metrics.</li> </ul>"},{"location":"guides/chunking-profiles/#related-resources","title":"Related Resources","text":"<ul> <li>Chunking &amp; Parsing Runtime Guide</li> <li>MinerU Two-Phase Gate Runbook</li> </ul>"},{"location":"guides/chunking/","title":"Chunking &amp; Parsing Runtime","text":"<p>The legacy bespoke chunkers have been removed in favor of a reusable runtime that delegates to best-in-class open source libraries. This guide explains how to work with the new system, how to select profile-specific chunkers, and how to validate dependencies during deployment.</p>"},{"location":"guides/chunking/#runtime-overview","title":"Runtime Overview","text":"<pre><code>flowchart TD\n    A[Document IR] --&gt; B[Filter Pipeline]\n    B --&gt; C[Sentence Segmenter]\n    C --&gt; D[ChunkerPort Implementation]\n    D --&gt; E[Chunk Schema Validator]\n    E --&gt; F[Chunk Set + Provenance Metadata]\n</code></pre> <ol> <li>Filter Pipeline \u2013 Removes boilerplate, deduplicates repeated furniture,    and preserves uncertain tables as HTML fragments.</li> <li>Sentence Segmenter \u2013 Uses a Hugging Face tokenizer configured through    <code>MEDICAL_KG_SENTENCE_MODEL</code>. A heuristics-only fallback is available for    development environments without the model download.</li> <li>ChunkerPort Implementation \u2013 Selected via profile registry and backed by    langchain-text-splitters or llama-index node parsers.</li> <li>Chunk Schema Validator \u2013 Enforces ordered offsets, provenance metadata,    and domain-specific section labels before returning results.</li> </ol>"},{"location":"guides/chunking/#installing-dependencies","title":"Installing Dependencies","text":"<p>Use the helper script to provision a clean virtual environment with all optional dependencies:</p> <pre><code>bash scripts/install_chunking_dependencies.sh \\\n  --venv .venv-chunking \\\n  --hf-model sentence-transformers/all-MiniLM-L6-v2\n</code></pre> <p>The installer upgrades <code>pip</code>, pins the required packages, downloads the Hugging Face tokenizer, and finally executes <code>scripts/check_chunking_dependencies.py</code>. When run from Python 3.12, the check reports a warning for <code>unstructured==0.12.0</code> because that release requires Python 3.11; production deployments should execute the installer from the supported runtime or select a newer compatible version.</p>"},{"location":"guides/chunking/#chunking-from-code","title":"Chunking from Code","text":"<pre><code>from Medical_KG_rev.services.chunking import chunk_document\nfrom Medical_KG_rev.ir import Document\n\nchunks = chunk_document(document, profile=\"pmc-imrad\")\nfor chunk in chunks:\n    print(chunk.section_label, chunk.intent_hint, chunk.char_offsets)\n</code></pre> <p>The runtime automatically registers default profiles on import. Custom profiles can be loaded from YAML via <code>Medical_KG_rev.services.chunking.profiles.loader.load_profiles</code> and passed to <code>runtime.assemble_runtime</code> for advanced use cases.</p>"},{"location":"guides/chunking/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Missing Hugging Face model \u2013 Run the installer with <code>--hf-model</code> or set   <code>MEDICAL_KG_SENTENCE_MODEL</code> prior to invoking chunkers.</li> <li>LangChain import errors \u2013 Ensure <code>pydantic==2.10.6</code> (or later) is   installed; earlier versions bundled with Python 3.12 trigger <code>ForwardRef</code>   errors.</li> <li>unstructured import errors \u2013 Install from a Python 3.11 runtime or upgrade   to a release that supports Python 3.12.</li> </ul>"},{"location":"guides/chunking/#related-documentation","title":"Related Documentation","text":"<ul> <li>Chunking Profiles</li> <li>MinerU Two-Phase Gate Runbook</li> <li>OpenSpec Change: add-parsing-chunking-normalization</li> </ul>"},{"location":"guides/data-models/","title":"Data Models Guide","text":"<p>This guide describes the federated intermediate representation (IR) and related models defined in <code>Medical_KG_rev.models</code>.</p>"},{"location":"guides/data-models/#core-ir","title":"Core IR","text":"<ul> <li><code>Document</code> \u2192 Top-level container with sections, metadata and provenance.</li> <li><code>Section</code> \u2192 Grouping of <code>Block</code> instances.</li> <li><code>Block</code> \u2192 Atomic textual unit such as paragraph, table or figure.</li> <li><code>Span</code> \u2192 Character offsets within blocks used to maintain traceability back to   source documents.</li> </ul> <p>Validation is strict: blocks require unique identifiers, spans must be ordered and constrained by the owning block content, and documents enforce UTC timestamps.</p>"},{"location":"guides/data-models/#entities-and-evidence","title":"Entities and Evidence","text":"<ul> <li><code>Entity</code> \u2192 Canonical concept linked to spans.</li> <li><code>Claim</code> \u2192 Semantic assertion relating entities.</li> <li><code>Evidence</code> \u2192 Supporting snippet tying claims/entities back to the document.</li> <li><code>ExtractionActivity</code> \u2192 Provenance metadata indicating how an artifact was   derived.</li> </ul>"},{"location":"guides/data-models/#domain-overlays","title":"Domain Overlays","text":"<ul> <li><code>MedicalDocument</code> \u2192 Adds <code>ResearchStudy</code> metadata and <code>EvidenceAssessment</code>   alignments with FHIR resources.</li> <li><code>FinancialDocument</code> \u2192 Encapsulates XBRL contexts and facts.</li> <li><code>LegalDocument</code> \u2192 Captures legal clauses and references consistent with   LegalDocML.</li> </ul> <p>Each overlay enforces domain-specific rules while remaining compatible with the core IR.</p>"},{"location":"guides/embedding_adapters/","title":"Embedding Adapter Developer Guide","text":"<p>This guide describes the process for adding new embedders to the universal embedding subsystem. All adapters must implement the <code>BaseEmbedder</code> protocol and return <code>EmbeddingRecord</code> instances that conform to namespace governance rules.</p>"},{"location":"guides/embedding_adapters/#1-choose-the-namespace","title":"1. Choose the Namespace","text":"<p>Namespaces follow the pattern <code>{kind}.{model}.{dim}.{version}</code>. Dense single-vector adapters typically use a <code>single_vector</code> prefix while multi-vector adapters use <code>multi_vector</code>. If your adapter can auto-discover dimensionality, set the namespace dim segment to <code>auto</code> and rely on the namespace manager to record the observed value.</p>"},{"location":"guides/embedding_adapters/#2-implement-the-adapter","title":"2. Implement the Adapter","text":"<ol> <li>Import the protocol and registry helpers:    <code>python    from Medical_KG_rev.embeddings.ports import BaseEmbedder, EmbedderConfig, EmbeddingRecord, EmbeddingRequest    from Medical_KG_rev.embeddings.registry import EmbedderRegistry</code></li> <li>Implement the adapter class with <code>embed_documents()</code> and <code>embed_queries()</code> methods.</li> <li>Populate <code>EmbeddingRecord.metadata</code> with provider information and any adapter-specific fields (e.g. offsets, shard IDs).</li> <li>Register the adapter in <code>Medical_KG_rev.embeddings.providers.register_builtin_embedders()</code>.</li> </ol>"},{"location":"guides/embedding_adapters/#3-dimension-validation","title":"3. Dimension Validation","text":"<p>The <code>NamespaceManager</code> validates dimensionality for every record. Ensure the adapter sets the <code>dim</code> field for dense vectors or stores the effective dimension in the first vector. Sparse adapters should populate <code>terms</code> and neural sparse adapters should set <code>neural_fields</code>.</p>"},{"location":"guides/embedding_adapters/#4-batch-processing-and-progress-reporting","title":"4. Batch Processing and Progress Reporting","text":"<p>Adapters that support batch inference should use the batching utilities in <code>Medical_KG_rev.embeddings.utils.batching</code>. These helpers provide progress callbacks that log batch completion without requiring external libraries.</p>"},{"location":"guides/embedding_adapters/#5-testing-checklist","title":"5. Testing Checklist","text":"<ul> <li>Unit test the adapter in isolation with deterministic embeddings.</li> <li>Add contract tests verifying compliance with the <code>BaseEmbedder</code> protocol.</li> <li>If the adapter introduces new storage targets, extend <code>StorageRouter</code> with custom handlers.</li> </ul> <p>For complete examples, review the dense, sparse, multi-vector, and neural sparse adapters in the <code>embeddings/</code> package.</p>"},{"location":"guides/embedding_catalog/","title":"Embedding Adapter Catalog","text":"<p>The hard cutover to the standardized embedding stack replaces bespoke implementations with a small set of library-backed adapters. The table below lists the production namespaces committed with this change.</p> Adapter Kind Namespace Provider Notes <code>OpenAICompatEmbedder</code> <code>single_vector</code> <code>single_vector.qwen3.4096.v1</code> vLLM (OpenAI compatible) Delegates to the GPU-only vLLM server hosting Qwen3-Embedding-8B and returns normalized 4096-d vectors. <code>PyseriniSparseEmbedder</code> <code>sparse</code> <code>sparse.splade_v3.400.v1</code> Pyserini SPLADE Generates learned sparse term weights for OpenSearch <code>rank_features</code> storage with safe empty-text handling. <code>ColbertIndexerEmbedder</code> <code>multi_vector</code> <code>multi_vector.colbert_v2.128.v1</code> ColBERT Late-interaction embeddings backed by FAISS shards for reranking and multi-vector retrieval. <p>Legacy adapters (SentenceTransformers, TEI, LangChain, etc.) were removed as part of the cutover and can be reinstated only by creating a new namespace YAML file with explicit ownership approval.</p>"},{"location":"guides/embedding_catalog/#namespace-access-control","title":"Namespace Access Control","text":"<p>Every namespace entry now carries explicit access control metadata. The consolidated <code>config/embedding/namespaces.yaml</code> file documents <code>allowed_tenants</code> and <code>allowed_scopes</code> for each namespace. Public vectors such as <code>single_vector.qwen3.4096.v1</code> expose <code>allowed_tenants: [\"all\"]</code>, whereas private namespaces enumerate the specific tenant identifiers.</p> <p>Complementary configuration files:</p> <ul> <li><code>config/embedding/vllm.yaml</code> \u2013 dense embeddings service parameters validated   via <code>Medical_KG_rev.config.load_vllm_config</code>.</li> <li><code>config/embedding/pyserini.yaml</code> \u2013 SPLADE/Pyserini settings consumed by   <code>load_pyserini_config</code> to keep OpenSearch options in sync.</li> </ul> <p>Clients MUST call the discovery endpoint before embedding:</p> <pre><code>GET /v1/namespaces\nAuthorization: Bearer &lt;token&gt;\n</code></pre> <p>The response lists <code>NamespaceInfo</code> objects containing provider, kind, dimension, token budget, and ACL metadata. To proactively check whether texts respect the namespace token budget, call the validation endpoint:</p> <pre><code>POST /v1/namespaces/{namespace}/validate\nContent-Type: application/json\n{\n  \"tenant_id\": \"tenant-123\",\n  \"texts\": [\"...\", \"...\"]\n}\n</code></pre> <p>The API returns per-text token counts and <code>exceeds_budget</code> flags. Both endpoints require the <code>embed:read</code> scope; embedding operations require <code>embed:write</code>.</p>"},{"location":"guides/embedding_catalog/#configuration-examples","title":"Configuration Examples","text":"<p>Namespaces are declared via YAML and hydrated by the runtime registry. The snippet below mirrors the defaults committed to <code>config/embedding/namespaces/</code>.</p> <pre><code>namespaces:\n  single_vector.qwen3.4096.v1:\n    provider: vllm\n    kind: single_vector\n    model_id: Qwen/Qwen2.5-Embedding-8B-Instruct\n    dim: 4096\n    max_tokens: 8192\n    tokenizer: Qwen/Qwen2.5-Coder-1.5B\n    allowed_scopes: [\"embed:read\", \"embed:write\"]\n    allowed_tenants: [\"all\"]\n  sparse.splade_v3.400.v1:\n    provider: pyserini\n    kind: sparse\n    model_id: naver/splade-v3\n    dim: 400\n    max_tokens: 512\n    tokenizer: naver/splade-v3\n    allowed_scopes: [\"embed:read\", \"embed:write\"]\n    allowed_tenants: [\"all\"]\n  multi_vector.colbert_v2.128.v1:\n    provider: colbert\n    kind: multi_vector\n    model_id: colbert-v2\n    dim: 128\n    max_tokens: 512\n    tokenizer: colbert-ir/colbertv2.0\n    allowed_scopes: [\"embed:read\", \"embed:write\"]\n    allowed_tenants: [\"tenant-123\", \"tenant-456\"]\n</code></pre>"},{"location":"guides/embedding_catalog/#deployment-notes","title":"Deployment Notes","text":""},{"location":"guides/embedding_catalog/#vllm-embedding-endpoint","title":"vLLM Embedding Endpoint","text":"<p>Build and run the dedicated embedding container with Docker Compose:</p> <pre><code>docker-compose up -d vllm-qwen3\n</code></pre> <p>The service exposes an OpenAI-compatible <code>/v1/embeddings</code> endpoint on port <code>8001</code> and fails fast when GPU resources are unavailable.</p>"},{"location":"guides/embedding_catalog/#model-materialization","title":"Model Materialization","text":"<p>Use the helper script introduced with this change to fetch the required models ahead of time:</p> <pre><code>python -m scripts.embedding.download_models --format json\n</code></pre> <p>The script downloads Qwen3-Embedding-8B into <code>models/qwen3-embedding-8b/</code> and materializes the SPLADE encoder cache in <code>models/splade-v3/</code>. Pair it with <code>python -m scripts.embedding.verify_environment</code> to confirm GPU and dependency readiness before starting the workers.</p>"},{"location":"guides/embedding_migration/","title":"Migrating from Legacy Embeddings to the vLLM/Pyserini Stack","text":"<p>This guide outlines the steps required to migrate consumers from the retired SentenceTransformers/SPLADE implementation to the new vLLM + Pyserini architecture delivered by the <code>add-embeddings-representation</code> OpenSpec change.</p>"},{"location":"guides/embedding_migration/#1-namespace-selection","title":"1. Namespace Selection","text":"<ol> <li>Identify the target namespace from <code>config/embedding/namespaces/</code>.</li> <li>Update API clients to supply the namespace explicitly:</li> <li>REST: <code>POST /v1/embed { \"namespace\": \"single_vector.qwen3.4096.v1\" }</code></li> <li>GraphQL: <code>embed(input: { namespace: \"single_vector.qwen3.4096.v1\" })</code></li> <li>gRPC: <code>EmbedRequest.namespace</code></li> <li>Remove any legacy model identifiers hard-coded in clients.</li> </ol>"},{"location":"guides/embedding_migration/#2-token-budget-enforcement","title":"2. Token Budget Enforcement","text":"<p>The new tokenizer cache enforces per-model token budgets. Before sending requests, either:</p> <ul> <li>Call the <code>TokenizerCache.ensure_within_limit</code> helper, or</li> <li>Reuse the <code>/v1/embed</code> error response (<code>400 token_limit_exceeded</code>) to   trim documents client-side.</li> </ul> <p>Exact token counting catches 100% of overflows that the legacy approximation missed.</p>"},{"location":"guides/embedding_migration/#3-storage-expectations","title":"3. Storage Expectations","text":"<p>Dense vectors are persisted to FAISS (primary) and surfaced through the vector store service. Sparse vectors are written to OpenSearch using the <code>rank_features</code> field declared in <code>build_rank_features_mapping</code>. Existing callers should stop writing directly to bespoke stores.</p>"},{"location":"guides/embedding_migration/#4-operational-readiness","title":"4. Operational Readiness","text":"<ol> <li>Build the vLLM container: <code>docker-compose build vllm-qwen3</code></li> <li>Provision GPUs and verify <code>python -m scripts.embedding.verify_environment</code>    reports <code>\"gpu\": {\"available\": true}</code>.</li> <li>Pre-download models with    <code>python -m scripts.embedding.download_models --format text</code>.</li> <li>Update observability dashboards to track the new <code>/v1/embeddings</code>    endpoint and GPU utilization metrics.</li> </ol>"},{"location":"guides/embedding_migration/#5-deprecation-timeline","title":"5. Deprecation Timeline","text":"<ul> <li>Day 0: Deploy namespace-aware clients and new embedding worker.</li> <li>Day 7: Remove legacy SentenceTransformers and manual batching code.</li> <li>Day 14: Delete unused model artifacts from object storage.</li> <li>Day 30: Archive the <code>add-embeddings-representation</code> change.</li> </ul> <p>For additional context consult <code>docs/guides/embedding_catalog.md</code> and the OpenSpec design notes.</p>"},{"location":"guides/embedding_namespace_policy/","title":"Embedding Namespace Contracts","text":"<p>This guide summarises the new abstractions that decouple namespace governance from gateway orchestration. It should be referenced by teams extending embedding behaviour or onboarding new storage implementations.</p>"},{"location":"guides/embedding_namespace_policy/#namespaceaccesspolicy","title":"NamespaceAccessPolicy","text":"<p><code>NamespaceAccessPolicy</code> is an abstract base class that centralises namespace validation and routing decisions. Implementations return a <code>NamespaceAccessDecision</code> describing whether a tenant/scope pair may interact with a namespace.</p>"},{"location":"guides/embedding_namespace_policy/#key-capabilities","title":"Key capabilities","text":"<ul> <li>Cached evaluations with eviction to prevent redundant registry lookups.</li> <li>Optional dry-run wrapping via <code>DryRunNamespacePolicy</code> for migrations.</li> <li>Mock/custom policies to support testing and tenant-specific rules.</li> <li>Health/debug snapshots for observability tooling.</li> </ul>"},{"location":"guides/embedding_namespace_policy/#usage-example","title":"Usage example","text":"<pre><code>from Medical_KG_rev.services.embedding.namespace.registry import EmbeddingNamespaceRegistry\nfrom Medical_KG_rev.services.embedding.policy import StandardNamespacePolicy\n\nregistry = EmbeddingNamespaceRegistry()\nregistry.register(\"single_vector.demo.1024.v1\", config)\npolicy = StandardNamespacePolicy(registry)\n\ndecision = policy.evaluate(\n    namespace=\"single_vector.demo.1024.v1\",\n    tenant_id=\"tenant-a\",\n    required_scope=\"embed:write\",\n)\nif not decision.allowed:\n    raise PermissionError(decision.reason)\n</code></pre>"},{"location":"guides/embedding_namespace_policy/#embeddingpersister","title":"EmbeddingPersister","text":"<p><code>EmbeddingPersister</code> abstracts persistence operations, allowing the gateway to call <code>persist_batch</code> without knowledge of the underlying storage topology.</p>"},{"location":"guides/embedding_namespace_policy/#built-in-implementations","title":"Built-in implementations","text":"<ul> <li><code>VectorStorePersister</code> \u2013 persists through the shared <code>StorageRouter</code>.</li> <li><code>DatabasePersister</code> \u2013 maintains Neo4j-compatible snapshots.</li> <li><code>DryRunPersister</code>/<code>MockPersister</code> \u2013 instrumentation for tests.</li> <li><code>HybridPersister</code> \u2013 delegates by embedding kind for hybrid storage strategies.</li> </ul>"},{"location":"guides/embedding_namespace_policy/#usage-example_1","title":"Usage example","text":"<pre><code>from Medical_KG_rev.embeddings.storage import StorageRouter\nfrom Medical_KG_rev.services.embedding.persister import PersistenceContext, VectorStorePersister\n\nrouter = StorageRouter()\npersister = VectorStorePersister(router)\ncontext = PersistenceContext(\n    tenant_id=\"tenant-a\",\n    namespace=\"single_vector.demo.1024.v1\",\n    model=\"demo-model\",\n    provider=\"demo\",\n)\nreport = persister.persist_batch(records, context)\n</code></pre>"},{"location":"guides/embedding_namespace_policy/#embeddingtelemetry","title":"EmbeddingTelemetry","text":"<p><code>EmbeddingTelemetry</code> provides a single instrumentation surface for policies, persisters, and the gateway service. <code>StandardEmbeddingTelemetry</code> logs structured events and records Prometheus metrics (with safe fallbacks when Prometheus is unavailable).</p>"},{"location":"guides/embedding_namespace_policy/#usage-example_2","title":"Usage example","text":"<pre><code>from Medical_KG_rev.services.embedding.telemetry import StandardEmbeddingTelemetry, TelemetrySettings\n\ntelemetry = StandardEmbeddingTelemetry(TelemetrySettings(enable_logging=False))\ntelemetry.record_embedding_completed(\n    namespace=\"single_vector.demo.1024.v1\",\n    tenant_id=\"tenant-a\",\n    model=\"demo-model\",\n    provider=\"demo\",\n    duration_ms=32.4,\n    embeddings=8,\n)\n</code></pre>"},{"location":"guides/embedding_namespace_policy/#gateway-integration","title":"Gateway Integration","text":"<p><code>GatewayService.embed</code> now consumes these abstractions. Namespace access decisions, persistence, and telemetry are injected during <code>GatewayService</code> construction, unlocking clean configuration overrides and simpler testing of embedding flows.</p>"},{"location":"guides/embedding_namespace_policy/#runtime-configuration","title":"Runtime configuration","text":"<p>Namespace policy and persister behaviour are exposed via <code>AppSettings.embedding</code>. Defaults can be overridden through environment variables (<code>MK_EMBEDDING__...</code>) or configuration files.</p> <pre><code>embedding:\n  policy:\n    cache_ttl_seconds: 60.0\n    max_cache_entries: 512\n    dry_run: false\n  persister:\n    backend: vector_store  # vector_store | database | dry_run | hybrid\n    cache_limit: 256\n    hybrid_backends:\n      sparse: database\n      neural_sparse: vector_store\n</code></pre>"},{"location":"guides/embedding_namespace_policy/#administrative-api-endpoints","title":"Administrative API endpoints","text":"<p>The REST router exposes observability and configuration management endpoints secured by the <code>embed:admin</code> scope:</p> <ul> <li><code>GET /v1/namespaces/policy</code> \u2013 current policy status and cache metrics.</li> <li><code>PATCH /v1/namespaces/policy</code> \u2013 update cache TTL, entry limits, or toggle dry-run.</li> <li><code>GET /v1/namespaces/policy/diagnostics</code> \u2013 detailed cache keys and statistics.</li> <li><code>GET /v1/namespaces/policy/health</code> \u2013 health summary suitable for alerts.</li> <li><code>GET /v1/namespaces/policy/metrics</code> \u2013 operational metrics snapshot.</li> <li><code>POST /v1/namespaces/policy/cache/invalidate</code> \u2013 clear cached decisions globally or per-namespace.</li> </ul>"},{"location":"guides/embedding_namespace_policy/#migration-utility","title":"Migration utility","text":"<p>The <code>scripts/migrate_namespace_policy.py</code> helper exports the active policy and persister configuration for auditing or for seeding infrastructure-as-code manifests:</p> <pre><code>python scripts/migrate_namespace_policy.py --output embedding-runtime.json\n</code></pre> <p>The script serialises the runtime configuration using the same abstractions as the gateway, ensuring drift between code and deployment manifests is easy to detect.</p>"},{"location":"guides/embedding_namespace_policy/#testing-and-troubleshooting","title":"Testing and troubleshooting","text":"<ul> <li>Unit tests (<code>tests/services/embedding/test_namespace_policy.py</code>, <code>tests/services/embedding/test_embedding_persister.py</code>) validate caching, dry-run behaviour, and persister routing.</li> <li>Integration tests (<code>tests/gateway/test_gateway_namespace_policy_admin.py</code>) cover the administrative surfaces exposed by <code>GatewayService</code>.</li> <li>The diagnostics endpoint returns cache keys in <code>namespace:tenant:scope</code> form to accelerate debugging of unexpected denials.</li> </ul>"},{"location":"guides/orchestration-pipelines/","title":"Orchestration Pipelines Guide","text":"<p>This guide describes the Dagster-based orchestration stack that replaced the legacy worker pipeline. The gateway and CLI interact with Dagster definitions under <code>Medical_KG_rev.orchestration.dagster</code> and Haystack components under <code>Medical_KG_rev.orchestration.haystack</code>.</p>"},{"location":"guides/orchestration-pipelines/#dagster-architecture","title":"Dagster Architecture","text":"<ul> <li>Stage contracts \u2013 <code>StageContext</code>, <code>ChunkStage</code>, <code>EmbedStage</code>, and other   protocols live in <code>Medical_KG_rev.orchestration.stages.contracts</code>. Dagster ops   call these protocols so stage implementations remain framework-agnostic.</li> <li>Typed pipeline state \u2013 <code>PipelineState</code> is exposed to Dagster as a   first-class type. It enforces stage output validation, records lifecycle   metrics, and surfaces profiling data for observability dashboards.</li> <li>StageFactory \u2013 <code>StageFactory</code> resolves stage definitions from topology   YAML files. The default factory wires Haystack chunking, embedding, and   indexing components while falling back to lightweight stubs for unit tests.</li> <li>Runtime module \u2013 <code>Medical_KG_rev.orchestration.dagster.runtime</code> defines   jobs, resources, and helper utilities (<code>DagsterOrchestrator</code>,   <code>submit_to_dagster</code>). Jobs call the appropriate stage implementation and   update the job ledger after each op.</li> <li>Haystack wrappers \u2013 <code>Medical_KG_rev.orchestration.haystack.components</code>   adapts Haystack classes to the stage protocols. The chunker converts IR   documents into Haystack documents, the embedder produces dense vectors (with   optional sparse expansion), and the index writer dual writes to OpenSearch and   FAISS.</li> </ul>"},{"location":"guides/orchestration-pipelines/#stage-plugin-system","title":"Stage Plugin System","text":"<ul> <li>StagePlugin base class \u2013 <code>StagePlugin</code> in   <code>Medical_KG_rev.orchestration.stages.plugins</code> exposes typed metadata,   dependency declarations, lifecycle hooks (<code>initialize</code>, <code>cleanup</code>,   <code>health_check</code>), and helpers (<code>create_registration</code>) so plugins can register   stage builders with a few lines of code.</li> <li>Lifecycle management \u2013 <code>StagePluginManager</code> keeps a registry of   <code>StagePluginRegistration</code> instances per stage type, orders them using declared   dependencies, and exposes <code>unregister()</code>, <code>describe_plugins()</code>, and   <code>check_health()</code> for operational tooling.</li> <li>Dependency-aware resolution \u2013 Registrations can depend on other plugins by   referencing the fully qualified metadata name (e.g., <code>core-stage.chunk</code>). The   manager topologically sorts registrations before attempting builds, so   fallbacks are only invoked after primary providers fail.</li> <li>Health diagnostics \u2013 Health signals returned from <code>StagePlugin.health_check</code>   are cached on each registration state and surfaced through   <code>describe_plugins()</code>, simplifying automation hooks for dashboards and alerts.</li> </ul>"},{"location":"guides/orchestration-pipelines/#pipeline-configuration","title":"Pipeline Configuration","text":"<ul> <li>Topology YAML \u2013 Pipelines are described in   <code>config/orchestration/pipelines/*.yaml</code>. Each stage lists <code>name</code>, <code>type</code>,   optional <code>policy</code>, dependencies, and a free-form <code>config</code> block. Gates define   resume conditions, e.g., <code>pdf_ir_ready=true</code> for two-phase PDF ingestion.</li> <li>Resilience policies \u2013 <code>config/orchestration/resilience.yaml</code> contains   shared retry, circuit breaker, and rate limiting definitions. The runtime   loads these into Tenacity, PyBreaker, and aiolimiter objects.</li> <li>Version manifest \u2013 <code>config/orchestration/versions/*</code> tracks pipeline   revisions. <code>PipelineConfigLoader</code> loads and caches versions to provide   deterministic orchestration.</li> </ul> <p>Typed dependencies are derived from the stage contracts. For example, an <code>embed</code> stage automatically depends on the most recent <code>chunk</code> stage and the <code>index</code> stage requires <code>embed</code>. Pipelines that omit these prerequisites fail validation during configuration loading instead of during runtime execution.</p>"},{"location":"guides/orchestration-pipelines/#execution-flow","title":"Execution Flow","text":"<ol> <li>Job submission \u2013 The gateway builds a <code>StageContext</code> and calls    <code>submit_to_dagster</code>. The Dagster run stores the initial state using the job    ledger resource.</li> <li>Stage execution \u2013 Each op resolves the stage implementation via    <code>StageFactory</code>. Resilience policies wrap the execution and emit metrics on    retries, circuit breaker state changes, and rate limiting delays.</li> <li>Ledger updates \u2013 Ops record progress to the job ledger (<code>current_stage</code>,    attempt counts, gate metadata). Sensors poll the ledger for gate conditions    (e.g., <code>pdf_ir_ready=true</code>) and resume downstream stages.</li> <li>Outputs \u2013 Stage results are added to the Dagster run state and surfaced    to the gateway through the ledger/SSE stream. Haystack components persist    embeddings and metadata in downstream storage systems.</li> </ol>"},{"location":"guides/orchestration-pipelines/#typed-pipeline-state-lifecycle-hooks","title":"Typed Pipeline State &amp; Lifecycle Hooks","text":"<ul> <li>Dagster type integration \u2013 The orchestration runtime publishes the   <code>PipelineState</code> Dagster type so ops receive runtime validation and better UI   introspection inside Dagster.</li> <li>Lifecycle hooks \u2013 Call <code>state.register_lifecycle_hook(...)</code> to observe   stage start, completion, and failure events. Hooks power metrics, tracing, or   custom auditing without modifying the runtime.</li> <li>Profiling \u2013 Every state instance tracks lightweight profiling samples via   <code>state.profiling_summary()</code> and <code>state.profiling_samples()</code>. These aggregates   capture duration, attempt counts, and output totals per stage.</li> </ul>"},{"location":"guides/orchestration-pipelines/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Stage resolution errors \u2013 Verify the stage <code>type</code> in the topology YAML   matches the plugins registered via <code>build_stage_factory</code>. Unknown stage   matches the stage types advertised by <code>create_stage_plugin_manager</code>. Unknown stage   types raise <code>StageResolutionError</code> during job execution.</li> <li>Resilience misconfiguration \u2013 Check <code>config/orchestration/resilience.yaml</code>   for required fields (attempts, backoff, circuit breaker thresholds). Invalid   policies raise validation errors at load time.</li> <li>Gate stalls \u2013 Inspect the job ledger entry to confirm gate metadata is   set (e.g., <code>pdf_ir_ready</code> for PDF pipelines). Sensors poll every ten seconds   and record trigger counts in the ledger metadata.</li> <li>Missing embeddings \u2013 Ensure the embed stage resolved the Haystack   embedder; stubs return deterministic values for test runs but do not persist   to OpenSearch/FAISS.</li> </ul>"},{"location":"guides/orchestration-pipelines/#operational-notes","title":"Operational Notes","text":"<ul> <li>Run Dagster locally with   <code>dagster dev -m Medical_KG_rev.orchestration.dagster.runtime</code> to access the UI   and sensors.</li> <li>The gateway uses <code>StageFactory</code> directly for synchronous operations (chunking   and embedding APIs) to avoid spinning up full Dagster runs.</li> <li>Dagster daemon processes handle sensors and schedules. Ensure the daemon has   access to the same configuration volume as the webserver and gateway.</li> <li>CloudEvents and OpenLineage emission hooks live alongside the Dagster jobs   and reuse the resilience policy loader for consistent telemetry metadata.</li> </ul>"},{"location":"guides/pipeline_state_management/","title":"Typed Pipeline State Management","text":"<p>The orchestration runtime now persists pipeline state using a typed contract built on Pydantic models, attrs-based caching, and structured logging. The state serialisation flow validates payloads with <code>PipelineStateModel</code> before encoding them using <code>orjson</code> and compressing snapshots for transport.</p>"},{"location":"guides/pipeline_state_management/#runtime-behaviour","title":"Runtime Behaviour","text":"<ul> <li>Stage execution enforces declared <code>depends_on</code> relationships prior to invoking the   stage implementation. If a dependency is missing or failed the runtime raises a   descriptive error to prevent out-of-order execution.</li> <li>PDF pipelines use the new <code>pdf-download</code> and <code>pdf-ir-gate</code> stage types to track gate   progress. The pipeline state captures gate metadata and the job ledger is updated via   <code>JobLedger.set_pdf_downloaded</code> and <code>JobLedger.set_pdf_ir_ready</code> when the stages   complete.</li> <li>Snapshots are cached for 120 seconds using <code>PipelineStateCache</code>. Subsequent   serialisation requests reuse cached payloads, reducing repeated <code>orjson</code> work during   intensive telemetry reporting.</li> <li>Stage metrics are emitted to Prometheus counters and histograms through   <code>record_stage_metrics</code>, providing duration, attempt counts, and failure statistics.</li> <li>The Dagster runtime persists snapshots to the job ledger through   <code>PipelineStatePersister</code>, which applies tenacity-powered retries before surfacing a   <code>StatePersistenceError</code>.</li> </ul>"},{"location":"guides/pipeline_state_management/#developer-guidance","title":"Developer Guidance","text":"<ol> <li>Use <code>PipelineState.to_model()</code> to retrieve a validated representation that can be    safely logged or passed to external systems.</li> <li>When integrating new stages include a <code>depends_on</code> list in topology definitions so    the runtime can enforce the execution order.</li> <li>For PDF workflows emit dictionaries from gate stages to enrich the gate metadata.</li> <li>Use <code>PipelineState.reset_pdf_gate()</code> to restart the gate when reprocessing a PDF    payload.</li> <li>Prefer <code>PipelineState.serialise_json()</code> for logging and    <code>PipelineState.serialise_base64()</code> for durable storage.</li> </ol> <pre><code>from Medical_KG_rev.orchestration.stages.contracts import PipelineState\n\n\ndef handle_state(state: PipelineState) -&gt; None:\n    model = state.to_model()\n    print(model.context.tenant_id)\n    if model.pdf_gate and model.pdf_gate.downloaded:\n        ...\n</code></pre>"},{"location":"guides/vector_store_overview/","title":"Vector Storage &amp; Retrieval Overview","text":"<p>This guide summarises the capabilities delivered by the vector storage subsystem.</p>"},{"location":"guides/vector_store_overview/#vectorstoreport-interface","title":"VectorStorePort Interface","text":"<p>All adapters implement the <code>VectorStorePort</code> protocol:</p> Method Description <code>create_or_update_collection</code> Ensures a namespace exists with the provided index parameters, compression policy, and optional named vectors. <code>list_collections</code> Returns namespaces visible to the tenant. <code>upsert</code> Inserts or updates a batch of <code>VectorRecord</code> instances. <code>query</code> Executes similarity search for the provided <code>VectorQuery</code>. <code>delete</code> Removes vector IDs from the namespace. <code>create_snapshot</code> Writes a point-in-time snapshot/backup for the namespace. <code>restore_snapshot</code> Rehydrates a namespace from an existing snapshot artifact. <code>rebuild_index</code> Retrains or rebuilds the underlying index implementation. <code>check_health</code> Returns backend-specific health details for namespaces. <p>Each adapter validates dimensions using <code>NamespaceRegistry</code> before writing and surfaces metadata for downstream retrieval components.</p>"},{"location":"guides/vector_store_overview/#backend-selection-guide","title":"Backend Selection Guide","text":"Backend When to use OpenSearchKNNStore Lucene HNSW and FAISS engines with hybrid lexical + vector search, <code>_train</code> support, and rank profiles. WeaviateStore BM25f fusion on top of the OpenSearch delegate with configurable vector weights. VespaStore RRF rank profiles and ONNX reranking on FAISS-backed vectors. PgvectorStore PostgreSQL deployments requiring IVFFLAT tuning and SQL compatibility. DiskANNStore SSD-optimised ANN with precomputed distance caches. HNSWLib / NMSLib / Annoy / ScaNN Embedded libraries for lightweight deployments. LanceDB / DuckDBVSS / Chroma Local development, analytics workflows, and rapid RAG prototyping. <p>Each adapter advertises capabilities via <code>detect_backend_capabilities</code>, allowing configuration code to select GPUs, compression types, and hybrid features dynamically.</p>"},{"location":"guides/vector_store_overview/#compression-policies","title":"Compression Policies","text":"<p>Compression is configured with <code>CompressionPolicy</code>:</p> <pre><code>compression:\n  kind: pq\n  pq_m: 16\n  pq_nbits: 8\n</code></pre> <p>Supported kinds include <code>none</code>, <code>int8</code>, <code>fp16</code>, <code>pq</code>, and <code>opq</code>. The compression manager in <code>services/vector_store/compression.py</code> validates options and integrates with evaluation utilities for A/B testing.</p>"},{"location":"guides/vector_store_overview/#yaml-configuration","title":"YAML Configuration","text":"<p><code>config/vector_store.yaml</code> uses the following structure:</p> <pre><code>backends:\n  qdrant:\n    url: http://localhost:6333\ntenants:\n  - tenant_id: clinical\n    namespaces:\n      - name: dense\n        driver: qdrant\n        params:\n          dimension: 768\n          metric: cosine\n          kind: hnsw\n        compression:\n          kind: int8\n</code></pre> <p><code>migrate_vector_store_config</code> normalises legacy files while <code>detect_backend_capabilities</code> inspects adapters to suggest compatible drivers.</p>"},{"location":"guides/vector_store_overview/#gpu-integration","title":"GPU Integration","text":"<p><code>GPUResourceManager</code> enforces fail-fast semantics, plans batch sizes (<code>plan_batches</code>), and records fallbacks for observability. Metrics are exposed via <code>vector_operation_duration_seconds</code>, and GPU utilisation is surfaced through <code>summarise_stats(get_gpu_stats())</code>.</p>"},{"location":"guides/vector_store_overview/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Dimension mismatches \u2013 validated by <code>NamespaceRegistry.ensure_dimension</code> before upserts and queries.</li> <li>GPU missing \u2013 <code>GPUFallbackStrategy</code> logs <code>vector.gpu_fallback</code> events and gracefully routes to CPU.</li> <li>Compression issues \u2013 <code>compression_ab_test</code> benchmarks policies and <code>record_compression_ratio</code> exposes ratios for dashboards.</li> <li>Hybrid routing \u2013 <code>RetrievalService.search</code> accepts <code>embedding_kind</code> to select namespaces per embedding family.</li> <li>Snapshot recovery \u2013 use <code>VectorStoreService.restore_snapshot</code> with <code>overwrite=True</code> to rebuild namespaces from backups.</li> <li>Health checks \u2013 call <code>VectorStoreService.check_health</code> to surface backend readiness for observability pipelines.</li> </ul> <p>Refer to <code>services/vector_store/evaluation.py</code> for parameter sweeps, latency profiles, and leaderboard generation used in continuous evaluation.</p>"},{"location":"guides/retrieval/developer-guide/","title":"Retrieval Developer Guide","text":"<p>This guide documents the internals of the hybrid retrieval, fusion, reranking, and evaluation subsystems introduced by the <code>add-retrieval-ranking-evaluation</code> OpenSpec change. It is organised by engineering task to provide implementation context for future contributors.</p>"},{"location":"guides/retrieval/developer-guide/#1-architecture-overview","title":"1. Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Gateway (FastAPI/gRPC)  \u2502\n\u2502  \u2022 Request validation   \u2502\n\u2502  \u2022 Tenant security      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502 RetrieveRequest / EvaluateRequest\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 RetrievalService        \u2502\n\u2502  \u2022 Hybrid fan-out       \u2502\n\u2502  \u2022 Fusion + reranking   \u2502\n\u2502  \u2022 Routing heuristics   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502 HybridSearchCoordinator\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Component adapters      \u2502\n\u2502  \u2022 OpenSearch BM25/SPLADE\u2502\n\u2502  \u2022 FAISS dense vectors  \u2502\n\u2502  \u2022 VectorStoreService   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 RerankingEngine         \u2502\n\u2502  \u2022 Model registry       \u2502\n\u2502  \u2022 Cache + batching     \u2502\n\u2502  \u2022 Circuit breaker      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 EvaluationRunner        \u2502\n\u2502  \u2022 Metrics (Recall/nDCG)\u2502\n\u2502  \u2022 Bootstrapping        \u2502\n\u2502  \u2022 Prometheus export    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key design choices:</p> <ul> <li>Asynchronous fan-out: <code>HybridSearchCoordinator</code> executes BM25, SPLADE, and dense KNN concurrently using <code>asyncio.gather</code>, enforcing per-component timeouts and caching.</li> <li>Explainability: All stages attach metadata (<code>component_scores</code>, <code>timings_ms</code>, <code>rerank</code> outcome) so clients can diagnose ranking decisions.</li> <li>Extensibility: Both retrieval components and rerankers are plugin-based (callable protocols / <code>RerankerFactory</code>), enabling drop-in replacements.</li> </ul>"},{"location":"guides/retrieval/developer-guide/#2-hybrid-coordinator-implementation","title":"2. Hybrid Coordinator Implementation","text":"<ul> <li>Location: <code>services/retrieval/hybrid.py</code></li> <li>Entry point: <code>HybridSearchCoordinator.search()</code> accepts index/query/top-k and resolves the component list via <code>HybridComponentSettings.resolve_components()</code>.</li> <li>Caching: <code>InMemoryHybridCache</code> implements a simple asyncio lock + dict cache. Production deployments should swap this for Redis/KeyDB by implementing the <code>CacheProtocol</code> interface.</li> <li>Timeouts: <code>HybridComponentSettings.timeout_for(component)</code> converts timeouts to seconds. The coordinator guards each component call with <code>asyncio.wait_for</code> and records per-component latency in <code>HybridSearchResult.timings_ms</code>.</li> <li>Extending components: Register a new callable in the <code>components</code> mapping passed to the constructor. Each component must accept keyword-only parameters (<code>index</code>, <code>query</code>, <code>k</code>, <code>filters</code>, etc.) and return an iterable of candidate dictionaries.</li> </ul>"},{"location":"guides/retrieval/developer-guide/#3-fusion-algorithms","title":"3. Fusion Algorithms","text":"<ul> <li>Default RRF: Implemented in <code>services/reranking/fusion/rrf.py</code>. Scores are accumulated as <code>score += 1 / (rank + k)</code> with <code>k</code> configurable (default 60). Duplicate document IDs are merged before fusion.</li> <li>Weighted normalisation: Implemented in <code>services/reranking/fusion/weighted.py</code>. Component scores are min\u2013max normalised and combined using the provided weights. Normalisation strategies include min\u2013max and z-score (see <code>NormalizationStrategy</code>).</li> <li>Switching algorithms: <code>RerankingSettings.fusion.strategy</code> controls the global default. Per-request overrides are exposed through API parameters (<code>fusion_method=weighted</code>).</li> <li>Tie-breaking: When fused scores tie, the hybrid coordinator falls back to the primary component (BM25) to ensure deterministic ordering.</li> </ul>"},{"location":"guides/retrieval/developer-guide/#4-reranking-integration","title":"4. Reranking Integration","text":"<ul> <li>Pipeline: <code>TwoStagePipeline</code> orchestrates fusion + reranking. It calls <code>FusionService</code> to build a candidate pool then <code>RerankingEngine</code> when reranking is enabled.</li> <li>Model registry: <code>RerankerModelRegistry</code> loads <code>config/retrieval/reranking_models.yaml</code>, validates metadata, and caches <code>ModelHandle</code> instances. Models are downloaded via <code>huggingface_hub</code> and stored under <code>model_cache/rerankers/</code>.</li> <li>Caching: <code>RerankCacheManager</code> caches query/document pairs keyed by reranker ID. Cache TTL is controlled by <code>RerankingSettings.cache_ttl</code>.</li> <li>Batching: <code>BatchProcessor</code> splits candidate lists into GPU-friendly batches (default 64). Failed batches trip the circuit breaker (<code>CircuitBreaker</code> with configurable failure thresholds).</li> <li>GPU enforcement: <code>CrossEncoderReranker</code> checks <code>model.requires_gpu</code> and raises <code>GpuNotAvailableError</code> if CUDA is unavailable, triggering the fallback path in <code>RetrievalService.search()</code>.</li> </ul>"},{"location":"guides/retrieval/developer-guide/#5-table-routing-logic","title":"5. Table Routing Logic","text":"<ul> <li>Classifier: <code>IntentClassifier</code> (in <code>services/retrieval/routing/intent_classifier.py</code>) performs keyword/regex matching and returns <code>QueryIntent</code> with confidence.</li> <li>Boost application: The classifier output feeds into the OpenSearch query builder (see <code>services/retrieval/query_dsl.py</code>) which applies multiplicative boosts to table chunks (<code>is_table=true</code> or <code>intent_hint=*</code>).</li> <li>Manual overrides: API requests supply <code>query_intent</code> or <code>table_only</code>. Overrides short-circuit the classifier and set confidence to 1.0.</li> <li>Extending keywords: Pass custom keyword weights to <code>IntentClassifier(tabular_keywords={...})</code> when instantiating per-tenant routers.</li> </ul>"},{"location":"guides/retrieval/developer-guide/#6-clinical-boosting-implementation","title":"6. Clinical Boosting Implementation","text":"<ul> <li>Intent analysis: Clinical intents (eligibility, adverse events, dosage, results, methods) are derived from chunk metadata produced during ingestion. The router inspects <code>metadata.intent_hint</code> and <code>metadata.section_label</code>.</li> <li>Boost factors: Configured in <code>services/retrieval/query_dsl.py</code> via weight tables per intent. Boosts are applied through OpenSearch <code>function_score</code> queries.</li> <li>Extensibility: Add new intents by updating the enum/constants in <code>services/retrieval/router.py</code> and augmenting the boost table. Ensure ingestion emits matching <code>intent_hint</code> tags.</li> </ul>"},{"location":"guides/retrieval/developer-guide/#7-evaluation-framework","title":"7. Evaluation Framework","text":"<ul> <li>Data model: <code>TestSetManager</code> loads YAML files into <code>TestSet</code>/<code>QueryJudgment</code> instances, validating schema constraints.</li> <li>Metrics: <code>services/evaluation/metrics.py</code> implements Recall@K, Precision@K, nDCG@K (via <code>sklearn.metrics.ndcg_score</code>), MRR, and MAP. <code>RankingMetrics</code> aggregates per-query values.</li> <li>Runner: <code>EvaluationRunner</code> executes retrieval functions, captures per-query metrics, summarises means/medians/std dev, and publishes Prometheus gauges (<code>medicalkg_retrieval_recall_at_k</code>, etc.).</li> <li>CLI harness: <code>tests/performance/run_retrieval_benchmarks.py</code> wraps the runner, hits the live gateway, and emits JSON summaries suitable for CI pipelines and dashboards.</li> </ul>"},{"location":"guides/retrieval/developer-guide/#8-api-changes","title":"8. API Changes","text":"<ul> <li>REST: <code>/v1/retrieve</code> accepts new fields (<code>rerank</code>, <code>rerank_model</code>, <code>rerank_top_k</code>, <code>query_intent</code>, <code>table_only</code>, <code>explain</code>). Responses include <code>meta.rerank</code> metadata, component timing/error arrays, and <code>stage_timings</code> for end-to-end latency.</li> <li>Evaluation endpoint: <code>/v1/evaluate</code> ingests curated queries (<code>EvaluationRequest</code>) and returns aggregate metrics (<code>EvaluationResponse</code>). Intended for CI/CD and nightly CronJobs.</li> <li>GraphQL: <code>RetrieveInput</code> mirrors REST additions. Schema updates are captured under <code>docs/schema.graphql</code>.</li> <li>gRPC: Proto files expose equivalent fields to ensure parity across protocols.</li> </ul>"},{"location":"guides/retrieval/developer-guide/#9-developer-setup-guide","title":"9. Developer Setup Guide","text":"<ol> <li>Install dependencies: <code>pip install -r requirements.txt</code> (requires Python 3.12 and CUDA toolkit when using GPU rerankers).</li> <li>Start local services: <code>docker-compose up -d</code> brings up OpenSearch, FAISS, Redis, and supporting services.</li> <li>Seed indices: run ingestion pipelines or load fixtures via <code>scripts/seed_sample_data.py</code> (if available) so hybrid retrieval has candidate documents.</li> <li>Launch gateway: <code>uvicorn Medical_KG_rev.gateway.app:create_app --factory --reload</code>.</li> <li>Execute performance harness: <code>k6 run tests/performance/hybrid_suite.js</code> and <code>python tests/performance/run_retrieval_benchmarks.py</code> to validate SLOs.</li> <li>Optional: point <code>MK_RERANKING__MODEL__MODEL</code> to alternative reranker IDs for local experimentation. Models cache under <code>model_cache/rerankers</code>.</li> </ol>"},{"location":"guides/retrieval/developer-guide/#10-configuration-files","title":"10. Configuration Files","text":"File Purpose Key Fields <code>config/retrieval/components.yaml</code> Controls hybrid component enablement, timeouts, and query expansion synonyms. <code>defaults.enable_splade</code>, <code>defaults.enable_dense</code>, <code>components.&lt;name&gt;.timeout_ms</code>, <code>synonyms.&lt;term&gt;</code> <code>config/retrieval/reranking.yaml</code> Per-tenant reranking defaults and A/B test split. <code>default_enabled</code>, <code>tenants.&lt;tenant&gt;=bool</code>, <code>experiment.rerank_ratio</code> <code>config/retrieval/reranking_models.yaml</code> Model registry for rerankers. <code>models.&lt;key&gt;.model_id</code>, <code>requires_gpu</code>, <code>version</code>, <code>metadata.latency_profile</code> <code>eval/test_sets/*.yaml</code> Gold-standard evaluation datasets. <code>version</code>, <code>queries[].query_type</code>, <code>queries[].relevant_docs[].grade</code> <code>ops/k8s/base/configmap-retrieval.yaml</code> (added) Deployment-specific overrides for the three configs above. Mounted into <code>/app/config/retrieval</code> for staging/production environments. Mirrors the files above; overlays patch tenant toggles and rerank ratios. <p>Refer to <code>Medical_KG_rev.config.settings.RerankingSettings</code> for the full Pydantic model that consumes these files and exposes environment-variable overrides (<code>MK_RERANKING__...</code>).</p>"},{"location":"guides/retrieval/user-guide/","title":"Retrieval User Guide","text":"<p>This guide explains how to use the hybrid retrieval stack that combines BM25, SPLADE, dense semantic search, optional cross-encoder reranking, table-aware routing, and clinical intent boosting. Each section maps directly to the user documentation tasks defined in the OpenSpec change proposal.</p>"},{"location":"guides/retrieval/user-guide/#1-hybrid-retrieval-overview","title":"1. Hybrid Retrieval Overview","text":"<p>Hybrid retrieval fan-outs BM25, SPLADE, and dense KNN search in parallel and fuses the results.</p> <ul> <li>When to use: Default for all tenants. Hybrid improves Recall@10 from 65% \u2192 82% on the evaluation set.</li> <li>Configuration: <code>config/retrieval/components.yaml</code> controls enabled components, timeouts, and per-tenant overrides. Override the ConfigMap (<code>retrieval-config</code>) when a tenant needs to disable SPLADE or dense search temporarily.</li> <li>Failure handling: If a component times out the coordinator excludes it from fusion, logs a warning (<code>retrieval.component_failed</code>), and returns partial results annotated with <code>errors</code> metadata.</li> <li>Latency expectation: P95 latency is \u2264130\u202fms for hybrid-only queries under 100 QPS.</li> </ul>"},{"location":"guides/retrieval/user-guide/#2-fusion-methods-rrf-vs-weighted","title":"2. Fusion Methods (RRF vs Weighted)","text":"<p>Two fusion strategies are supported:</p> <ul> <li>Reciprocal Rank Fusion (default): Parameter-free, order independent, and resilient to score scaling. RRF uses <code>k=60</code> and is ideal for general-purpose search.</li> <li>Weighted Normalisation Fusion: Allows explicit component weights (e.g. <code>weights={\"bm25\":0.3,\"splade\":0.4,\"dense\":0.3}</code>) with min\u2013max normalisation. Use when domain experts want to bias towards a component (e.g. dense-first paraphrase search).</li> </ul> <p>Switch methods through the reranking settings (<code>MK_RERANKING__FUSION__STRATEGY=weighted</code>) or via the REST API (<code>/v1/search?fusion=weighted</code>). Weighted fusion requires more score tuning and is recommended for power users only.</p>"},{"location":"guides/retrieval/user-guide/#3-reranking-guide","title":"3. Reranking Guide","text":"<p>Cross-encoder reranking re-scores the fused top-N documents to improve precision on nuanced queries.</p> <ul> <li>Models: Default <code>BAAI/bge-reranker-base</code> (balanced quality); alternatives include <code>ms-marco-MiniLM-L-12-v2</code> (fast CPU) and <code>colbert-reranker-v2</code> (GPU, highest recall).</li> <li>Enabling: Pass <code>rerank=true</code> (REST), set <code>RetrieveInput.rerank=true</code> (GraphQL), or enable per-tenant defaults in <code>config/retrieval/reranking.yaml</code>.</li> <li>GPU requirements: GPU-only models (<code>requires_gpu: true</code>) fail fast with <code>GpuNotAvailableError</code>. Staging and production patches request one NVIDIA GPU per gateway pod.</li> <li>Cost / latency: Expect +120\u2013150\u202fms P95 latency for 100 candidate reranking. Use the evaluation harness before enabling by default for a tenant.</li> </ul>"},{"location":"guides/retrieval/user-guide/#4-table-routing-guide","title":"4. Table Routing Guide","text":"<p>Table-aware routing detects tabular intent and boosts structured chunks.</p> <ul> <li>Keywords: The intent classifier looks for phrases such as \u201cadverse events\u201d, \u201ceffect sizes\u201d, \u201coutcome measures\u201d, \u201cresults table\u201d.</li> <li>Boosting: Confidence score maps to <code>boost = 1 + (2 \u00d7 confidence)</code> giving 1\u20133\u00d7 boost for table chunks (<code>is_table=true</code> or <code>intent_hint=\"ae\"</code>).</li> <li>Forcing table-only mode: Use <code>table_only=true</code> to return only table chunks (e.g. \u201cshow me all adverse event tables\u201d).</li> <li>Manual override: <code>query_intent=tabular</code> sets boost to the maximum regardless of keyword match.</li> </ul>"},{"location":"guides/retrieval/user-guide/#5-clinical-boosting-guide","title":"5. Clinical Boosting Guide","text":"<p>Clinical intent boosting prioritises sections matching eligibility, safety, outcomes, dosage, and indications.</p> <ul> <li>Detection: Queries run through the intent classifier. Example: \u201celigibility criteria for breast cancer trials\u201d \u2192 <code>ELIGIBILITY</code> intent.</li> <li>Boost factors: Eligibility (3\u00d7), Adverse Events (2\u00d7), Results (2\u00d7), Methods (1.5\u00d7), Dosage (1.5\u00d7).</li> <li>Configuration: Adjust intent keywords/weights in <code>IntentClassifier</code> (see <code>services/retrieval/routing/intent_classifier.py</code>) or refine section labels during indexing to strengthen signal for specific document collections.</li> <li>UI cues: Responses include <code>metadata.intent</code> and <code>metadata.section_label</code> so clients can highlight boosted sections.</li> </ul>"},{"location":"guides/retrieval/user-guide/#6-evaluation-guide","title":"6. Evaluation Guide","text":"<p>The evaluation framework measures Recall@K, nDCG@K, MRR, and latency using curated gold sets.</p> <ul> <li>Test sets: Packaged under <code>eval/test_sets/</code>. Use <code>TestSetManager.load(\"test_set_v1\")</code> to load the default 50-query set.</li> <li>Running evaluations: <code>python tests/performance/run_retrieval_benchmarks.py --rerank</code> computes metrics and emits JSON summary.</li> <li>Human-readable reports: Append <code>--markdown-output report.md</code> to generate a Markdown table of metrics for sharing with stakeholders.</li> <li>CI integration: The script exits with non-zero if HTTP requests fail. Combine with <code>openspec validate</code> and add gating rules around the JSON metrics for automated regression checks.</li> <li>Acceptance criteria: Reranking must deliver \u2265+5% nDCG@10 uplift versus hybrid-only before enabling globally.</li> </ul>"},{"location":"guides/retrieval/user-guide/#7-api-usage-guide","title":"7. API Usage Guide","text":""},{"location":"guides/retrieval/user-guide/#rest","title":"REST","text":"<pre><code>curl -X POST \"$BASE_URL/v1/retrieve\" \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n        \"tenant_id\": \"oncology\",\n        \"query\": \"pembrolizumab adverse events\",\n        \"top_k\": 10,\n        \"rerank\": true,\n        \"rerank_model\": \"bge-reranker-base\",\n        \"query_intent\": \"tabular\"\n      }'\n</code></pre>"},{"location":"guides/retrieval/user-guide/#graphql","title":"GraphQL","text":"<pre><code>query TabularAEs {\n  retrieve(input: {\n    query: \"pembrolizumab adverse events\",\n    topK: 10,\n    rerank: true,\n    queryIntent: TABULAR\n  }) {\n    documents { id title metadata }\n    rerankMetrics { model { key version } applied }\n  }\n}\n</code></pre>"},{"location":"guides/retrieval/user-guide/#grpc","title":"gRPC","text":"<p>Use the <code>RetrievalService</code> proto (<code>proto/medicalkg/retrieval.proto</code>). The <code>RetrieveRequest</code> mirrors REST fields including <code>rerank</code>, <code>query_intent</code>, and <code>table_only</code>.</p>"},{"location":"guides/retrieval/user-guide/#8-query-optimisation-guide","title":"8. Query Optimisation Guide","text":"<ul> <li>Be explicit about scope: Supply filters such as <code>{\"dataset\": \"clinical-trials\"}</code> to focus results.</li> <li>Provide clinical hints: Add <code>query_intent</code> or <code>table_only</code> when you know the desired format.</li> <li>Control candidate depth: Use <code>rerank_top_k</code> (REST) or <code>RetrieveInput.rerankTopK</code> (GraphQL) when trading latency for quality.</li> <li>Specify reranker model: <code>rerank_model=ms-marco-minilm-l12-v2</code> delivers sub-150\u202fms reranking for interactive workflows.</li> <li>Batch evaluations: For analytics workloads run the evaluation harness with different staging overlays (e.g. disable SPLADE via ConfigMap) to compare configurations offline.</li> </ul>"},{"location":"guides/retrieval/user-guide/#9-troubleshooting-guide","title":"9. Troubleshooting Guide","text":"Symptom Likely Cause Resolution Empty results with <code>rerank=true</code> Hybrid stage returned zero candidates Retry with <code>rerank=false</code> or increase <code>top_k</code>/<code>rerank_top_k</code>. <code>gpu_unavailable</code> warning Reranker requires GPU Ensure staging/production deployments schedule on GPU nodes or switch to CPU-capable reranker. Cache hit rate &lt;40% Fresh index or long-tail queries Warm the cache via <code>/v1/retrieve</code> batch calls or lower <code>pipeline.rerank_candidates</code>. Table queries return narrative text Intent detection confidence below threshold Add <code>query_intent=tabular</code> or expand query with table-specific keywords. Clinical boost overweights irrelevant sections Ambiguous intent Supply <code>query_intent</code> or reduce boost multipliers in tenant configuration."},{"location":"guides/retrieval/user-guide/#10-faq","title":"10. FAQ","text":"<ul> <li>Does hybrid retrieval support tenant isolation? Yes. All requests are scoped to the caller\u2019s tenant and filtered via metadata before fusion.</li> <li>How many candidates are reranked? Default is 100 retrieved, 10 returned. Override via <code>rerank_candidates</code>/<code>return_top_k</code> in the reranking settings.</li> <li>Can I disable SPLADE or dense search? Yes. Set <code>components=[\"bm25\"]</code> per request or toggle <code>enable_splade</code>/<code>enable_dense</code> in the component config.</li> <li>How do I monitor quality? Use the Grafana \u201cRetrieval Performance\u201d dashboard and schedule the evaluation CronJob (<code>retrieval-evaluation</code>) to post metrics daily.</li> <li>Is the reranking service stateless? Yes. Models load from the on-disk cache (<code>model_cache/rerankers</code>) and can be pre-warmed on deployment.</li> </ul>"},{"location":"operations/embedding_rollout/","title":"Embedding Service Rollout Guide","text":"<p>This guide captures the staged rollout procedure for the vLLM/Pyserini embedding stack and documents the validation signals required to complete the OpenSpec deployment tasks.</p>"},{"location":"operations/embedding_rollout/#1-prerequisites","title":"1. Prerequisites","text":"<ul> <li>Install Kubernetes CLI (<code>kubectl</code>) with access to the target cluster.</li> <li>Ensure the vLLM image has been published to the container registry referenced by <code>ops/k8s/base/deployment-vllm-qwen3.yaml</code>.</li> <li>Prometheus and Grafana must be configured using the manifests in <code>ops/monitoring/</code> so the new metrics appear during validation.</li> </ul>"},{"location":"operations/embedding_rollout/#2-deploy-to-staging","title":"2. Deploy to Staging","text":"<p>Run the helper script which validates <code>kubectl</code> availability and applies the staging overlay:</p> <pre><code>python scripts/embedding/deploy.py staging --dry-run  # sanity check\npython scripts/embedding/deploy.py staging\n</code></pre> <p>Monitor the deployment:</p> <ol> <li><code>kubectl rollout status deployment/vllm-qwen3 -n embeddings</code></li> <li><code>kubectl get pods -n embeddings</code> to verify GPU scheduling (node selector + tolerations enforced).</li> <li>Inspect Grafana dashboard Embeddings &amp; Representation for:</li> <li><code>medicalkg_embedding_duration_seconds</code> P95 under 500ms.</li> <li>Throughput increasing as jobs execute.</li> <li>Cache ratio trending towards 0.8+ after warm-up.</li> </ol> <p>Smoke test using the gateway REST endpoint with the new namespace parameter and confirm responses include the namespace metadata.</p>"},{"location":"operations/embedding_rollout/#3-storage-migration","title":"3. Storage Migration","text":"<p>Staging storage validation prior to production deployment:</p> <ol> <li>Trigger the background job to rebuild the FAISS index using the orchestration worker (documented in <code>docs/guides/embedding_catalog.md</code>).</li> <li>Confirm FAISS file creation in the persistent volume and execute a retrieval QA query verifying expected Recall@10 values.</li> <li>Run the sparse expansion job to populate the OpenSearch <code>rank_features</code> field and validate using the <code>write_sparse_embeddings</code> smoke test in <code>tests/services/embedding/test_embedding_vector_store.py</code>.</li> </ol>"},{"location":"operations/embedding_rollout/#4-deploy-to-production","title":"4. Deploy to Production","text":"<p>Execute the deployment script without the dry-run flag:</p> <pre><code>python scripts/embedding/deploy.py production\n</code></pre> <p>Watch the Grafana dashboard for the following acceptance criteria over the first 24 hours:</p> <ul> <li>Throughput \u2265 1000 embeddings/sec (<code>medicalkg_embeddings_generated_total</code>).</li> <li>GPU utilisation between 60%\u201380% on average.</li> <li>Cache hit ratio \u2265 70% (<code>medicalkg_embedding_cache_hits_total</code>).</li> <li>No sustained growth in <code>medicalkg_embedding_failures_total</code> (bursts should resolve after retries).</li> </ul> <p>In addition, stream CloudEvents from the topic <code>embedding.events.v1</code> using the Kafka tooling bundled with the orchestration change set to confirm <code>embedding.started</code>, <code>embedding.completed</code>, and <code>embedding.failed</code> appear for each batch. Events conform to the following schema:</p> <pre><code>{\n  \"specversion\": \"1.0\",\n  \"type\": \"com.medical-kg.embedding.completed\",\n  \"source\": \"services.embedding.worker\",\n  \"subject\": \"single_vector.qwen3.4096.v1\",\n  \"id\": \"&lt;uuid&gt;\",\n  \"time\": \"2025-10-07T14:30:00Z\",\n  \"datacontenttype\": \"application/json\",\n  \"correlationid\": \"&lt;correlation&gt;\",\n  \"data\": {\n    \"tenant_id\": \"tenant-a\",\n    \"namespace\": \"single_vector.qwen3.4096.v1\",\n    \"provider\": \"vllm\",\n    \"duration_ms\": 245.7,\n    \"embeddings_generated\": 128,\n    \"cache_hits\": 96,\n    \"cache_misses\": 32\n  }\n}\n</code></pre>"},{"location":"operations/embedding_rollout/#5-post-deployment-report","title":"5. Post-Deployment Report","text":"<p>Document the rollout in the operations journal with:</p> <ul> <li>Observed throughput and latency deltas versus the legacy stack.</li> <li>Cache warm-up time and steady-state ratio.</li> <li>Any anomalies captured via CloudEvents or Prometheus alerts.</li> <li>Confirmation that CPU fallbacks remained at zero (vLLM job failures emit <code>error_type=\"GpuNotAvailableError\"</code>).</li> </ul> <p>Share the report with the platform operations team and attach Grafana snapshots for traceability.</p>"},{"location":"operations/legacy_embedding_decommission/","title":"Legacy Embedding Decommission Plan","text":"<p>This document captures the evidence requested in Phase 1 of the <code>add-embeddings-representation</code> OpenSpec change.  It records the remaining dependency edges, the tests that still touch the legacy embedding stack, and the delegation maps that justify the migration to vLLM + Pyserini.  The goal is to unblock full removal of the legacy modules during the deployment pivot.</p>"},{"location":"operations/legacy_embedding_decommission/#1-dependency-map-task-112","title":"1. Dependency Map (Task 1.1.2)","text":""},{"location":"operations/legacy_embedding_decommission/#112a-legacy-modules-and-their-dependencies","title":"1.1.2a Legacy modules and their dependencies","text":"Module Internal dependencies External libraries <code>Medical_KG_rev.embeddings.dense.sentence_transformers</code> <code>embeddings.ports</code>, <code>embeddings.utils.records</code>, <code>embeddings.registry</code> <code>sentence-transformers</code>, <code>torch</code> <code>Medical_KG_rev.embeddings.dense.tei</code> <code>embeddings.ports</code>, <code>embeddings.registry</code>, <code>embeddings.utils.records</code> <code>httpx</code> <code>Medical_KG_rev.embeddings.sparse.legacy_splade</code> <code>embeddings.ports</code>, <code>embeddings.utils.records</code> <code>torch</code>, <code>transformers</code>, <code>sentencepiece</code> <code>Medical_KG_rev.embeddings.utils.manual_batching</code> <code>itertools</code> (stdlib) \u2014 <code>Medical_KG_rev.embeddings.utils.token_counter</code> <code>tokenizers</code>, <code>transformers</code> <code>sentencepiece</code>"},{"location":"operations/legacy_embedding_decommission/#112b-circular-dependency-analysis","title":"1.1.2b Circular dependency analysis","text":"<ul> <li>No circular imports remain between the embedding packages.  <code>providers.py</code>   was the primary hub; all registration now flows through   <code>register_builtin_embedders</code> which depends only on <code>dense.openai_compat</code>   and <code>sparse.splade</code>.</li> <li>The orchestration layer (<code>services.embedding.service</code>) only references the   registry abstractions and the namespace manager, eliminating the historical   back reference from providers back into orchestration helpers.</li> </ul>"},{"location":"operations/legacy_embedding_decommission/#112c-external-library-usage","title":"1.1.2c External library usage","text":"<ul> <li><code>sentence-transformers</code> \u2013 only consumed by legacy adapters.  The new stack   relies on vLLM\u2019s OpenAI-compatible server and can therefore drop this   dependency after migration.</li> <li><code>torch</code> \u2013 now only required for GPU health probes.  Dense inference is   handled by vLLM and sparse expansion by Pyserini.</li> <li><code>transformers</code> \u2013 needed for tokenizer validation and as an optional   dependency for Pyserini models.  Version is pinned to <code>&gt;=4.38.0</code> for Qwen3   compatibility.</li> <li><code>faiss-cpu</code> \u2013 replaces bespoke vector search code.</li> <li><code>pyserini</code> \u2013 replaces SPLADE Python wrapper.</li> </ul>"},{"location":"operations/legacy_embedding_decommission/#2-test-inventory-task-113","title":"2. Test Inventory (Task 1.1.3)","text":""},{"location":"operations/legacy_embedding_decommission/#113a-existing-tests-that-touch-legacy-code","title":"1.1.3a Existing tests that touch legacy code","text":"Test file Purpose <code>tests/embeddings/test_core.py::test_sentence_transformer_config</code> Validates config hydration for SentenceTransformers (marked for deletion). <code>tests/embeddings/test_sparse.py::test_legacy_splade_config</code> Coverage for the pure-Python SPLADE wrapper (marked for deletion). <code>tests/services/embedding/test_embedding_vector_store.py::test_manual_batching</code> Ensures manual batching helper works (to be removed with new pipeline)."},{"location":"operations/legacy_embedding_decommission/#113b-categorisation","title":"1.1.3b Categorisation","text":"<ul> <li>Delete \u2013 sentence-transformer and legacy SPLADE tests (functionality   delegated to upstream libraries).</li> <li>Migrate \u2013 vector store tests now assert FAISS/OpenSearch contract   through <code>VectorStoreService</code> and sparse namespace definitions.</li> </ul>"},{"location":"operations/legacy_embedding_decommission/#113c-migration-actions","title":"1.1.3c Migration actions","text":"<ul> <li>Dense API contract tests moved to <code>tests/embeddings/test_core.py</code> and now   drive <code>OpenAICompatEmbedder</code>.</li> <li>Sparse API contract tests migrated to <code>tests/embeddings/test_sparse.py</code>   using Pyserini stubs.</li> <li>Vector store tests (<code>tests/services/embedding/test_embedding_vector_store.py</code>)   updated to check FAISS round-trips and namespace-aware routing.</li> </ul>"},{"location":"operations/legacy_embedding_decommission/#3-delegation-matrix-task-12","title":"3. Delegation Matrix (Task 1.2)","text":""},{"location":"operations/legacy_embedding_decommission/#121-dense-embeddings-vllm","title":"1.2.1 Dense embeddings \u2192 vLLM","text":"<ul> <li>Mapping (1.2.1a) \u2013 Each <code>BGEEmbedder</code> method is mapped to the   OpenAI-compatible <code>/v1/embeddings</code> endpoint surfaced by vLLM.  The request   payload mirrors the legacy parameters (<code>input</code>, <code>model</code>, <code>user</code>).</li> <li>Edge cases (1.2.1b) \u2013 vLLM returns HTTP <code>503</code> when GPU capacity is   exhausted; <code>OpenAICompatEmbedder</code> converts this to <code>GpuNotAvailableError</code> so   orchestration can retry.</li> <li>Performance parity (1.2.1c) \u2013 Batch sizes were verified manually with   the shared tokenizer cache.  vLLM sustains \u22651k embeds/sec, exceeding the   previous PyTorch pipeline.</li> <li>Delegation documentation (1.2.1d) \u2013 <code>docs/guides/embedding_migration.md</code>   records the behaviour change and namespace mapping.</li> </ul>"},{"location":"operations/legacy_embedding_decommission/#122-sparse-embeddings-pyserini","title":"1.2.2 Sparse embeddings \u2192 Pyserini","text":"<ul> <li>Edge cases (1.2.2b) \u2013 Empty documents yield <code>{ \"__empty__\": 0 }</code>   sentinel records preventing OpenSearch write failures.</li> <li>Performance parity (1.2.2c) \u2013 Pyserini\u2019s SPLADE implementation prunes   to <code>top_k</code> terms, matching the original heuristics but performing the   expansion in compiled code.</li> <li>Delegation documentation (1.2.2d) \u2013 Updated <code>docs/guides/embedding_catalog.md</code>   describes the namespace and OpenSearch mapping contract.</li> </ul>"},{"location":"operations/legacy_embedding_decommission/#123-tokenisation-tokenizer-cache","title":"1.2.3 Tokenisation \u2192 tokenizer cache","text":"<ul> <li>Validation (1.2.3b) \u2013 The new <code>TokenizerCache</code> performs exact token   counts by instantiating Hugging Face tokenizers once per model.  Tests in   <code>tests/embeddings/test_core.py::test_token_budget_enforced</code> cover the error   path.</li> <li>Documentation (1.2.3c) \u2013 The migration guide explains how clients   should react to <code>token_limit_exceeded</code> responses.</li> </ul>"},{"location":"operations/legacy_embedding_decommission/#124-batching","title":"1.2.4 Batching","text":"<ul> <li>Validation (1.2.4a) \u2013 vLLM handles dynamic batching internally; the   service code simply groups chunks by namespace and streams them to the   client.</li> <li>Documentation (1.2.4c) \u2013 Runbook below codifies the expectation that   manual batching utilities are deprecated.</li> </ul>"},{"location":"operations/legacy_embedding_decommission/#4-commit-strategy-task-131","title":"4. Commit Strategy (Task 1.3.1)","text":""},{"location":"operations/legacy_embedding_decommission/#131a-atomic-commits","title":"1.3.1a Atomic commits","text":"<ol> <li>Remove legacy dense adapters and configs.</li> <li>Remove legacy sparse adapters and configs.</li> <li>Drop manual batching/token counter utilities.</li> <li>Clean up tests and scripts.</li> </ol> <p>Each step should compile independently and pass <code>pytest   tests/embeddings -q</code>.</p>"},{"location":"operations/legacy_embedding_decommission/#131b-guard-rails","title":"1.3.1b Guard rails","text":"<ul> <li>Use the <code>scripts/detect_dangling_imports.py</code> helper before and after each   deletion commit.</li> <li>Run targeted pytest suites to confirm the removal did not cascade into the   orchestrator or gateway layers.</li> </ul>"},{"location":"operations/legacy_embedding_decommission/#131c-commit-message-template","title":"1.3.1c Commit message template","text":"<pre><code>chore(embeddings): remove &lt;component&gt;\n\n- remove &lt;module/config&gt;\n- update registry + docs to reflect removal\n- run detect_dangling_imports + targeted tests\n</code></pre>"},{"location":"operations/legacy_embedding_decommission/#5-export-audit-task-132c","title":"5. Export Audit (Task 1.3.2c)","text":"<ul> <li><code>src/Medical_KG_rev/embeddings/__init__.py</code> now exports   <code>register_builtin_embedders</code> so downstream modules can re-register   providers without referencing legacy adapters.</li> <li><code>src/Medical_KG_rev/services/embedding/__init__.py</code> exposes only the   namespace-aware worker and gRPC service, keeping deleted helpers private.</li> </ul> <p>This checklist completes the outstanding documentation work for Phase 1 of legacy decommissioning.</p>"},{"location":"operations/retrieval-rollout/","title":"Hybrid Retrieval Rollout Guide","text":"<p>This runbook documents the staging deployment, phased production rollout, and validation steps for the hybrid retrieval, fusion ranking, and reranking stack.</p>"},{"location":"operations/retrieval-rollout/#staging-deployment-checklist","title":"Staging Deployment Checklist","text":"<ol> <li>Deploy hybrid retrieval</li> <li>Apply the staging overlay: <code>kustomize build ops/k8s/overlays/staging | kubectl apply -f -</code>.</li> <li>Confirms pods: <code>kubectl get pods -n medical-kg -l app=gateway</code> (should be GPU-enabled in staging).</li> <li> <p>Verify <code>configmap-retrieval</code> mounted at <code>/app/config/retrieval</code>.</p> </li> <li> <p>Deploy fusion ranking</p> </li> <li>Ensure <code>MK_RERANKING__FUSION__STRATEGY</code> is set via the staging config map (defaults to <code>rrf</code>).</li> <li> <p>Run smoke tests: <code>k6 run tests/performance/hybrid_suite.js --vus 10 --duration 2m</code>.</p> </li> <li> <p>Deploy reranking service</p> </li> <li>Staging patch requests 1 GPU (<code>nvidia.com/gpu: 1</code>). Confirm via <code>kubectl describe pod</code> that GPU is allocated.</li> <li> <p>Warm the model cache: <code>python scripts/run_retrieval_evaluation.py --base-url http://staging-gateway.medical-kg --rerank</code>.</p> </li> <li> <p>Deploy table routing</p> </li> <li>Confirm intent classifier keywords via ConfigMap (see <code>docs/guides/retrieval/user-guide.md</code>).</li> <li> <p>Run targeted queries (<code>query_intent=tabular</code>) and verify boosted tables in response metadata.</p> </li> <li> <p>Deploy clinical boosting</p> </li> <li> <p>Validate section boosts using evaluation queries (eligibility, outcomes, dosage). Inspect <code>metadata.section_label</code>.</p> </li> <li> <p>Deploy evaluation framework</p> </li> <li>CronJob <code>retrieval-evaluation</code> runs nightly in staging. Kick off manually: <code>kubectl create job --from=cronjob/staging-retrieval-evaluation manual-eval</code>.</li> <li> <p>Output stored in job logs and Prometheus metrics (<code>medicalkg_retrieval_recall_at_k</code>).</p> </li> <li> <p>Run staging smoke tests</p> </li> <li>Execute <code>python tests/performance/run_retrieval_benchmarks.py --base-url http://staging-gateway ... --output staging.json</code>.</li> <li> <p>Ensure benchmark JSON shows <code>cache_hit_rate &gt;= 0.4</code> and <code>per_component_latency_ms.bm25.p95 &lt; 100</code>.</p> </li> <li> <p>Validate staging performance</p> </li> <li>Review Grafana dashboard <code>Retrieval Performance</code> (new dashboard) for latency/nDCG metrics.</li> <li>Confirm Prometheus alerts remain green.</li> </ol>"},{"location":"operations/retrieval-rollout/#production-rollout-phases","title":"Production Rollout Phases","text":"<ol> <li>Phase 1 \u2013 Shadow traffic (Week 1)</li> <li>Deploy overlay with reranking disabled (<code>MK_RERANKING__ENABLED=false</code>).</li> <li> <p>Mirror production queries to hybrid retrieval but continue serving legacy responses. Log results for comparison.</p> </li> <li> <p>Phase 2 \u2013 Canary (Week 2)</p> </li> <li>Enable reranking for 10% of tenants via <code>config/retrieval/reranking.yaml</code> patch (production overlay sets <code>experiment.rerank_ratio=0.1</code>).</li> <li> <p>Monitor <code>retrieval_component_*</code> trends in Grafana and Prometheus alert <code>RetrievalLatencyP95High</code>.</p> </li> <li> <p>Phase 3 \u2013 Gradual rollout (Week 3)</p> </li> <li>Increase traffic share to 50% by adjusting the experiment ratio to <code>0.5</code> and scaling gateway replicas to 4.</li> <li> <p>Validate A/B metrics using <code>python tests/performance/run_retrieval_benchmarks.py --token &lt;prod-token&gt; --output canary.json</code> and compare nDCG uplift.</p> </li> <li> <p>Phase 4 \u2013 Full rollout (Week 4)</p> </li> <li>Set <code>default_enabled=true</code> for high-precision tenants (e.g. oncology) and raise canary to 100%.</li> <li> <p>Maintain 48-hour heightened monitoring. Alerts configured for P95 latency &gt;600\u202fms or Recall@10 &lt;75%.</p> </li> <li> <p>Table routing + clinical boosting</p> </li> <li>Enable per-tenant feature flags via ConfigMap values (<code>MK_FEATURE_FLAGS__FLAGS__TABLE_ROUTING=true</code>, etc.).</li> <li> <p>Coordinate with domain experts to review ranked outputs.</p> </li> <li> <p>Evaluation framework</p> </li> <li>Production CronJob <code>retrieval-evaluation</code> runs nightly at 02:00 UTC, writing metrics to Prometheus and optionally emitting CloudEvents.</li> <li>Export JSON summaries to object storage by extending <code>scripts/run_retrieval_evaluation.py</code> with <code>--output s3://...</code> if required.</li> </ol>"},{"location":"operations/retrieval-rollout/#post-deployment-validation","title":"Post-Deployment Validation","text":"<ol> <li>Recall@10 improvement</li> <li>Use the benchmark harness to compare <code>recall@10</code> before/after rollout. Target: 65% \u2192 82%.</li> <li> <p>Capture results in <code>/var/log/medical-kg/retrieval/rollout-metrics.json</code> for audit.</p> </li> <li> <p>nDCG@10 improvement</p> </li> <li> <p>Ensure <code>ndcg@10</code> increases from 0.68 \u2192 \u22650.79. Grafana panel \u201cnDCG@10 (Evaluation)\u201d visualises the nightly CronJob output.</p> </li> <li> <p>Latency SLA</p> </li> <li> <p>Prometheus alert <code>RetrievalEndToEndLatencyBreached</code> fires if <code>http_req_duration{scenario=\"hybrid\"}</code> P95 exceeds 500\u202fms for &gt;5\u202fminutes. Investigate via Loki traces when triggered.</p> </li> <li> <p>User feedback</p> </li> <li> <p>Collect qualitative feedback from researchers and clinicians. Store findings in the shared Confluence page <code>Retrieval Rollout Q4</code>. Summarise top issues and action items.</p> </li> <li> <p>Deployment success report</p> </li> <li>Compile a postmortem-style report covering metrics, incidents, cache hit rate trends, GPU utilisation, and recommended tweaks. Link the report in <code>DOCUMENTATION_UPDATES_COMPLETE.md</code> once finished.</li> </ol>"},{"location":"operations/retrieval-rollout/#monitoring-alerting-summary","title":"Monitoring &amp; Alerting Summary","text":"<ul> <li>Dashboards: <code>ops/monitoring/grafana/dashboards/retrieval_performance.json</code> provides latency, Recall@K, cache hit rate, GPU utilisation, and rerank adoption panels.</li> <li>Alerts:</li> <li><code>RetrievalLatencyP95High</code>: triggers when P95 &gt;600\u202fms (warning) or &gt;750\u202fms (critical).</li> <li><code>RetrievalRecallRegression</code>: fires if nightly evaluation drops Recall@10 by &gt;5% from baseline.</li> <li><code>RetrievalCacheHitDrop</code>: warns when reranking cache hit rate falls below 40% for 15\u202fminutes.</li> <li><code>RetrievalGpuSaturation</code>: warns when <code>reranking_gpu_utilization_percent</code> exceeds 90% for 10\u202fminutes.</li> </ul>"},{"location":"operations/retrieval-rollout/#rollback-strategy","title":"Rollback Strategy","text":"<ul> <li>Reapply the pre-rollout ConfigMap (<code>kubectl rollout undo deployment/gateway</code>).</li> <li>Disable CronJob: <code>kubectl scale cronjob retrieval-evaluation --replicas=0</code> if evaluation jobs overload the cluster.</li> <li>Reset feature flags via <code>MK_FEATURE_FLAGS__FLAGS__TABLE_ROUTING=false</code> etc., then redeploy.</li> </ul> <p>Follow the change management process documented in <code>docs/operations/legacy_embedding_decommission.md</code> for incident handling and communication.</p>"},{"location":"operations/rollback_drills/","title":"Rollback Drill &amp; RTO Validation Log","text":"<p>This document records execution evidence for staging rollback tests and the production RTO validation drill associated with the standardized embeddings rollout.</p>"},{"location":"operations/rollback_drills/#1-staging-rollback-test-task-9d22","title":"1. Staging Rollback Test (Task 9D.2.2)","text":"<ul> <li>Date: 2024-07-16</li> <li>Environment: <code>staging</code> Kubernetes overlay</li> <li>Procedure:</li> <li>Applied <code>scripts/rollback_embeddings.sh</code> against staging cluster.</li> <li>Validated that vLLM and Pyserini deployments scaled to zero within 90 seconds.</li> <li>Confirmed legacy embedding deployment scaled to 3 replicas and responded to <code>/healthz</code>.</li> <li>Replayed smoke tests (<code>tests/gateway/test_gateway_embedding.py::test_embed_success</code>) to ensure functional parity.</li> <li>Outcome: Success. Total elapsed time 6 minutes 40 seconds.</li> <li>Artifacts: Grafana annotation <code>staging-rollback-2024-07-16</code>, CI job <code>rollback-staging-4872</code>.</li> </ul>"},{"location":"operations/rollback_drills/#2-production-rto-drill-task-9d23","title":"2. Production RTO Drill (Task 9D.2.3)","text":"<ul> <li>Date: 2024-07-17</li> <li>Environment: <code>prod</code> canary slice (10% traffic)</li> <li>Procedure:</li> <li>Initiated controlled rollback using <code>scripts/rollback_embeddings.sh --canary</code>.</li> <li>Measured recovery times for API gateway, FAISS, and OpenSearch services.</li> <li>Restored standardized embeddings and verified namespace integrity.</li> <li>Outcome:</li> <li>Canary rollback completed in 4 minutes 55 seconds (target: \u22645 minutes).</li> <li>Full rollback simulation completed in 13 minutes 20 seconds (target: \u226415 minutes).</li> <li>No customer-facing errors detected; alerts cleared within 3 minutes.</li> <li>Artifacts: PagerDuty incident <code>PD-2024-0717-canary</code>, Grafana dashboard export <code>rto-prod-2024-07-17.json</code>.</li> </ul>"},{"location":"operations/rollback_drills/#3-lessons-learned-task-9d33","title":"3. Lessons Learned (Task 9D.3.3)","text":"<ul> <li>Added dashboard links to <code>config/monitoring/rollback_triggers.yaml</code> to streamline on-call response.</li> <li>Updated runbook with explicit manual trigger guidance and post-incident review scheduling.</li> <li>Captured drill notes in Confluence page <code>EMB-Rollback-2024Q3</code>; linked to on-call handbook.</li> </ul>"},{"location":"operations/rollback_drills/#4-follow-up-actions","title":"4. Follow-up Actions","text":"<ul> <li>Maintain quarterly schedule for combined staging + production drills.</li> <li>Automate collection of rollback metrics using Grafana snapshots.</li> <li>Ensure rollback template (see <code>../templates/rollback_incident_template.md</code>) is attached to every drill ticket.</li> </ul>"},{"location":"operations/tenant_isolation_pen_test/","title":"Tenant Isolation Penetration Test Report","text":"<p>Date: 2024-07-18 Scope: Gateway REST, GraphQL, and gRPC embedding surfaces (multi-tenancy enforcement).</p>"},{"location":"operations/tenant_isolation_pen_test/#objectives","title":"Objectives","text":"<ul> <li>Validate that tenant metadata is enforced across REST, GraphQL, and gRPC embedding endpoints.</li> <li>Ensure namespace access control prevents unauthorized namespace usage.</li> <li>Confirm observability alerts when cross-tenant attempts occur.</li> </ul>"},{"location":"operations/tenant_isolation_pen_test/#methodology","title":"Methodology","text":"<ol> <li>Reconnaissance \u2013 Enumerated namespaces through authorized tenant tokens to identify access surfaces.</li> <li>REST Attack Simulation \u2013 Used <code>scripts/audit_tenant_isolation.py</code> to issue cross-tenant requests against <code>/v1/embed</code> with forged tenant IDs.</li> <li>GraphQL Mutation Fuzzing \u2013 Leveraged <code>tests/gateway/test_graphql_embedding.py::test_cross_tenant_denied</code> as baseline, replayed with varying namespace/scope combinations.</li> <li>gRPC Channel Probing \u2013 Executed <code>tests/contract/test_grpc_server.py::test_cross_tenant_denied</code> using mismatched tenant metadata.</li> <li>Telemetry Review \u2013 Queried Prometheus for <code>medicalkg_cross_tenant_access_attempts_total</code> and verified audit logs.</li> </ol>"},{"location":"operations/tenant_isolation_pen_test/#findings","title":"Findings","text":"<ul> <li>All cross-tenant requests returned <code>403</code> with <code>Tenant not authorized for namespace</code> responses.</li> <li>Namespace registry correctly denied tenants outside <code>allowed_tenants</code> list.</li> <li>Middleware injected <code>validated_tenant_id</code> and prevented spoofed JWT tenant IDs.</li> <li>Metrics counter incremented for each blocked attempt, enabling alerting.</li> <li>No data exfiltration vectors observed via request replay or parameter fuzzing.</li> </ul>"},{"location":"operations/tenant_isolation_pen_test/#remediations","title":"Remediations","text":"<ul> <li>None required. Existing safeguards met penetration test criteria.</li> <li>Scheduled quarterly re-test aligned with security calendar.</li> </ul>"},{"location":"operations/tenant_isolation_pen_test/#evidence-artifacts","title":"Evidence Artifacts","text":"<ul> <li>REST denial logs: <code>gateway-embedding-service-2024-07-18.log</code> (attached in internal ticket).</li> <li>Prometheus snapshot: <code>prom://medicalkg_cross_tenant_access_attempts_total?time=2024-07-18T02:10Z</code>.</li> <li>Test execution trace stored in CI artifact <code>tenant-isolation-penetration.zip</code>.</li> </ul>"},{"location":"operations/tenant_isolation_pen_test/#sign-off","title":"Sign-off","text":"<ul> <li>Security Lead: Ada McKenzie (<code>ada.mckenzie@medicalkg.example</code>)</li> <li>Reviewer: Ops On-call (Week 29)</li> </ul> <p>Penetration testing complete. Tenant isolation controls verified.</p>"},{"location":"reranking/guide/","title":"Reranking &amp; Fusion Guide","text":""},{"location":"reranking/guide/#rerankerport-interface","title":"RerankerPort Interface","text":"<p>All rerankers implement the <code>RerankerPort</code> interface defined under <code>Medical_KG_rev.services.reranking.ports</code>. The contract requires a <code>score_pairs</code> method that accepts a sequence of <code>QueryDocumentPair</code> instances and returns a <code>RerankingResponse</code> containing ordered <code>RerankResult</code> entries. Implementations should:</p> <ul> <li>Validate tenant isolation before scoring.</li> <li>Support configurable batch sizes and honour the <code>top_k</code> limiter.</li> <li>Normalise scores to the <code>[0, 1]</code> interval for downstream fusion compatibility.</li> <li>Respect the <code>requires_gpu</code> flag to fail fast when GPU acceleration is mandatory.</li> </ul>"},{"location":"reranking/guide/#selecting-a-reranker","title":"Selecting a Reranker","text":"Scenario Recommended Reranker Notes Maximum quality, GPU available <code>cross_encoder:bge</code> Uses FP16 acceleration when deployed on CUDA devices. Low latency CPU workloads <code>cross_encoder:minilm</code> Balances lexical and dense features with optional INT8 quantisation. Generative scoring <code>cross_encoder:monot5</code> Applies prompt-style relevance estimation. LLM-backed reranking <code>cross_encoder:qwen</code> Calls vLLM/OpenAI compatible endpoints. ColBERT late interaction <code>late_interaction:colbert_index</code> Fetches token vectors from an external ColBERT index. OpenSearch first/second phase ranking <code>ltr:opensearch</code> Integrates with SLTR feature stores."},{"location":"reranking/guide/#model-registry-selection","title":"Model Registry &amp; Selection","text":"<ul> <li>Configuration: <code>config/retrieval/reranking_models.yaml</code> lists supported rerankers, their HuggingFace identifiers, and rollout metadata. Update this file when onboarding a new model; manifests are cached under <code>model_cache/rerankers/</code>.</li> <li>API Overrides: Clients may select a model via <code>GET /v1/search?rerank_model=ms-marco-minilm-l12-v2</code> (REST), GraphQL <code>RetrieveInput.rerank_model</code>, or the pipeline query payload. Unknown models gracefully fall back to the default while annotating the response metadata with a <code>warnings: [\"model_fallback\"]</code> entry.</li> <li>Versioning: Retrieval responses expose <code>rerank.metrics.model.version</code> so dashboards and CI checks can track upgrades across deployments.</li> <li>A/B Testing: Pair the model registry with <code>Medical_KG_rev.services.evaluation.ABTestRunner</code> to compare <code>nDCG@10</code> deltas before promoting a challenger model. A +5% uplift is required before enabling reranking by default for a tenant.</li> </ul>"},{"location":"reranking/guide/#fusion-algorithms-trade-offs","title":"Fusion Algorithms &amp; Trade-offs","text":"<ul> <li>Reciprocal Rank Fusion (RRF): Fast heuristic that blends rankings from multiple retrievers. Tie-breaking now honours original retrieval scores to maintain deterministic ordering.</li> <li>Weighted Fusion: Applies min-max normalisation before combining strategies with configured weights. Validations ensure weights sum to 1.</li> <li>Deduplication: Duplicate documents merge metadata, highlights, and per-strategy scores before final ranking.</li> </ul>"},{"location":"reranking/guide/#yaml-configuration-examples","title":"YAML Configuration Examples","text":"<pre><code>reranking:\n  enabled: true\n  cache_ttl: 1800\n  model:\n    reranker_id: cross_encoder:bge\n    device: cuda:0\n    precision: fp16\n  fusion:\n    strategy: rrf\n    rrf_k: 90\n  pipeline:\n    retrieve_candidates: 1500\n    rerank_candidates: 200\n    return_top_k: 20\n</code></pre> <p>Legacy configuration documents can be converted with <code>Medical_KG_rev.config.migrate_reranking_config</code> which supports <code>model_name</code>, <code>fusion_strategy</code>, and <code>cacheTtl</code> keys.</p>"},{"location":"reranking/guide/#batch-processing-gpu-optimisation","title":"Batch Processing &amp; GPU Optimisation","text":"<ul> <li><code>BatchProcessor</code> adapts batch sizes based on live GPU memory snapshots and can operate asynchronously for multi-query reranking.</li> <li>FP16 precision is automatically leveraged for BGE rerankers on CUDA devices; set <code>precision: fp16</code> in configuration.</li> <li>Long-running batches trigger automatic splits and issue Prometheus alerts for potential GPU saturation.</li> </ul>"},{"location":"reranking/guide/#troubleshooting","title":"Troubleshooting","text":"Symptom Likely Cause Resolution <code>GPUUnavailableError</code> Reranker requires CUDA but none detected Update deployment targets or disable GPU-only rerankers. Low cache hit rate Index updates invalidated cache Use cache warming via <code>RerankingEngine.warm_cache</code> for popular queries. Slow reranking latency Oversized batches triggering splits Check <code>reranking_duration_seconds</code> histogram and reduce <code>rerank_candidates</code>."},{"location":"reranking/guide/#evaluation-harness-usage","title":"Evaluation Harness Usage","text":"<pre><code>from Medical_KG_rev.services.reranking.evaluation.harness import RerankerEvaluator\n\nevaluator = RerankerEvaluator(ground_truth={\"q1\": {\"doc-1\", \"doc-2\"}})\nresult = evaluator.evaluate(\"cross_encoder:bge\", {\"q1\": [\"doc-1\", \"doc-3\"]}, [12, 18, 22])\ncurve = evaluator.build_tradeoff_curve([result])\nleaderboard = evaluator.leaderboard([result])\n</code></pre> <p>Trade-off curves return <code>(latency_p95_ms, ndcg_at_10)</code> points, while <code>ab_test</code> reports metric deltas between baseline and challenger rerankers.</p>"},{"location":"runbooks/embeddings_service_runbook/","title":"Embeddings Service Operations Runbook","text":"<p>This runbook fulfils task 10.3.1 of the <code>add-embeddings-representation</code> change.  It is intended for the SRE team that operates the GPU-only embedding stack.</p>"},{"location":"runbooks/embeddings_service_runbook/#1-vllm-service-lifecycle","title":"1. vLLM Service Lifecycle","text":"<ol> <li>Build the image:    <code>bash    docker compose build vllm-qwen3</code></li> <li>Deploy via Kubernetes (see manifests under <code>ops/k8s</code>):    <code>bash    kubectl apply -k ops/k8s/overlays/production</code></li> <li>Health check endpoint: <code>GET /health</code> should return <code>{\"status\":\"healthy\"}</code>.</li> <li>Embedding endpoint: <code>POST /v1/embeddings</code> with namespace-qualified models    (e.g. <code>single_vector.qwen3.4096.v1</code>).</li> </ol>"},{"location":"runbooks/embeddings_service_runbook/#configuration-sources","title":"Configuration Sources","text":"<ul> <li>Dense embedding service parameters live in <code>config/embedding/vllm.yaml</code> and are   parsed via <code>Medical_KG_rev.config.load_vllm_config</code>. Update GPU utilisation,   batching thresholds, or model metadata there and commit with the rollout.</li> <li>Sparse SPLADE settings (Pyserini) reside in <code>config/embedding/pyserini.yaml</code>.   The helper <code>load_pyserini_config</code> validates the schema and exposes   OpenSearch-specific knobs (<code>rank_features_field</code>, <code>max_weight</code>).</li> </ul>"},{"location":"runbooks/embeddings_service_runbook/#2-gpu-troubleshooting","title":"2. GPU Troubleshooting","text":"Symptom Checks Resolution Pod fails to start <code>kubectl describe pod</code> \u2192 look for <code>nvidia.com/gpu</code> scheduling errors Ensure node has GPU label and drivers installed. 503 GPU unavailable <code>scripts.embedding.verify_environment</code> reports <code>available: false</code> Reboot node, reseat drivers, or cordon and drain affected node. OOM vLLM logs mention CUDA OOM Reduce batch size via <code>GPU_MEMORY_UTILIZATION</code> env var and redeploy."},{"location":"runbooks/embeddings_service_runbook/#3-faiss-index-management","title":"3. FAISS Index Management","text":"<ol> <li>Initial bootstrap via <code>scripts/vector_store/bootstrap_faiss.py</code> (ensures HNSW    index and metadata in object storage).</li> <li>Incremental updates handled by <code>VectorStoreService.upsert</code>; monitor the    <code>embedding.vector_store.upserted</code> metric.</li> <li>Rebuild procedure:</li> <li>Pause ingestion pipeline.</li> <li>Delete FAISS PVC (<code>kubectl delete pvc faiss-data</code>).</li> <li>Re-run bootstrap script.</li> <li>Resume ingestion.</li> </ol>"},{"location":"runbooks/embeddings_service_runbook/#4-opensearch-rank-features","title":"4. OpenSearch Rank Features","text":"<ul> <li>Index templates defined in <code>config/embedding/namespaces/*.yaml</code> include the   <code>rank_features</code> mapping.  Apply template updates using the   <code>scripts/opensearch/apply_rank_features.py</code> helper.</li> <li>Validate with:   <code>bash   curl -u \"$USER:$PASS\" https://opensearch/_mapping | jq '.properties'</code></li> </ul>"},{"location":"runbooks/embeddings_service_runbook/#5-monitoring-alerting","title":"5. Monitoring &amp; Alerting","text":"<ul> <li>Dashboards \u2013 Grafana folder <code>Embeddings &amp; Representation</code>.  Panels:   latency (FAISS P95 &lt; 50ms, OpenSearch P95 &lt; 200ms), throughput, and GPU   utilisation.</li> <li>Alerts \u2013 Prometheus rules located in <code>ops/monitoring/embeddings.rules.yaml</code>:</li> <li><code>EmbeddingGpuUnavailable</code> \u2013 triggered when health endpoint returns non-200.</li> <li><code>EmbeddingThroughputLow</code> \u2013 triggered when throughput &lt; 500 emb/sec.</li> <li><code>EmbeddingLatencyHigh</code> \u2013 triggered when FAISS P95 &gt; 80ms for 5 minutes.</li> </ul>"},{"location":"runbooks/embeddings_service_runbook/#6-namespace-access-controls","title":"6. Namespace Access Controls","text":"<ul> <li>Discovery API <code>GET /v1/namespaces</code> requires <code>embed:read</code>. Returns   <code>NamespaceInfo</code> entries with <code>allowed_tenants</code> and <code>allowed_scopes</code>.</li> <li>Validation API <code>POST /v1/namespaces/{namespace}/validate</code> checks token   budgets before embedding. Calls <code>transformers.AutoTokenizer</code> based on the   namespace config and records <code>medicalkg_cross_tenant_access_attempts_total</code>   when blocked.</li> <li>Embedding requests (<code>POST /v1/embed</code>) must include <code>tenant_id</code> and a   namespace registered for that tenant. The FastAPI middleware   <code>TenantValidationMiddleware</code> fails the request if the JWT tenant differs   from the payload.</li> <li>For investigations, audit the <code>namespace_access</code> entries in the gateway   logs and the Prometheus counter above.</li> </ul>"},{"location":"runbooks/embeddings_service_runbook/#7-emergency-procedures","title":"7. Emergency Procedures","text":"<ol> <li>Rollback \u2013 Scale down vLLM deployment and scale up the legacy    <code>sentence-transformers</code> worker (available in <code>ops/k8s/overlays/rollback</code>).    Automated rollback conditions are codified in    <code>config/monitoring/rollback_triggers.yaml</code> and are mirrored as Grafana    alerts. Keep that file in sync with dashboard IDs referenced below.</li> <li>Restart \u2013 <code>kubectl rollout restart deployment vllm-qwen3</code>.</li> <li>Purge cache \u2013 Delete <code>.vllm_cache</code> PVC to flush stale KV cache.</li> </ol> <p>Rollback Triggers</p> <ul> <li>Automated alerts \u2013 See <code>config/monitoring/rollback_triggers.yaml</code> for   the canonical set of alerting rules (latency degradation, GPU failure rate,   token overflow, vLLM availability). Any critical trigger automatically opens   a PagerDuty incident and recommends running the rollback script.</li> <li>Manual triggers \u2013 Initiate rollback when any of the following conditions   are observed even if alerts have not fired:</li> <li>Embedding quality degradation (Recall@10 drop \u22655% from previous baseline).</li> <li>GPU memory leaks or repeated OOMs despite healthy alert status.</li> <li>vLLM startup failures (health checks stuck in <code>503</code> for &gt;5 minutes after     deployment).</li> <li>Incorrect vector dimensions or sparse term weights detected during smoke     tests (e.g., FAISS <code>DimensionMismatchError</code>).</li> </ul> <p>After invoking a manual trigger, attach the <code>docs/templates/rollback_incident_template.md</code> to the incident ticket and schedule the post-incident review within two hours of rollback completion.</p> <p>RTO Targets</p> <ul> <li>Canary rollback: 5 minutes (scale down new workloads, scale up legacy).</li> <li>Full rollback (with OpenSearch mapping restoration): 15 minutes.</li> <li>Maximum tolerated RTO: 20 minutes (documented in incident postmortem).</li> </ul> <p>Perform quarterly rollback drills in staging following <code>scripts/rollback_embeddings.sh</code> and record metrics in the change log. Drill outcomes and RTO validation history are tracked in <code>docs/operations/rollback_drills.md</code>.</p>"},{"location":"runbooks/embeddings_service_runbook/#8-pre-deployment-checklist-task-1113","title":"8. Pre-Deployment Checklist (Task 11.1.3)","text":"<ul> <li>[x] Unit and integration tests green (<code>pytest tests/embeddings -q</code>).</li> <li>[x] <code>scripts/detect_dangling_imports.py</code> returns success.</li> <li>[x] GPU fail-fast path validated via <code>scripts.embedding.verify_environment</code>.</li> <li>[x] Dashboards and alerts reviewed with operations team.</li> <li>[x] Runbook reviewed and linked from on-call handbook.</li> </ul>"},{"location":"runbooks/embeddings_service_runbook/#9-staging-production-rollout-tasks-112-113","title":"9. Staging &amp; Production Rollout (Tasks 11.2 &amp; 11.3)","text":"<ol> <li>Deploy to staging overlay and run smoke tests (<code>tests/smoke/embed_smoke.py</code>).</li> <li>Run storage migration job to rebuild FAISS and OpenSearch indices.</li> <li>Promote manifests to production overlay, monitor for 24\u201348 hours.</li> <li>Capture performance deltas and lessons learned in post-deployment report.</li> </ol> <p>This document should be attached to the change record during CAB review and kept up-to-date with future enhancements.</p>"},{"location":"runbooks/mineru-two-phase-gate/","title":"MinerU Two-Phase Gate Runbook","text":"<p>The PDF ingestion pipeline is split into two phases to enforce GPU-backed MinerU parsing before chunking and embeddings resume. This runbook explains how operators can monitor, unblock, and validate the workflow.</p>"},{"location":"runbooks/mineru-two-phase-gate/#prerequisites","title":"Prerequisites","text":"<ul> <li>MinerU GPU service deployed (<code>Medical_KG_rev.services.gpu.mineru_service</code>)</li> <li>Job ledger entries with the additional PDF gate fields</li> <li>Gateway endpoint <code>/v1/jobs/{job_id}/postpdf-start</code> available</li> <li>Chunking stack deployed with the new Hugging Face sentence segmenter</li> </ul>"},{"location":"runbooks/mineru-two-phase-gate/#operational-flow","title":"Operational Flow","text":"<ol> <li>PDF Download \u2013 Orchestration workers fetch the PDF and update the job    ledger with <code>pdf_downloaded=True</code>.</li> <li>MinerU Parsing \u2013 GPU service converts PDFs into Markdown/JSON artifacts,    extracts bounding boxes, and emits table HTML when rectangularization is    uncertain.</li> <li>Ledger Update \u2013 Successful MinerU execution sets    <code>pdf_ir_ready=True</code> and stores the <code>mineru_bbox_map</code> payload.</li> <li>Manual Resume \u2013 Operators trigger <code>/v1/jobs/{job_id}/postpdf-start</code> once    the GPU output is verified.</li> <li>Chunking &amp; Embedding \u2013 Downstream stages pick up the job, load the saved    MinerU artifacts, and proceed using the profile-specific chunker.</li> </ol>"},{"location":"runbooks/mineru-two-phase-gate/#triggering-postpdf-start","title":"Triggering <code>postpdf-start</code>","text":"<pre><code>curl -X POST \"https://&lt;gateway&gt;/v1/jobs/${JOB_ID}/postpdf-start\" \\\n  -H \"Authorization: Bearer ${TOKEN}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"data\":{\"type\":\"postpdf-start\",\"attributes\":{}}}'\n</code></pre> <p>The gateway validates that <code>pdf_ir_ready</code> is <code>true</code>. If the check fails, the API returns <code>409 Conflict</code> with details. Successful requests mark <code>postpdf_start_triggered=True</code>.</p>"},{"location":"runbooks/mineru-two-phase-gate/#troubleshooting","title":"Troubleshooting","text":"Symptom Action MinerU job fails with GPU error Confirm GPU availability (<code>nvidia-smi</code>), redeploy MinerU, and retry the job. <code>postpdf-start</code> returns 409 Inspect ledger entry via Dagster UI or Redis CLI to confirm PDF IR readiness. Chunker rejects MinerU output Run <code>scripts/check_chunking_dependencies.py</code> to verify dependencies and ensure the correct profile is selected. Missing tables in chunks Check MinerU HTML artifacts for <code>is_unparsed_table=true</code> and rerun chunking after manual review."},{"location":"runbooks/mineru-two-phase-gate/#monitoring-checklist","title":"Monitoring Checklist","text":"<ul> <li>Grafana dashboard <code>Medical_KG_Chunking_Quality</code> \u2013 monitor chunk counts,   failure rates, and sentence segmentation fallback events.</li> <li>Prometheus metrics <code>mineru_gate_triggered_total</code> and   <code>postpdf_start_triggered_total</code> \u2013 confirm jobs move through the two-phase gate.</li> <li>Dagster sensor logs \u2013 ensure the post-PDF pipeline triggers automatically   after manual approval.</li> </ul>"},{"location":"runbooks/mineru-two-phase-gate/#related-guides","title":"Related Guides","text":"<ul> <li>Chunking &amp; Parsing Runtime</li> <li>Chunking Profiles</li> <li>OpenSpec Change Documentation</li> </ul>"},{"location":"runbooks/vllm-server-restart/","title":"Runbook: Restarting the vLLM Server","text":"<p>This runbook explains how to safely restart the vLLM server that serves MinerU workers.</p>"},{"location":"runbooks/vllm-server-restart/#preconditions","title":"Preconditions","text":"<ul> <li>MinerU jobs draining or paused</li> <li>Operator access to the <code>medical-kg</code> namespace</li> <li>Grafana + Prometheus available for monitoring</li> </ul>"},{"location":"runbooks/vllm-server-restart/#steps","title":"Steps","text":"<ol> <li> <p>Scale MinerU workers to zero <code>bash    kubectl scale deployment/mineru-workers --replicas=0 -n medical-kg    kubectl rollout status deployment/mineru-workers -n medical-kg</code></p> </li> <li> <p>Restart the vLLM deployment <code>bash    kubectl rollout restart deployment/vllm-server -n medical-kg    kubectl rollout status deployment/vllm-server -n medical-kg</code></p> </li> <li> <p>Verify health <code>bash    kubectl exec -n medical-kg deployment/vllm-server -- curl -sf http://localhost:8000/health</code></p> </li> <li> <p>Scale MinerU workers back up <code>bash    kubectl scale deployment/mineru-workers --replicas=8 -n medical-kg    kubectl rollout status deployment/mineru-workers -n medical-kg</code></p> </li> <li> <p>Monitor metrics</p> </li> <li>Grafana dashboard: <code>MinerU / vLLM</code></li> <li> <p>Prometheus queries:</p> <ul> <li><code>mineru_vllm_request_duration_seconds:histogram_quantile(0.95, sum(rate(...)[5m]))</code></li> <li><code>mineru_vllm_circuit_breaker_state</code></li> </ul> </li> <li> <p>Resume job submission once metrics stabilise and worker readiness probes are healthy.</p> </li> </ol>"},{"location":"runbooks/vllm-server-restart/#rollback","title":"Rollback","text":"<p>If the restart fails, roll back the vLLM deployment:</p> <pre><code>kubectl rollout undo deployment/vllm-server -n medical-kg\n</code></pre> <p>Then scale workers back to the previous replica count.</p>"},{"location":"runbooks/vllm-server-restart/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] vLLM <code>/health</code> returns HTTP 200</li> <li>[ ] MinerU workers <code>READY</code></li> <li>[ ] Circuit breaker metric returns to <code>0</code> (closed)</li> <li>[ ] No <code>mineru_vllm_client_failures_total</code> increase during restart window</li> </ul>"},{"location":"troubleshooting/vllm-connectivity/","title":"Troubleshooting Guide: MinerU \u2194 vLLM Connectivity","text":"<p>This guide catalogues common failure scenarios when MinerU workers communicate with the vLLM server.</p>"},{"location":"troubleshooting/vllm-connectivity/#1-worker-startup-failure","title":"1. Worker Startup Failure","text":"<p>Symptoms - Worker pod fails readiness probe - Logs show <code>vLLM server health check failed on startup</code></p> <p>Diagnostics - <code>kubectl logs deployment/mineru-workers -n medical-kg --tail=100</code> - <code>kubectl get pods -n medical-kg -l app=vllm-server</code> - <code>kubectl exec -n medical-kg deployment/mineru-workers -- curl -sf http://vllm-server:8000/health</code></p> <p>Resolution - Ensure the vLLM pod is running and ready - Check <code>networkpolicy-vllm-server.yaml</code> to confirm worker namespace selector - Verify DNS resolution inside the worker pod (<code>nslookup vllm-server</code>)</p>"},{"location":"troubleshooting/vllm-connectivity/#2-elevated-latency-timeouts","title":"2. Elevated Latency / Timeouts","text":"<p>Symptoms - <code>mineru_vllm_client_failures_total{error_type=\"timeout\"}</code> increasing - Circuit breaker transitions to <code>OPEN</code></p> <p>Diagnostics - Grafana: inspect the <code>vLLM Queue Depth</code> panel - Prometheus query: <code>vllm_time_to_first_token_seconds</code> and <code>gpu_utilization</code> - Review worker logs for <code>mineru.vllm.retry</code> warnings</p> <p>Resolution - Scale the vLLM deployment vertically (larger GPU) or horizontally (tensor parallelism) - Increase <code>connection_pool_size</code> and <code>retry_attempts</code> in <code>config/mineru.yaml</code> - Confirm no other workloads are saturating the GPU node</p>"},{"location":"troubleshooting/vllm-connectivity/#3-authentication-tls-issues","title":"3. Authentication / TLS Issues","text":"<p>Symptoms - Workers report <code>HTTP 403</code> or <code>HTTP 495</code></p> <p>Diagnostics - Inspect vLLM server logs for mTLS or token errors - Confirm configuration in <code>ops/k8s/base/configmap-vllm-server.yaml</code> - Check Istio/NGINX ingress annotations if traffic passes through a mesh</p> <p>Resolution - Regenerate and distribute TLS certificates if mutual TLS enabled - Ensure worker environment includes updated auth headers via ConfigMap or Secret</p>"},{"location":"troubleshooting/vllm-connectivity/#4-model-download-failures","title":"4. Model Download Failures","text":"<p>Symptoms - vLLM pod stuck pulling model - Logs show <code>Read timeout</code> from Hugging Face</p> <p>Diagnostics - <code>kubectl logs deployment/vllm-server -n medical-kg</code> - Check PVC mount <code>pvc-huggingface-cache</code> - Inspect egress firewall rules</p> <p>Resolution - Pre-seed the model artefacts into the PVC - Allow outbound HTTPS to <code>huggingface.co</code> - Increase <code>connection_timeout_seconds</code> in <code>config/mineru.yaml</code></p>"},{"location":"troubleshooting/vllm-connectivity/#5-persistent-circuit-breaker-open-state","title":"5. Persistent Circuit Breaker Open State","text":"<p>Symptoms - <code>mineru_vllm_circuit_breaker_state</code> remains at <code>2</code> - Workers immediately fail with <code>Circuit breaker is open</code></p> <p>Diagnostics - Inspect worker logs for the first failure event - Query Prometheus for <code>mineru_vllm_client_failures_total</code> to identify root cause</p> <p>Resolution - Validate network connectivity and DNS - If vLLM server recovered, restart MinerU workers to reset the breaker state - Consider increasing <code>recovery_timeout_seconds</code> after verifying stability</p> <p>Document root causes and mitigations in the incident tracker to aid future responses.</p>"}]}