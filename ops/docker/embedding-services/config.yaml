# Embedding services configuration
embedding_services:
    host: "0.0.0.0"
    port: 50051
    log_level: "INFO"

    # GPU management
    gpu:
        enabled: true
        device_id: 0
        memory_fraction: 0.8
        fail_fast: true # Fail immediately if GPU unavailable

    # Model configurations
    models:
        default:
            model_name: "sentence-transformers/all-MiniLM-L6-v2"
            batch_size: 32
            max_length: 512

        biomedical:
            model_name: "sentence-transformers/all-MiniLM-L6-v2"
            batch_size: 32
            max_length: 512

        multilingual:
            model_name: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
            batch_size: 16
            max_length: 512

    # Performance
    performance:
        max_concurrent_requests: 10
        request_timeout: 30
        batch_processing: true
        cache_size: 1000

    # Health checks
    health:
        check_interval: 30
        gpu_check: true
        memory_check: true
        model_check: true
