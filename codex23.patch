diff --git a/openspec/changes/add-pluggable-orchestration-stages/tasks.md b/openspec/changes/add-pluggable-orchestration-stages/tasks.md
index 1184eb83911ab47d72fcbae2ac0010003ddaed79..8a0d342a7270cba86d7b9402c792987faf5fa9dc 100644
--- a/openspec/changes/add-pluggable-orchestration-stages/tasks.md
+++ b/openspec/changes/add-pluggable-orchestration-stages/tasks.md
@@ -1,122 +1,122 @@
 # Implementation Tasks: Pluggable Orchestration Stages

 ## 1. Stage Metadata System Design

 ### 1.1 Define Stage Metadata Model

-- [ ] 1.1.1 Create `StageMetadata` dataclass with fields:
+- [x] 1.1.1 Create `StageMetadata` dataclass with fields:
   - `stage_type: str` - The stage type identifier
   - `state_key: str` - Key used in orchestration state (e.g., "payloads", "document")
   - `output_handler: Callable` - Function to apply stage output to state
   - `output_counter: Callable` - Function to count stage outputs for metrics
   - `description: str` - Human-readable description of stage purpose
   - `dependencies: list[str]` - Optional list of stage types this depends on
-- [ ] 1.1.2 Create `StageRegistry` class to manage stage metadata
-- [ ] 1.1.3 Add validation for metadata consistency (e.g., state_key should be valid Python identifier)
+- [x] 1.1.2 Create `StageRegistry` class to manage stage metadata
+- [x] 1.1.3 Add validation for metadata consistency (e.g., state_key should be valid Python identifier)

 ### 1.2 Plugin Registry Architecture

-- [ ] 1.2.1 Design entry point group: `medical_kg.orchestration.stages`
-- [ ] 1.2.2 Create `StagePlugin` protocol for stage registration functions
-- [ ] 1.2.3 Implement `discover_stages()` function using `importlib.metadata.entry_points()`
-- [ ] 1.2.4 Add error handling for malformed plugin registrations
+- [x] 1.2.1 Design entry point group: `medical_kg.orchestration.stages`
+- [x] 1.2.2 Create `StagePlugin` protocol for stage registration functions
+- [x] 1.2.3 Implement `discover_stages()` function using `importlib.metadata.entry_points()`
+- [x] 1.2.4 Add error handling for malformed plugin registrations

 ## 2. Core Runtime Refactoring

 ### 2.1 Migrate Existing Stages to Metadata System

-- [ ] 2.1.1 Define metadata for all existing stage types:
+- [x] 2.1.1 Define metadata for all existing stage types:
   - `ingest` → state_key: "payloads", output_handler: set_payloads, output_counter: len
   - `parse` → state_key: "document", output_handler: set_document, output_counter: 1
   - `ir-validation` → state_key: "document", output_handler: set_document, output_counter: 1
   - `chunk` → state_key: "chunks", output_handler: set_chunks, output_counter: len
   - `embed` → state_key: "embedding_batch", output_handler: set_embedding_batch, output_counter: len(vectors)
   - `index` → state_key: "index_receipt", output_handler: set_index_receipt, output_counter: chunks_indexed
   - `extract` → state_key: ["entities", "claims"], output_handler: unpack_extraction, output_counter: len(entities)+len(claims)
   - `knowledge-graph` → state_key: "graph_receipt", output_handler: set_graph_receipt, output_counter: nodes_written
-- [ ] 2.1.2 Create default metadata registry with all existing stages
-- [ ] 2.1.3 Update `build_default_stage_factory` to use metadata registry
+- [x] 2.1.2 Create default metadata registry with all existing stages
+- [x] 2.1.3 Update `build_default_stage_factory` to use metadata registry

 ### 2.2 Update Runtime Functions

-- [ ] 2.2.1 Replace hardcoded `_stage_state_key()` with metadata lookup
-- [ ] 2.2.2 Replace hardcoded `_apply_stage_output()` with metadata-driven output handling
-- [ ] 2.2.3 Replace hardcoded `_infer_output_count()` with metadata-driven counting
-- [ ] 2.2.4 Update `StageFactory.resolve()` to use metadata for validation
+- [x] 2.2.1 Replace hardcoded `_stage_state_key()` with metadata lookup
+- [x] 2.2.2 Replace hardcoded `_apply_stage_output()` with metadata-driven output handling
+- [x] 2.2.3 Replace hardcoded `_infer_output_count()` with metadata-driven counting
+- [x] 2.2.4 Update `StageFactory.resolve()` to use metadata for validation

 ### 2.3 Add Plugin Discovery

-- [ ] 2.3.1 Modify `StageFactory.__init__()` to accept optional plugin registry
-- [ ] 2.3.2 Add `register_stage()` method to dynamically add stages at runtime
-- [ ] 2.3.3 Implement `load_plugins()` class method to discover and load stage plugins
-- [ ] 2.3.4 Add plugin validation during discovery (ensure required metadata fields)
+- [x] 2.3.1 Modify `StageFactory.__init__()` to accept optional plugin registry
+- [x] 2.3.2 Add `register_stage()` method to dynamically add stages at runtime
+- [x] 2.3.3 Implement `load_plugins()` class method to discover and load stage plugins
+- [x] 2.3.4 Add plugin validation during discovery (ensure required metadata fields)

 ## 3. Example Plugin Implementations

 ### 3.1 Download Stage Plugin

-- [ ] 3.1.1 Create `download` stage metadata:
+- [x] 3.1.1 Create `download` stage metadata:
   - state_key: "downloaded_files"
   - output_handler: handles file download results
   - output_counter: counts downloaded files
-- [ ] 3.1.2 Implement `DownloadStage` class implementing the stage protocol
-- [ ] 3.1.3 Create entry point registration for download stage
-- [ ] 3.1.4 Add configuration for download stage (URLs, retry policies, etc.)
+- [x] 3.1.2 Implement `DownloadStage` class implementing the stage protocol
+- [x] 3.1.3 Create entry point registration for download stage
+- [x] 3.1.4 Add configuration for download stage (URLs, retry policies, etc.)

 ### 3.2 Gate Stage Plugin

-- [ ] 3.2.1 Create `gate` stage metadata:
+- [x] 3.2.1 Create `gate` stage metadata:
   - state_key: None (gate stages don't produce outputs)
   - output_handler: no-op handler
   - output_counter: returns 0
-- [ ] 3.2.2 Implement `GateStage` class that checks conditions and raises `GateConditionError` if not met
-- [ ] 3.2.3 Create entry point registration for gate stage
-- [ ] 3.2.4 Add configuration for gate conditions (ledger field checks, timeout, etc.)
+- [x] 3.2.2 Implement `GateStage` class that checks conditions and raises `GateConditionError` if not met
+- [x] 3.2.3 Create entry point registration for gate stage
+- [x] 3.2.4 Add configuration for gate conditions (ledger field checks, timeout, etc.)

 ## 4. Pipeline Configuration Updates

 ### 4.1 Extend Pipeline Schema

 - [ ] 4.1.1 Add plugin registration section to `PipelineTopologyConfig`
 - [ ] 4.1.2 Add stage metadata override capabilities in pipeline YAML
 - [ ] 4.1.3 Update pipeline validation to handle plugin-registered stages

 ### 4.2 Update Existing Pipelines

 - [ ] 4.2.1 Update `config/orchestration/pipelines/auto.yaml` to use new plugin system
 - [ ] 4.2.2 Update `config/orchestration/pipelines/pdf-two-phase.yaml` to include gate stage
 - [ ] 4.2.3 Ensure backward compatibility with existing pipeline definitions

 ## 5. Testing and Validation

 ### 5.1 Unit Tests for Core System

-- [ ] 5.1.1 Test `StageMetadata` validation and serialization
-- [ ] 5.1.2 Test `StageRegistry` plugin discovery and registration
-- [ ] 5.1.3 Test runtime functions use metadata correctly
-- [ ] 5.1.4 Test error handling for unknown stage types
+- [x] 5.1.1 Test `StageMetadata` validation and serialization
+- [x] 5.1.2 Test `StageRegistry` plugin discovery and registration
+- [x] 5.1.3 Test runtime functions use metadata correctly
+- [x] 5.1.4 Test error handling for unknown stage types

 ### 5.2 Integration Tests for New Stages

 - [ ] 5.2.1 Test download stage end-to-end with mocked file downloads
 - [ ] 5.2.2 Test gate stage with various condition scenarios (pass/fail/timeout)
 - [ ] 5.2.3 Test plugin registration and discovery mechanisms

 ### 5.3 Pipeline Integration Tests

 - [ ] 5.3.1 Test PDF two-phase pipeline with gate stage integration
 - [ ] 5.3.2 Test mixed plugin and built-in stage pipelines
 - [ ] 5.3.3 Test pipeline validation with new stage types

 ## 6. Documentation and Examples

 ### 6.1 Developer Documentation

 - [ ] 6.1.1 Update `docs/guides/pipeline-authoring.md` with plugin stage examples
 - [ ] 6.1.2 Create `docs/guides/custom-stages.md` with step-by-step guide
 - [ ] 6.1.3 Document entry point specification for third-party plugins

 ### 6.2 Code Examples

 - [ ] 6.2.1 Create example plugin package structure
 - [ ] 6.2.2 Add example download and gate stage implementations
diff --git a/pyproject.toml b/pyproject.toml
index eab57971582be9b3f564c065bb002cd594ad9f05..abc5ceb477559e77ce3f6ac096ce8db35f36af9f 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -646,50 +646,54 @@ docs = [
     "pdoc>=15.0.4",
 ]

 chunking = [
     "langchain-text-splitters>=0.3.11",
     "llama-index-core",
     "haystack-ai>=2.18.1",
     "unstructured>=0.11.8",
     "hdbscan>=0.8.40",
     "networkx>=3.2.1",
     "layoutparser>=0.3.4",
     "docling>=2.55.1",
     "gensim>=4.3.3",
     "nltk>=3.9.2",
     "pysbd>=0.3.4",
     "scikit-learn>=1.7.2",
     "spacy>=3.7.2",
 ]
 reranking = [
     "xgboost>=3.0.5",
 ]

 [project.entry-points."medical_kg.adapters"]
 example = "Medical_KG_rev.adapters.plugins.example:ExampleAdapterPlugin"

+[project.entry-points."medical_kg.orchestration.stages"]
+download = "Medical_KG_rev.orchestration.stage_plugins:register_download_stage"
+gate = "Medical_KG_rev.orchestration.stage_plugins:register_gate_stage"
+
 [project.urls]
 Homepage = "https://github.com/your-org/Medical_KG_rev"
 Documentation = "https://your-org.github.io/Medical_KG_rev"
 Repository = "https://github.com/your-org/Medical_KG_rev"
 Issues = "https://github.com/your-org/Medical_KG_rev/issues"

 [project.scripts]
 medkg = "Medical_KG_rev.cli:main"
 medkg-gateway = "Medical_KG_rev.gateway.main:main"

 [build-system]
 requires = ["setuptools>=68.0", "wheel"]
 build-backend = "setuptools.build_meta"

 [tool.setuptools.packages.find]
 where = ["src"]

 [tool.setuptools.package-data]
 "Medical_KG_rev.kg" = ["*.ttl"]
 "Medical_KG_rev.services.evaluation.data" = ["test_sets/*.yaml"]

 [tool.black]
 line-length = 100
 target-version = ["py312"]
 include = '\.pyi?$'
diff --git a/src/Medical_KG_rev/orchestration/dagster/runtime.py b/src/Medical_KG_rev/orchestration/dagster/runtime.py
index 11d5dc449d8439644b6964dddca4df13385d11d3..0a14a1c730de6675e658ad3d202de5a7b21f1935 100644
--- a/src/Medical_KG_rev/orchestration/dagster/runtime.py
+++ b/src/Medical_KG_rev/orchestration/dagster/runtime.py
@@ -1,236 +1,247 @@
 """Dagster runtime orchestration primitives."""

 from __future__ import annotations

-from dataclasses import dataclass
+from dataclasses import dataclass, field
 import re
 import time
 from pathlib import Path
-from typing import Any, Callable, Mapping, Sequence
+from typing import Any, Callable, Mapping
 from uuid import uuid4

 from dagster import (
     Definitions,
     ExecuteInProcessResult,
     In,
     Out,
     ResourceDefinition,
     RunRequest,
     SensorEvaluationContext,
     SkipReason,
     graph,
     op,
     sensor,
 )

 from Medical_KG_rev.adapters.plugins.bootstrap import get_plugin_manager
 from Medical_KG_rev.adapters.plugins.manager import AdapterPluginManager
 from Medical_KG_rev.adapters.plugins.models import AdapterRequest
 from Medical_KG_rev.orchestration.dagster.configuration import (
     PipelineConfigLoader,
     PipelineTopologyConfig,
     StageExecutionHooks,
     ResiliencePolicyLoader,
     StageDefinition,
 )
+from Medical_KG_rev.orchestration.dagster.stage_registry import (
+    StageMetadata,
+    StageRegistry,
+    StageRegistryError,
+)
 from Medical_KG_rev.orchestration.dagster.stages import (
     HaystackPipelineResource,
     build_default_stage_factory,
     create_default_pipeline_resource,
 )
 from Medical_KG_rev.orchestration.events import StageEventEmitter
 from Medical_KG_rev.orchestration.kafka import KafkaClient
 from Medical_KG_rev.orchestration.ledger import JobLedger, JobLedgerError
 from Medical_KG_rev.orchestration.openlineage import OpenLineageEmitter
 from Medical_KG_rev.orchestration.stages.contracts import StageContext
 from Medical_KG_rev.utils.logging import get_logger

 logger = get_logger(__name__)


 class StageResolutionError(RuntimeError):
     """Raised when a stage cannot be resolved from the registry."""


 @dataclass(slots=True)
 class StageFactory:
     """Resolve orchestration stages by topology stage type."""

-    registry: Mapping[str, Callable[[StageDefinition], object]]
+    registry: StageRegistry = field(default_factory=StageRegistry)

     def resolve(self, pipeline: str, stage: StageDefinition) -> object:
         try:
-            factory = self.registry[stage.stage_type]
-        except KeyError as exc:  # pragma: no cover - defensive guard
+            builder = self.registry.get_builder(stage.stage_type)
+            metadata = self.registry.get_metadata(stage.stage_type)
+        except StageRegistryError as exc:  # pragma: no cover - defensive guard
             raise StageResolutionError(
                 f"Pipeline '{pipeline}' declared unknown stage type '{stage.stage_type}'"
             ) from exc
-        instance = factory(stage)
+        instance = builder(stage)
         logger.debug(
             "dagster.stage.resolved",
             pipeline=pipeline,
             stage=stage.name,
             stage_type=stage.stage_type,
+            description=metadata.description,
         )
         return instance

+    def get_metadata(self, stage_type: str) -> StageMetadata:
+        return self.registry.get_metadata(stage_type)
+
+    def register_stage(
+        self,
+        *,
+        metadata: StageMetadata,
+        builder: Callable[[StageDefinition], object],
+        replace: bool = False,
+    ) -> None:
+        self.registry.register_stage(metadata=metadata, builder=builder, replace=replace)
+
+    def load_plugins(self) -> list[str]:
+        return self.registry.load_plugins()
+

 @op(
     name="bootstrap",
     out=Out(dict),
     config_schema={
         "context": dict,
         "adapter_request": dict,
         "payload": dict,
     },
 )
 def bootstrap_op(context) -> dict[str, Any]:
     """Initialise the orchestration state for a Dagster run."""

     ctx_payload = context.op_config["context"]
     adapter_payload = context.op_config["adapter_request"]
     payload = context.op_config.get("payload", {})

     stage_ctx = StageContext(
         tenant_id=ctx_payload["tenant_id"],
         job_id=ctx_payload.get("job_id"),
         doc_id=ctx_payload.get("doc_id"),
         correlation_id=ctx_payload.get("correlation_id"),
         metadata=ctx_payload.get("metadata", {}),
         pipeline_name=ctx_payload.get("pipeline_name"),
         pipeline_version=ctx_payload.get("pipeline_version"),
     )
     adapter_request = AdapterRequest.model_validate(adapter_payload)

     state = {
         "context": stage_ctx,
         "adapter_request": adapter_request,
         "payload": payload,
         "results": {},
         "job_id": stage_ctx.job_id,
     }
     logger.debug(
         "dagster.bootstrap.initialised",
         tenant_id=stage_ctx.tenant_id,
         pipeline=stage_ctx.pipeline_name,
     )
     return state


-def _stage_state_key(stage_type: str) -> str:
-    return {
-        "ingest": "payloads",
-        "parse": "document",
-        "ir-validation": "document",
-        "chunk": "chunks",
-        "embed": "embedding_batch",
-        "index": "index_receipt",
-        "extract": "extraction",
-        "knowledge-graph": "graph_receipt",
-    }.get(stage_type, stage_type)
-
-
 def _apply_stage_output(
-    stage_type: str,
+    metadata: StageMetadata,
     stage_name: str,
     state: dict[str, Any],
     output: Any,
 ) -> dict[str, Any]:
-    if stage_type == "ingest":
-        state["payloads"] = output
-    elif stage_type in {"parse", "ir-validation"}:
-        state["document"] = output
-    elif stage_type == "chunk":
-        state["chunks"] = output
-    elif stage_type == "embed":
-        state["embedding_batch"] = output
-    elif stage_type == "index":
-        state["index_receipt"] = output
-    elif stage_type == "extract":
-        entities, claims = output
-        state["entities"] = entities
-        state["claims"] = claims
-    elif stage_type == "knowledge-graph":
-        state["graph_receipt"] = output
-    else:  # pragma: no cover - guard for future expansion
-        state[_stage_state_key(stage_type)] = output
+    metadata.output_handler(state, stage_name, output)
+    snapshot = metadata.result_snapshot(state, output)
     state.setdefault("results", {})[stage_name] = {
-        "type": stage_type,
-        "output": state.get(_stage_state_key(stage_type)),
+        "type": metadata.stage_type,
+        "output": snapshot,
     }
     return state


-def _infer_output_count(stage_type: str, output: Any) -> int:
-    if output is None:
+def _infer_output_count(metadata: StageMetadata, output: Any) -> int:
+    try:
+        count = metadata.output_counter(output)
+    except Exception:  # pragma: no cover - defensive guard
         return 0
-    if stage_type in {"ingest", "chunk"} and isinstance(output, Sequence):
-        return len(output)
-    if stage_type in {"parse", "ir-validation"}:
-        return 1
-    if stage_type == "embed" and hasattr(output, "vectors"):
-        vectors = getattr(output, "vectors")
-        if isinstance(vectors, Sequence):
-            return len(vectors)
-    if stage_type == "index" and hasattr(output, "chunks_indexed"):
-        indexed = getattr(output, "chunks_indexed")
-        if isinstance(indexed, int):
-            return indexed
-    if stage_type == "extract" and isinstance(output, tuple) and len(output) == 2:
-        entities, claims = output
-        entity_count = len(entities) if isinstance(entities, Sequence) else 0
-        claim_count = len(claims) if isinstance(claims, Sequence) else 0
-        return entity_count + claim_count
-    if stage_type == "knowledge-graph" and hasattr(output, "nodes_written"):
-        nodes = getattr(output, "nodes_written", 0)
-        if isinstance(nodes, int):
-            return nodes
-    return 1
+    if not isinstance(count, int):  # pragma: no cover - defensive guard
+        try:
+            count = int(count)
+        except Exception:
+            return 0
+    return max(count, 0)
+
+
+def _resolve_upstream_value(
+    state: Mapping[str, Any], metadata: StageMetadata, stage_factory: StageFactory
+) -> Any:
+    if metadata.dependencies:
+        aggregated: dict[str, Any] = {}
+        for dependency in metadata.dependencies:
+            try:
+                dep_metadata = stage_factory.get_metadata(dependency)
+            except StageRegistryError:  # pragma: no cover - defensive guard
+                continue
+            dep_keys = dep_metadata.state_keys
+            if not dep_keys:
+                continue
+            if len(dep_keys) == 1:
+                key = dep_keys[0]
+                aggregated[key] = state.get(key)
+            else:
+                aggregated[dependency] = {key: state.get(key) for key in dep_keys}
+        if aggregated:
+            if len(aggregated) == 1:
+                return next(iter(aggregated.values()))
+            return aggregated
+    keys = metadata.state_keys
+    if keys is None or not keys:
+        return state.get(metadata.stage_type)
+    if len(keys) == 1:
+        return state.get(keys[0])
+    return {key: state.get(key) for key in keys}


 def _make_stage_op(
     topology: PipelineTopologyConfig,
     stage_definition: StageDefinition,
 ):
     stage_type = stage_definition.stage_type
     stage_name = stage_definition.name
     policy_name = stage_definition.policy or "default"

     @op(
         name=stage_name,
         ins={"state": In(dict)},
         out=Out(dict),
         required_resource_keys={
             "stage_factory",
             "resilience_policies",
             "job_ledger",
             "event_emitter",
         },
     )
     def _stage_op(context, state: dict[str, Any]) -> dict[str, Any]:
-        stage = context.resources.stage_factory.resolve(topology.name, stage_definition)
+        stage_factory: StageFactory = context.resources.stage_factory
+        stage = stage_factory.resolve(topology.name, stage_definition)
+        metadata = stage_factory.get_metadata(stage_type)
         policy_loader: ResiliencePolicyLoader = context.resources.resilience_policies

         execute = getattr(stage, "execute")
         execution_state: dict[str, Any] = {
             "attempts": 0,
             "duration": 0.0,
             "failed": False,
             "error": None,
         }

         def _on_retry(retry_state: Any) -> None:
             job_identifier = state.get("job_id")
             if job_identifier:
                 ledger.increment_retry(job_identifier, stage_name)
             sleep_seconds = getattr(getattr(retry_state, "next_action", None), "sleep", 0.0) or 0.0
             attempt_number = getattr(retry_state, "attempt_number", 0) + 1
             error = getattr(getattr(retry_state, "outcome", None), "exception", lambda: None)()
             reason = str(error) if error else "retry"
             emitter.emit_retrying(
                 state["context"],
                 stage_name,
                 attempt=attempt_number,
                 backoff_ms=int(sleep_seconds * 1000),
                 reason=reason,
             )
@@ -265,66 +276,65 @@ def _make_stage_op(

         try:
             if stage_type == "ingest":
                 adapter_request: AdapterRequest = state["adapter_request"]
                 result = wrapped(stage_ctx, adapter_request)
             elif stage_type in {"parse", "ir-validation"}:
                 payloads = state.get("payloads", [])
                 result = wrapped(stage_ctx, payloads)
             elif stage_type == "chunk":
                 document = state.get("document")
                 result = wrapped(stage_ctx, document)
             elif stage_type == "embed":
                 chunks = state.get("chunks", [])
                 result = wrapped(stage_ctx, chunks)
             elif stage_type == "index":
                 batch = state.get("embedding_batch")
                 result = wrapped(stage_ctx, batch)
             elif stage_type == "extract":
                 document = state.get("document")
                 result = wrapped(stage_ctx, document)
             elif stage_type == "knowledge-graph":
                 entities = state.get("entities", [])
                 claims = state.get("claims", [])
                 result = wrapped(stage_ctx, entities, claims)
             else:  # pragma: no cover - guard for future expansion
-                upstream = state.get(_stage_state_key(stage_type))
+                upstream = _resolve_upstream_value(state, metadata, stage_factory)
                 result = wrapped(stage_ctx, upstream)
         except Exception as exc:
             attempts = execution_state.get("attempts") or 1
             emitter.emit_failed(stage_ctx, stage_name, attempt=attempts, error=str(exc))
             if job_id:
                 ledger.mark_failed(job_id, stage=stage_name, reason=str(exc))
             raise

         updated = dict(state)
-        _apply_stage_output(stage_type, stage_name, updated, result)
-        output = updated.get(_stage_state_key(stage_type))
+        _apply_stage_output(metadata, stage_name, updated, result)
         attempts = execution_state.get("attempts") or 1
         duration_seconds = execution_state.get("duration") or (time.perf_counter() - start_time)
         duration_ms = int(duration_seconds * 1000)
-        output_count = _infer_output_count(stage_type, output)
+        output_count = _infer_output_count(metadata, result)

         if job_id:
             ledger.update_metadata(
                 job_id,
                 {
                     f"stage.{stage_name}.attempts": attempts,
                     f"stage.{stage_name}.output_count": output_count,
                     f"stage.{stage_name}.duration_ms": duration_ms,
                 },
             )
         emitter.emit_completed(
             stage_ctx,
             stage_name,
             attempt=attempts,
             duration_ms=duration_ms,
             output_count=output_count,
         )
         logger.debug(
             "dagster.stage.completed",
             pipeline=topology.name,
             stage=stage_name,
             stage_type=stage_type,
             policy=policy_name,
             attempts=attempts,
             duration_ms=duration_ms,
diff --git a/src/Medical_KG_rev/orchestration/dagster/stage_registry.py b/src/Medical_KG_rev/orchestration/dagster/stage_registry.py
new file mode 100644
index 0000000000000000000000000000000000000000..bebe4713b2a4ad9a75d079fee5dec3926ccbdeb6
--- /dev/null
+++ b/src/Medical_KG_rev/orchestration/dagster/stage_registry.py
@@ -0,0 +1,249 @@
+"""Stage metadata and plugin registry for Dagster orchestration stages."""
+
+from __future__ import annotations
+
+import re
+from dataclasses import dataclass, field
+from importlib import metadata
+from typing import Any, Callable, Iterable, Mapping, Protocol, Sequence
+
+import structlog
+
+from Medical_KG_rev.orchestration.dagster.configuration import StageDefinition
+
+logger = structlog.get_logger(__name__)
+
+
+StageBuilder = Callable[[StageDefinition], object]
+
+
+class StageRegistryError(RuntimeError):
+    """Raised when stage metadata registration or lookup fails."""
+
+
+@dataclass(slots=True, frozen=True)
+class StageMetadata:
+    """Metadata describing how a stage integrates with the runtime state."""
+
+    stage_type: str
+    state_key: str | Sequence[str] | None
+    output_handler: Callable[[dict[str, Any], str, Any], None]
+    output_counter: Callable[[Any], int]
+    description: str
+    dependencies: Sequence[str] = field(default_factory=tuple)
+
+    _IDENTIFIER_PATTERN = re.compile(r"^[A-Za-z_][A-Za-z0-9_]*$")
+
+    def __post_init__(self) -> None:
+        if not isinstance(self.stage_type, str) or not self.stage_type.strip():
+            raise StageRegistryError("Stage type must be a non-empty string")
+        if not callable(self.output_handler):
+            raise StageRegistryError(
+                f"Stage '{self.stage_type}' output_handler must be callable"
+            )
+        if not callable(self.output_counter):
+            raise StageRegistryError(
+                f"Stage '{self.stage_type}' output_counter must be callable"
+            )
+        if not isinstance(self.description, str) or not self.description.strip():
+            raise StageRegistryError(
+                f"Stage '{self.stage_type}' description must be a non-empty string"
+            )
+        for dependency in self.dependencies:
+            if not isinstance(dependency, str) or not dependency.strip():
+                raise StageRegistryError(
+                    f"Stage '{self.stage_type}' dependency '{dependency}' is invalid"
+                )
+        self._validate_state_keys(self.state_key)
+
+    @property
+    def state_keys(self) -> Sequence[str] | None:
+        if self.state_key is None:
+            return None
+        if isinstance(self.state_key, str):
+            return (self.state_key,)
+        return tuple(self.state_key)
+
+    def result_snapshot(self, state: Mapping[str, Any], output: Any) -> Any:
+        keys = self.state_keys
+        if keys is None:
+            return output
+        if len(keys) == 1:
+            return state.get(keys[0])
+        return {key: state.get(key) for key in keys}
+
+    @classmethod
+    def _validate_state_keys(cls, state_key: str | Sequence[str] | None) -> None:
+        if state_key is None:
+            return
+        keys = (state_key,) if isinstance(state_key, str) else tuple(state_key)
+        if not keys:
+            raise StageRegistryError("state_key collection cannot be empty")
+        for key in keys:
+            if not isinstance(key, str) or not key:
+                raise StageRegistryError("state_key entries must be non-empty strings")
+            if not cls._IDENTIFIER_PATTERN.match(key):
+                raise StageRegistryError(
+                    f"Invalid state key '{key}'; must be a valid Python identifier"
+                )
+
+
+@dataclass(slots=True, frozen=True)
+class StageRegistration:
+    """Combination of metadata and builder used for registration."""
+
+    metadata: StageMetadata
+    builder: StageBuilder
+
+    def __post_init__(self) -> None:
+        if not callable(self.builder):
+            raise StageRegistryError(
+                f"Stage '{self.metadata.stage_type}' builder must be callable"
+            )
+
+
+class StagePlugin(Protocol):
+    """Protocol for plugin registration callables."""
+
+    def __call__(self) -> StageRegistration | Iterable[StageRegistration]:
+        """Return one or more stage registrations."""
+
+
+def discover_stages(
+    group: str = "medical_kg.orchestration.stages",
+) -> Iterable[StagePlugin]:
+    """Yield plugin callables discovered via entry points."""
+
+    try:
+        entry_points = metadata.entry_points()
+    except Exception as exc:  # pragma: no cover - defensive guard
+        logger.warning("dagster.stage.plugins.discovery_failed", error=str(exc))
+        return []
+    selected = entry_points.select(group=group) if hasattr(entry_points, "select") else []
+    plugins: list[StagePlugin] = []
+    for entry_point in selected:
+        try:
+            loaded = entry_point.load()
+        except Exception as exc:  # pragma: no cover - discovery guard
+            logger.warning(
+                "dagster.stage.plugins.load_failed",
+                entry_point=entry_point.name,
+                error=str(exc),
+            )
+            continue
+        if not callable(loaded):
+            logger.warning(
+                "dagster.stage.plugins.invalid",
+                entry_point=entry_point.name,
+                reason="not callable",
+            )
+            continue
+        plugins.append(loaded)  # type: ignore[return-value]
+    return plugins
+
+
+class StageRegistry:
+    """Registry responsible for managing stage metadata and builders."""
+
+    def __init__(
+        self,
+        *,
+        plugin_loader: Callable[[], Iterable[StagePlugin]] | None = None,
+    ) -> None:
+        self._metadata: dict[str, StageMetadata] = {}
+        self._builders: dict[str, StageBuilder] = {}
+        self._plugin_loader = plugin_loader or (lambda: discover_stages())
+
+    def register(self, registration: StageRegistration, *, replace: bool = False) -> None:
+        stage_type = registration.metadata.stage_type
+        if stage_type in self._metadata and not replace:
+            raise StageRegistryError(
+                f"Stage '{stage_type}' is already registered"
+            )
+        self._metadata[stage_type] = registration.metadata
+        self._builders[stage_type] = registration.builder
+        logger.debug(
+            "dagster.stage.registry.registered",
+            stage_type=stage_type,
+            description=registration.metadata.description,
+        )
+
+    def register_stage(
+        self,
+        *,
+        metadata: StageMetadata,
+        builder: StageBuilder,
+        replace: bool = False,
+    ) -> None:
+        registration = StageRegistration(metadata=metadata, builder=builder)
+        self.register(registration, replace=replace)
+
+    def get_metadata(self, stage_type: str) -> StageMetadata:
+        try:
+            return self._metadata[stage_type]
+        except KeyError as exc:  # pragma: no cover - guard
+            raise StageRegistryError(f"Unknown stage type '{stage_type}'") from exc
+
+    def get_builder(self, stage_type: str) -> StageBuilder:
+        try:
+            return self._builders[stage_type]
+        except KeyError as exc:  # pragma: no cover - guard
+            raise StageRegistryError(f"Unknown stage type '{stage_type}'") from exc
+
+    def load_plugins(self) -> list[str]:
+        loaded: list[str] = []
+        for plugin in self._plugin_loader():
+            try:
+                registrations = plugin()
+            except Exception as exc:
+                logger.warning(
+                    "dagster.stage.plugins.registration_failed",
+                    plugin=_plugin_name(plugin),
+                    error=str(exc),
+                )
+                continue
+            if isinstance(registrations, StageRegistration):
+                registrations = [registrations]
+            elif isinstance(registrations, Iterable):
+                registrations = list(registrations)
+            else:
+                logger.warning(
+                    "dagster.stage.plugins.invalid_return",
+                    plugin=_plugin_name(plugin),
+                )
+                continue
+            for registration in registrations:
+                try:
+                    self.register(registration)
+                except StageRegistryError as exc:
+                    logger.warning(
+                        "dagster.stage.plugins.registration_conflict",
+                        plugin=_plugin_name(plugin),
+                        stage_type=registration.metadata.stage_type,
+                        error=str(exc),
+                    )
+                    continue
+                loaded.append(registration.metadata.stage_type)
+        return loaded
+
+    def stage_types(self) -> list[str]:
+        return sorted(self._metadata)
+
+
+def _plugin_name(plugin: StagePlugin) -> str:
+    if hasattr(plugin, "__qualname__"):
+        return str(getattr(plugin, "__qualname__"))
+    if hasattr(plugin, "__name__"):
+        return str(getattr(plugin, "__name__"))
+    return plugin.__class__.__name__
+
+
+__all__ = [
+    "StageBuilder",
+    "StageMetadata",
+    "StagePlugin",
+    "StageRegistration",
+    "StageRegistry",
+    "StageRegistryError",
+    "discover_stages",
+]
diff --git a/src/Medical_KG_rev/orchestration/dagster/stages.py b/src/Medical_KG_rev/orchestration/dagster/stages.py
index b2a0426177d4a38e1936f255834690cfb6b3b84f..e897ad062167a9999b047be909757331a4ba2d7e 100644
--- a/src/Medical_KG_rev/orchestration/dagster/stages.py
+++ b/src/Medical_KG_rev/orchestration/dagster/stages.py
@@ -1,63 +1,142 @@
 """Default stage implementations and builder helpers for Dagster pipelines."""

 from __future__ import annotations

 import json
 from dataclasses import dataclass
-from typing import Any, Callable, Mapping, Sequence
+from collections.abc import Sequence
+from typing import Any, Mapping
 from uuid import uuid4

 import structlog

 from Medical_KG_rev.adapters import AdapterPluginError
 from Medical_KG_rev.adapters.plugins.manager import AdapterPluginManager
 from Medical_KG_rev.adapters.plugins.models import AdapterDomain, AdapterRequest
 from Medical_KG_rev.models.entities import Claim, Entity
 from Medical_KG_rev.models.ir import Block, BlockType, Document, Section
 from Medical_KG_rev.orchestration.dagster.configuration import StageDefinition
+from Medical_KG_rev.orchestration.dagster.stage_registry import (
+    StageMetadata,
+    StageRegistry,
+    StageRegistryError,
+)
 from Medical_KG_rev.orchestration.haystack.components import (
     HaystackChunker,
     HaystackEmbedder,
     HaystackIndexWriter,
 )
 from Medical_KG_rev.orchestration.stages.contracts import (
     ChunkStage,
     EmbedStage,
     ExtractStage,
     GraphWriteReceipt,
     IngestStage,
     IndexStage,
     KGStage,
     ParseStage,
     StageContext,
 )
 from Medical_KG_rev.orchestration.stages.contracts import RawPayload

 logger = structlog.get_logger(__name__)


+def _sequence_length(output: Any) -> int:
+    if isinstance(output, Sequence) and not isinstance(output, (str, bytes)):
+        return len(output)
+    return 0
+
+
+def _count_single(output: Any) -> int:
+    return 1 if output is not None else 0
+
+
+def _count_embed(output: Any) -> int:
+    vectors = getattr(output, "vectors", None)
+    if isinstance(vectors, Sequence):
+        return len(vectors)
+    return 0
+
+
+def _count_index(output: Any) -> int:
+    indexed = getattr(output, "chunks_indexed", None)
+    if isinstance(indexed, int):
+        return max(indexed, 0)
+    return 0
+
+
+def _count_extract(output: Any) -> int:
+    if not isinstance(output, tuple) or len(output) != 2:
+        return 0
+    entities, claims = output
+    entity_count = _sequence_length(entities)
+    claim_count = _sequence_length(claims)
+    return entity_count + claim_count
+
+
+def _count_graph(output: Any) -> int:
+    nodes = getattr(output, "nodes_written", None)
+    if isinstance(nodes, int):
+        return max(nodes, 0)
+    return 0
+
+
+def _handle_ingest(state: dict[str, Any], _: str, output: Any) -> None:
+    state["payloads"] = output
+
+
+def _handle_document(state: dict[str, Any], _: str, output: Any) -> None:
+    state["document"] = output
+
+
+def _handle_chunks(state: dict[str, Any], _: str, output: Any) -> None:
+    state["chunks"] = output
+
+
+def _handle_embedding_batch(state: dict[str, Any], _: str, output: Any) -> None:
+    state["embedding_batch"] = output
+
+
+def _handle_index_receipt(state: dict[str, Any], _: str, output: Any) -> None:
+    state["index_receipt"] = output
+
+
+def _handle_extract(state: dict[str, Any], _: str, output: Any) -> None:
+    entities: Any = []
+    claims: Any = []
+    if isinstance(output, tuple) and len(output) == 2:
+        entities, claims = output
+    state["entities"] = list(entities) if isinstance(entities, Sequence) else entities
+    state["claims"] = list(claims) if isinstance(claims, Sequence) else claims
+
+
+def _handle_graph_receipt(state: dict[str, Any], _: str, output: Any) -> None:
+    state["graph_receipt"] = output
+
+
 class AdapterIngestStage(IngestStage):
     """Fetch raw payloads from a configured adapter using the plugin manager."""

     def __init__(
         self,
         manager: AdapterPluginManager,
         *,
         adapter_name: str,
         strict: bool = False,
         default_domain: AdapterDomain = AdapterDomain.BIOMEDICAL,
         extra_parameters: Mapping[str, Any] | None = None,
     ) -> None:
         self._manager = manager
         self._adapter = adapter_name
         self._strict = strict
         self._default_domain = default_domain
         self._extra_parameters = dict(extra_parameters or {})

     def execute(self, ctx: StageContext, request: AdapterRequest) -> list[RawPayload]:
         merged_parameters = {**self._extra_parameters, **dict(request.parameters)}
         domain = request.domain or self._default_domain  # type: ignore[union-attr]
         invocation_request = request.model_copy(update={"parameters": merged_parameters, "domain": domain})
         try:
             result = self._manager.invoke(self._adapter, invocation_request, strict=self._strict)
         except AdapterPluginError as exc:
@@ -228,86 +307,182 @@ class NoOpDocumentWriter:
     def run(self, *, documents: Sequence[Any]) -> dict[str, Any]:  # pragma: no cover - trivial
         logger.debug("dagster.index.writer.noop", writer=self._name, documents=len(documents))
         return {"documents": list(documents)}


 @dataclass(slots=True)
 class HaystackPipelineResource:
     splitter: SimpleDocumentSplitter
     embedder: SimpleEmbedder
     dense_writer: NoOpDocumentWriter
     sparse_writer: NoOpDocumentWriter


 def create_default_pipeline_resource() -> HaystackPipelineResource:
     return HaystackPipelineResource(
         splitter=SimpleDocumentSplitter(),
         embedder=SimpleEmbedder(),
         dense_writer=NoOpDocumentWriter(name="faiss"),
         sparse_writer=NoOpDocumentWriter(name="opensearch"),
     )


 def build_default_stage_factory(
     manager: AdapterPluginManager,
     pipeline: HaystackPipelineResource | None = None,
-) -> dict[str, Callable[[StageDefinition], object]]:
-    """Return builder mappings for standard Dagster stage types."""
+) -> StageRegistry:
+    """Build the default stage registry with built-in metadata and builders."""

     pipeline = pipeline or create_default_pipeline_resource()
     splitter = pipeline.splitter
     embedder = pipeline.embedder
     dense_writer = pipeline.dense_writer
     sparse_writer = pipeline.sparse_writer

     def _ingest_builder(definition: StageDefinition) -> IngestStage:
         config = definition.config
         adapter_name = config.get("adapter")
         if not adapter_name:
             raise ValueError(f"Stage '{definition.name}' requires an adapter name")
         strict = bool(config.get("strict", False))
         domain_value = config.get("domain")
         try:
             domain = AdapterDomain(domain_value) if domain_value else AdapterDomain.BIOMEDICAL
         except Exception as exc:  # pragma: no cover - validation guard
             raise ValueError(f"Invalid adapter domain '{domain_value}'") from exc
         extra_parameters = config.get("parameters", {}) if isinstance(config, Mapping) else {}
         return AdapterIngestStage(
             manager,
             adapter_name=adapter_name,
             strict=strict,
             default_domain=domain,
             extra_parameters=extra_parameters if isinstance(extra_parameters, Mapping) else {},
         )

     def _parse_builder(_: StageDefinition) -> ParseStage:
         return AdapterParseStage()

     def _validation_builder(_: StageDefinition) -> ParseStage:
         return IRValidationStage()

     def _chunk_builder(_: StageDefinition) -> ChunkStage:
         return HaystackChunker(splitter, chunker_name="haystack.semantic", granularity="paragraph")

     def _embed_builder(_: StageDefinition) -> EmbedStage:
         return HaystackEmbedder(embedder=embedder, require_gpu=False, sparse_expander=None)

     def _index_builder(_: StageDefinition) -> IndexStage:
         return HaystackIndexWriter(dense_writer=dense_writer, sparse_writer=sparse_writer)

     def _extract_builder(_: StageDefinition) -> ExtractStage:
         return NoOpExtractStage()

     def _kg_builder(_: StageDefinition) -> KGStage:
         return NoOpKnowledgeGraphStage()

-    registry: dict[str, Callable[[StageDefinition], object]] = {
-        "ingest": _ingest_builder,
-        "parse": _parse_builder,
-        "ir-validation": _validation_builder,
-        "chunk": _chunk_builder,
-        "embed": _embed_builder,
-        "index": _index_builder,
-        "extract": _extract_builder,
-        "knowledge-graph": _kg_builder,
-    }
+    registry = StageRegistry()
+    registry.register_stage(
+        metadata=StageMetadata(
+            stage_type="ingest",
+            state_key="payloads",
+            output_handler=_handle_ingest,
+            output_counter=_sequence_length,
+            description="Fetches raw payloads from an adapter",
+        ),
+        builder=_ingest_builder,
+    )
+    registry.register_stage(
+        metadata=StageMetadata(
+            stage_type="parse",
+            state_key="document",
+            output_handler=_handle_document,
+            output_counter=_count_single,
+            description="Parses raw payloads into an IR document",
+            dependencies=("ingest",),
+        ),
+        builder=_parse_builder,
+    )
+    registry.register_stage(
+        metadata=StageMetadata(
+            stage_type="ir-validation",
+            state_key="document",
+            output_handler=_handle_document,
+            output_counter=_count_single,
+            description="Validates parsed documents before downstream stages",
+            dependencies=("parse",),
+        ),
+        builder=_validation_builder,
+    )
+    registry.register_stage(
+        metadata=StageMetadata(
+            stage_type="chunk",
+            state_key="chunks",
+            output_handler=_handle_chunks,
+            output_counter=_sequence_length,
+            description="Splits documents into retrieval-ready chunks",
+            dependencies=("parse", "ir-validation"),
+        ),
+        builder=_chunk_builder,
+    )
+    registry.register_stage(
+        metadata=StageMetadata(
+            stage_type="embed",
+            state_key="embedding_batch",
+            output_handler=_handle_embedding_batch,
+            output_counter=_count_embed,
+            description="Generates embeddings for document chunks",
+            dependencies=("chunk",),
+        ),
+        builder=_embed_builder,
+    )
+    registry.register_stage(
+        metadata=StageMetadata(
+            stage_type="index",
+            state_key="index_receipt",
+            output_handler=_handle_index_receipt,
+            output_counter=_count_index,
+            description="Writes embeddings to downstream indexes",
+            dependencies=("embed",),
+        ),
+        builder=_index_builder,
+    )
+    registry.register_stage(
+        metadata=StageMetadata(
+            stage_type="extract",
+            state_key=("entities", "claims"),
+            output_handler=_handle_extract,
+            output_counter=_count_extract,
+            description="Extracts biomedical entities and claims",
+            dependencies=("parse",),
+        ),
+        builder=_extract_builder,
+    )
+    registry.register_stage(
+        metadata=StageMetadata(
+            stage_type="knowledge-graph",
+            state_key="graph_receipt",
+            output_handler=_handle_graph_receipt,
+            output_counter=_count_graph,
+            description="Persists extracted facts into the knowledge graph",
+            dependencies=("extract",),
+        ),
+        builder=_kg_builder,
+    )
+    try:
+        from Medical_KG_rev.orchestration import stage_plugins
+
+        for plugin_factory in (stage_plugins.register_download_stage, stage_plugins.register_gate_stage):
+            registration = None
+            try:
+                registration = plugin_factory()
+                registry.register(registration)
+            except StageRegistryError as exc:
+                stage_type = registration.metadata.stage_type if registration else getattr(plugin_factory, "__name__", "unknown")
+                logger.debug(
+                    "dagster.stage.registry.plugin_skipped",
+                    stage_type=stage_type,
+                    error=str(exc),
+                )
+    except Exception as exc:  # pragma: no cover - defensive guard
+        logger.warning("dagster.stage.registry.plugin_init_failed", error=str(exc))
+    registry.load_plugins()
     return registry
diff --git a/src/Medical_KG_rev/orchestration/stage_plugins/__init__.py b/src/Medical_KG_rev/orchestration/stage_plugins/__init__.py
new file mode 100644
index 0000000000000000000000000000000000000000..4ce7a471e0b5443895ba3e7cb5a4eb27ace34f1e
--- /dev/null
+++ b/src/Medical_KG_rev/orchestration/stage_plugins/__init__.py
@@ -0,0 +1,179 @@
+"""Built-in plugin registrations for pluggable orchestration stages."""
+
+from __future__ import annotations
+
+from collections.abc import Iterable, Mapping, Sequence
+from dataclasses import dataclass
+from typing import Any
+
+import structlog
+
+from Medical_KG_rev.orchestration.dagster.configuration import StageDefinition
+from Medical_KG_rev.orchestration.dagster.stage_registry import (
+    StageMetadata,
+    StageRegistration,
+)
+from Medical_KG_rev.orchestration.stages.contracts import StageContext
+
+logger = structlog.get_logger(__name__)
+
+
+class GateConditionError(RuntimeError):
+    """Raised when a gate stage condition fails."""
+
+
+def _sequence_length(value: Any) -> int:
+    if isinstance(value, Sequence) and not isinstance(value, (str, bytes)):
+        return len(value)
+    return 0
+
+
+def _handle_download_output(state: dict[str, Any], _: str, output: Any) -> None:
+    state["downloaded_files"] = output
+
+
+def _handle_gate_output(state: dict[str, Any], _: str, output: Any) -> None:  # pragma: no cover - no-op
+    return None
+
+
+@dataclass(slots=True)
+class DownloadStage:
+    """Example download stage that records configured sources."""
+
+    name: str
+    sources: list[dict[str, Any]]
+
+    def execute(self, ctx: StageContext, upstream: Any) -> list[dict[str, Any]]:
+        results: list[dict[str, Any]] = []
+        for index, source in enumerate(self.sources):
+            record = {
+                "id": f"{self.name}:{index}",
+                "tenant_id": ctx.tenant_id,
+                "source": dict(source),
+                "status": "skipped",
+            }
+            results.append(record)
+        if not results and upstream:
+            results.append(
+                {
+                    "id": f"{self.name}:0",
+                    "tenant_id": ctx.tenant_id,
+                    "source": {"upstream": upstream},
+                    "status": "forwarded",
+                }
+            )
+        logger.debug(
+            "dagster.stage.download.completed",
+            stage=self.name,
+            tenant_id=ctx.tenant_id,
+            files=len(results),
+        )
+        return results
+
+
+@dataclass(slots=True)
+class GateCondition:
+    key: str
+    expected: Any = True
+
+
+@dataclass(slots=True)
+class GateStage:
+    """Gate stage validating state conditions before proceeding."""
+
+    name: str
+    conditions: tuple[GateCondition, ...]
+
+    def execute(self, ctx: StageContext, upstream: Any) -> None:
+        state = upstream if isinstance(upstream, dict) else {"value": upstream}
+        for condition in self.conditions:
+            value = state
+            for part in condition.key.split("."):
+                if isinstance(value, dict):
+                    value = value.get(part)
+                else:
+                    value = getattr(value, part, None)
+            if value != condition.expected:
+                logger.warning(
+                    "dagster.stage.gate.blocked",
+                    stage=self.name,
+                    tenant_id=ctx.tenant_id,
+                    key=condition.key,
+                    expected=condition.expected,
+                    actual=value,
+                )
+                raise GateConditionError(
+                    f"Gate '{self.name}' blocked: expected {condition.key} == {condition.expected!r}"
+                )
+        logger.debug(
+            "dagster.stage.gate.passed",
+            stage=self.name,
+            tenant_id=ctx.tenant_id,
+            conditions=len(self.conditions),
+        )
+
+
+def register_download_stage() -> StageRegistration:
+    """Register the built-in download stage plugin."""
+
+    def _builder(definition: StageDefinition) -> DownloadStage:
+        config = definition.config or {}
+        sources = config.get("sources") or config.get("urls") or []
+        normalised: list[dict[str, Any]] = []
+        if isinstance(sources, dict):
+            normalised.append(dict(sources))
+        elif isinstance(sources, Iterable) and not isinstance(sources, (str, bytes)):
+            for item in sources:
+                if isinstance(item, dict):
+                    normalised.append(dict(item))
+                else:
+                    normalised.append({"value": item})
+        return DownloadStage(name=definition.name, sources=normalised)
+
+    metadata = StageMetadata(
+        stage_type="download",
+        state_key="downloaded_files",
+        output_handler=_handle_download_output,
+        output_counter=_sequence_length,
+        description="Downloads external resources referenced by upstream payloads",
+        dependencies=("ingest",),
+    )
+    return StageRegistration(metadata=metadata, builder=_builder)
+
+
+def register_gate_stage() -> StageRegistration:
+    """Register the built-in gate stage plugin."""
+
+    def _builder(definition: StageDefinition) -> GateStage:
+        config = definition.config or {}
+        conditions_config = config.get("conditions") or []
+        parsed: list[GateCondition] = []
+        for entry in conditions_config:
+            if isinstance(entry, Mapping):
+                key = entry.get("key") or "value"
+                parsed.append(GateCondition(key=str(key), expected=entry.get("expected", True)))
+            elif isinstance(entry, str):
+                parsed.append(GateCondition(key=entry, expected=True))
+        if not parsed:
+            parsed.append(GateCondition(key="value", expected=True))
+        return GateStage(name=definition.name, conditions=tuple(parsed))
+
+    metadata = StageMetadata(
+        stage_type="gate",
+        state_key=None,
+        output_handler=_handle_gate_output,
+        output_counter=lambda _: 0,
+        description="Halts pipeline execution until configured conditions are met",
+        dependencies=("download",),
+    )
+    return StageRegistration(metadata=metadata, builder=_builder)
+
+
+__all__ = [
+    "DownloadStage",
+    "GateCondition",
+    "GateConditionError",
+    "GateStage",
+    "register_download_stage",
+    "register_gate_stage",
+]
diff --git a/tests/orchestration/test_stage_contracts.py b/tests/orchestration/test_stage_contracts.py
index c2323960ed4fc3498d0dad58cb1292d1e7fbf1a4..b0659f3fc60300123388496eac4f8b966a3fb511 100644
--- a/tests/orchestration/test_stage_contracts.py
+++ b/tests/orchestration/test_stage_contracts.py
@@ -1,29 +1,31 @@
 from types import SimpleNamespace

 import pytest

+pytest.importorskip("pydantic")
+
 from Medical_KG_rev.adapters.plugins.models import AdapterDomain, AdapterRequest
 from Medical_KG_rev.orchestration.dagster.configuration import StageDefinition
 from Medical_KG_rev.orchestration.dagster.stages import build_default_stage_factory
 from Medical_KG_rev.orchestration.stages.contracts import (
     ChunkStage,
     EmbedStage,
     EmbeddingBatch,
     ExtractStage,
     GraphWriteReceipt,
     IngestStage,
     IndexReceipt,
     IndexStage,
     KGStage,
     ParseStage,
     StageContext,
 )


 class StubPluginManager:
     def __init__(self) -> None:
         self.invocations: list[tuple[str, AdapterRequest]] = []

     def invoke(self, adapter: str, request: AdapterRequest, *, strict: bool = False):
         self.invocations.append((adapter, request))
         payload = {"text": "Example abstract for testing", "title": "Test"}
@@ -41,70 +43,70 @@ def stage_context() -> StageContext:
         pipeline_version="2024-01-01",
     )


 @pytest.fixture()
 def adapter_request() -> AdapterRequest:
     return AdapterRequest(
         tenant_id="tenant-a",
         correlation_id="corr-1",
         domain=AdapterDomain.BIOMEDICAL,
         parameters={"adapter": "clinical-trials"},
     )


 def _definition(stage_type: str, name: str, config: dict | None = None) -> StageDefinition:
     payload = {"name": name, "type": stage_type, "policy": "default"}
     if config:
         payload["config"] = config
     return StageDefinition.model_validate(payload)


 def test_default_stage_factory_complies_with_protocols(stage_context, adapter_request):
     manager = StubPluginManager()
     registry = build_default_stage_factory(manager)

-    ingest = registry["ingest"](
+    ingest = registry.get_builder("ingest")(
         _definition("ingest", "ingest", {"adapter": "clinical-trials", "strict": False})
     )
     assert isinstance(ingest, IngestStage)
     payloads = ingest.execute(stage_context, adapter_request)
     assert payloads and isinstance(payloads[0], dict)

-    parse = registry["parse"](_definition("parse", "parse"))
+    parse = registry.get_builder("parse")(_definition("parse", "parse"))
     assert isinstance(parse, ParseStage)
     document = parse.execute(stage_context, payloads)

-    validator = registry["ir-validation"](_definition("ir-validation", "ir_validation"))
+    validator = registry.get_builder("ir-validation")(_definition("ir-validation", "ir_validation"))
     assert isinstance(validator, ParseStage)
     validated = validator.execute(stage_context, document)
     assert validated is document

-    chunker = registry["chunk"](_definition("chunk", "chunk"))
+    chunker = registry.get_builder("chunk")(_definition("chunk", "chunk"))
     assert isinstance(chunker, ChunkStage)
     chunks = chunker.execute(stage_context, document)
     assert chunks and chunks[0].doc_id == document.id

-    embedder = registry["embed"](_definition("embed", "embed"))
+    embedder = registry.get_builder("embed")(_definition("embed", "embed"))
     assert isinstance(embedder, EmbedStage)
     batch = embedder.execute(stage_context, chunks)
     assert isinstance(batch, EmbeddingBatch)
     assert batch.vectors

-    indexer = registry["index"](_definition("index", "index"))
+    indexer = registry.get_builder("index")(_definition("index", "index"))
     assert isinstance(indexer, IndexStage)
     receipt = indexer.execute(stage_context, batch)
     assert isinstance(receipt, IndexReceipt)
     assert receipt.chunks_indexed == len(batch.vectors)

-    extractor = registry["extract"](_definition("extract", "extract"))
+    extractor = registry.get_builder("extract")(_definition("extract", "extract"))
     assert isinstance(extractor, ExtractStage)
     entities, claims = extractor.execute(stage_context, document)
     assert entities == [] and claims == []

-    kg_stage = registry["knowledge-graph"](_definition("knowledge-graph", "kg"))
+    kg_stage = registry.get_builder("knowledge-graph")(_definition("knowledge-graph", "kg"))
     assert isinstance(kg_stage, KGStage)
     graph_receipt = kg_stage.execute(stage_context, entities, claims)
     assert isinstance(graph_receipt, GraphWriteReceipt)
     assert graph_receipt.nodes_written == 0

     assert manager.invocations and manager.invocations[0][0] == "clinical-trials"
diff --git a/tests/orchestration/test_stage_registry.py b/tests/orchestration/test_stage_registry.py
new file mode 100644
index 0000000000000000000000000000000000000000..1afd64c17da5593fb67592b04569965090e93556
--- /dev/null
+++ b/tests/orchestration/test_stage_registry.py
@@ -0,0 +1,72 @@
+from types import SimpleNamespace
+from typing import Any
+
+import pytest
+
+pytest.importorskip("pydantic")
+
+from Medical_KG_rev.orchestration.dagster.runtime import StageFactory, StageResolutionError
+from Medical_KG_rev.orchestration.dagster.stage_registry import (
+    StageMetadata,
+    StageRegistration,
+    StageRegistry,
+    StageRegistryError,
+)
+
+
+def _builder(_: Any) -> object:
+    return object()
+
+
+def test_stage_metadata_rejects_invalid_state_key():
+    with pytest.raises(StageRegistryError):
+        StageMetadata(
+            stage_type="invalid",
+            state_key="123-key",
+            output_handler=lambda *_: None,
+            output_counter=lambda _: 0,
+            description="invalid",
+        )
+
+
+def test_stage_registry_register_and_lookup():
+    registry = StageRegistry()
+    metadata = StageMetadata(
+        stage_type="custom",
+        state_key="result",
+        output_handler=lambda state, _, output: state.update({"result": output}),
+        output_counter=lambda output: 1 if output else 0,
+        description="Custom stage",
+    )
+    registry.register(StageRegistration(metadata=metadata, builder=_builder))
+
+    resolved_metadata = registry.get_metadata("custom")
+    assert resolved_metadata.stage_type == "custom"
+    builder = registry.get_builder("custom")
+    instance = builder(SimpleNamespace(name="stage", stage_type="custom", config={}))
+    assert instance is not None
+
+
+def test_stage_registry_plugin_loader_registers_plugins():
+    metadata = StageMetadata(
+        stage_type="plugin-stage",
+        state_key="value",
+        output_handler=lambda state, _, output: state.update({"value": output}),
+        output_counter=lambda output: int(output or 0),
+        description="Plugin provided stage",
+    )
+
+    def _plugin():
+        return StageRegistration(metadata=metadata, builder=_builder)
+
+    registry = StageRegistry(plugin_loader=lambda: [_plugin])
+    loaded = registry.load_plugins()
+    assert "plugin-stage" in loaded
+    assert registry.get_metadata("plugin-stage").description == "Plugin provided stage"
+
+
+def test_stage_factory_raises_on_unknown_stage():
+    registry = StageRegistry()
+    factory = StageFactory(registry)
+    with pytest.raises(StageResolutionError):
+        factory.resolve("pipeline", SimpleNamespace(name="missing", stage_type="missing", config={}))
